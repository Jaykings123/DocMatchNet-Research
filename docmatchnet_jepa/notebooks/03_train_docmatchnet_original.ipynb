{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DocMatchNet-Original Training\n",
    "==============================\n",
    "Single-stage training with score-space prediction\n",
    "\n",
    "GPU Required: T4 or P100  \n",
    "Runtime: ~2-3 hours total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 1: Setup\n",
    "# ============================================================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Set seed per run: 42, 123, 456\n",
    "SEED = 42\n",
    "\n",
    "# Check GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "# Reproducibility\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Output path per seed\n",
    "RUN_DIR = f'/kaggle/working/results/original/seed_{SEED}'\n",
    "os.makedirs(RUN_DIR, exist_ok=True)\n",
    "print(f\"Run dir: {RUN_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 2: Load Data\n",
    "# ============================================================\n",
    "# Update this if your Kaggle dataset slug/path differs.\n",
    "DATA_DIR = '/kaggle/input/docmatchnet-jepa-data/data'\n",
    "\n",
    "# PyTorch 2.6+: use weights_only=False for non-state_dict data files.\n",
    "doctor_embeddings = torch.load(f'{DATA_DIR}/doctor_embeddings.pt', weights_only=False)\n",
    "case_embeddings = torch.load(f'{DATA_DIR}/case_embeddings.pt', weights_only=False)\n",
    "clinical_features = torch.load(f'{DATA_DIR}/clinical_features.pt', weights_only=False)\n",
    "pastwork_features = torch.load(f'{DATA_DIR}/pastwork_features.pt', weights_only=False)\n",
    "logistics_features = torch.load(f'{DATA_DIR}/logistics_features.pt', weights_only=False)\n",
    "trust_features = torch.load(f'{DATA_DIR}/trust_features.pt', weights_only=False)\n",
    "context_features = torch.load(f'{DATA_DIR}/context_features.pt', weights_only=False)\n",
    "relevance_labels = torch.load(f'{DATA_DIR}/relevance_labels.pt', weights_only=False)\n",
    "doctor_indices = torch.load(f'{DATA_DIR}/doctor_indices.pt', weights_only=False)\n",
    "case_metadata = torch.load(f'{DATA_DIR}/case_metadata.pt', weights_only=False)\n",
    "splits = torch.load(f'{DATA_DIR}/splits.pt', weights_only=False)\n",
    "\n",
    "print('Loaded data:')\n",
    "print(f'  Doctor embeddings: {doctor_embeddings.shape}')\n",
    "print(f'  Case embeddings: {case_embeddings.shape}')\n",
    "print(f'  Clinical features: {clinical_features.shape}')\n",
    "print(f\"  Train/Val/Test: {len(splits['train'])}/{len(splits['val'])}/{len(splits['test'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 3: Dataset Classes\n",
    "# ============================================================\n",
    "class DocMatchDatasetOriginal(Dataset):\n",
    "    \"\"\"Dataset for pairwise score-space training.\"\"\"\n",
    "\n",
    "    def __init__(self, indices, case_emb, doc_emb, doc_indices,\n",
    "                 clinical, pastwork, logistics, trust, context,\n",
    "                 relevance, metadata):\n",
    "        self.indices = indices\n",
    "        self.case_emb = case_emb\n",
    "        self.doc_emb = doc_emb\n",
    "        self.doc_indices = doc_indices\n",
    "        self.clinical = clinical\n",
    "        self.pastwork = pastwork\n",
    "        self.logistics = logistics\n",
    "        self.trust = trust\n",
    "        self.context = context\n",
    "        self.relevance = relevance\n",
    "        self.metadata = metadata\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        case_idx = self.indices[idx]\n",
    "        rel = self.relevance[case_idx]\n",
    "\n",
    "        pos_mask = rel >= 3\n",
    "        if pos_mask.sum() == 0:\n",
    "            pos_mask = rel == rel.max()\n",
    "\n",
    "        neg_mask = rel <= 1\n",
    "        if neg_mask.sum() == 0:\n",
    "            neg_mask = rel < rel.max()\n",
    "\n",
    "        pos_local = torch.where(pos_mask)[0]\n",
    "        neg_local = torch.where(neg_mask)[0]\n",
    "\n",
    "        pos_idx = pos_local[torch.randint(len(pos_local), (1,))].item()\n",
    "        neg_idx = neg_local[torch.randint(len(neg_local), (1,))].item()\n",
    "\n",
    "        pos_doc_global = self.doc_indices[case_idx, pos_idx]\n",
    "        neg_doc_global = self.doc_indices[case_idx, neg_idx]\n",
    "\n",
    "        return {\n",
    "            'case_embedding': self.case_emb[case_idx],\n",
    "            'pos_doctor_embedding': self.doc_emb[pos_doc_global],\n",
    "            'neg_doctor_embedding': self.doc_emb[neg_doc_global],\n",
    "            'pos_clinical': self.clinical[case_idx, pos_idx],\n",
    "            'neg_clinical': self.clinical[case_idx, neg_idx],\n",
    "            'pos_pastwork': self.pastwork[case_idx, pos_idx],\n",
    "            'neg_pastwork': self.pastwork[case_idx, neg_idx],\n",
    "            'pos_logistics': self.logistics[case_idx, pos_idx],\n",
    "            'neg_logistics': self.logistics[case_idx, neg_idx],\n",
    "            'pos_trust': self.trust[case_idx, pos_idx],\n",
    "            'neg_trust': self.trust[case_idx, neg_idx],\n",
    "            'context': self.context[case_idx],\n",
    "            'pos_label': torch.tensor(1.0, dtype=torch.float32),\n",
    "            'neg_label': torch.tensor(0.0, dtype=torch.float32),\n",
    "            'context_category': self.metadata['context_category'][case_idx]\n",
    "        }\n",
    "\n",
    "\n",
    "class DocMatchDatasetEval(Dataset):\n",
    "    \"\"\"Dataset for listwise evaluation.\"\"\"\n",
    "\n",
    "    def __init__(self, indices, case_emb, doc_emb, doc_indices,\n",
    "                 clinical, pastwork, logistics, trust, context,\n",
    "                 relevance, metadata):\n",
    "        self.indices = indices\n",
    "        self.case_emb = case_emb\n",
    "        self.doc_emb = doc_emb\n",
    "        self.doc_indices = doc_indices\n",
    "        self.clinical = clinical\n",
    "        self.pastwork = pastwork\n",
    "        self.logistics = logistics\n",
    "        self.trust = trust\n",
    "        self.context = context\n",
    "        self.relevance = relevance\n",
    "        self.metadata = metadata\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        case_idx = self.indices[idx]\n",
    "        doc_global_indices = self.doc_indices[case_idx]\n",
    "\n",
    "        return {\n",
    "            'case_embedding': self.case_emb[case_idx],\n",
    "            'doctor_embeddings': self.doc_emb[doc_global_indices],\n",
    "            'clinical': self.clinical[case_idx],\n",
    "            'pastwork': self.pastwork[case_idx],\n",
    "            'logistics': self.logistics[case_idx],\n",
    "            'trust': self.trust[case_idx],\n",
    "            'context': self.context[case_idx],\n",
    "            'relevance': self.relevance[case_idx],\n",
    "            'context_category': self.metadata['context_category'][case_idx]\n",
    "        }\n",
    "\n",
    "train_ds = DocMatchDatasetOriginal(\n",
    "    splits['train'], case_embeddings, doctor_embeddings, doctor_indices,\n",
    "    clinical_features, pastwork_features, logistics_features, trust_features,\n",
    "    context_features, relevance_labels, case_metadata\n",
    ")\n",
    "\n",
    "val_ds = DocMatchDatasetEval(\n",
    "    splits['val'], case_embeddings, doctor_embeddings, doctor_indices,\n",
    "    clinical_features, pastwork_features, logistics_features, trust_features,\n",
    "    context_features, relevance_labels, case_metadata\n",
    ")\n",
    "\n",
    "test_ds = DocMatchDatasetEval(\n",
    "    splits['test'], case_embeddings, doctor_embeddings, doctor_indices,\n",
    "    clinical_features, pastwork_features, logistics_features, trust_features,\n",
    "    context_features, relevance_labels, case_metadata\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_ds, batch_size=1, shuffle=False)\n",
    "test_loader = DataLoader(test_ds, batch_size=1, shuffle=False)\n",
    "\n",
    "print(f'Train batches: {len(train_loader)}')\n",
    "print(f'Val samples: {len(val_ds)}')\n",
    "print(f'Test samples: {len(test_ds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 4: DocMatchNetOriginal Model\n",
    "# ============================================================\n",
    "class DocMatchNetOriginal(nn.Module):\n",
    "    \"\"\"Original DocMatchNet with score-space prediction.\"\"\"\n",
    "\n",
    "    def __init__(self, embed_dim=384, hidden_dim=256, gate_dim=32, context_dim=8,\n",
    "                 n_attention_heads=4, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.patient_proj = nn.Linear(embed_dim, hidden_dim)\n",
    "        self.doctor_proj = nn.Linear(embed_dim, hidden_dim)\n",
    "        self.cross_attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_dim,\n",
    "            num_heads=n_attention_heads,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.interaction_norm = nn.LayerNorm(hidden_dim)\n",
    "\n",
    "        self.clinical_encoder = self._make_encoder(4, gate_dim)\n",
    "        self.pastwork_encoder = self._make_encoder(5, gate_dim)\n",
    "        self.logistics_encoder = self._make_encoder(5, gate_dim)\n",
    "        self.trust_encoder = self._make_encoder(3, gate_dim)\n",
    "\n",
    "        gate_input_dim = hidden_dim + context_dim\n",
    "        self.clinical_gate = self._make_gate(gate_input_dim, gate_dim)\n",
    "        self.pastwork_gate = self._make_gate(gate_input_dim, gate_dim)\n",
    "        self.logistics_gate = self._make_gate(gate_input_dim, gate_dim)\n",
    "        self.trust_gate = self._make_gate(gate_input_dim, gate_dim)\n",
    "\n",
    "        self._init_gate_biases()\n",
    "\n",
    "        self.scoring_head = nn.Sequential(\n",
    "            nn.Linear(gate_dim * 4, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def _make_encoder(self, input_dim, output_dim):\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim),\n",
    "            nn.BatchNorm1d(output_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(output_dim, output_dim),\n",
    "            nn.BatchNorm1d(output_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def _make_gate(self, input_dim, output_dim):\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, output_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def _init_gate_biases(self):\n",
    "        nn.init.constant_(self.clinical_gate[-2].bias, 0.4)\n",
    "        nn.init.constant_(self.pastwork_gate[-2].bias, 0.0)\n",
    "        nn.init.constant_(self.logistics_gate[-2].bias, 0.0)\n",
    "        nn.init.constant_(self.trust_gate[-2].bias, -0.4)\n",
    "\n",
    "    def forward(self, patient_emb, doctor_emb, clinical, pastwork, logistics, trust, context):\n",
    "        p = self.patient_proj(patient_emb).unsqueeze(1)\n",
    "        d = self.doctor_proj(doctor_emb).unsqueeze(1)\n",
    "\n",
    "        interaction, attn_weights = self.cross_attention(p, d, d)\n",
    "        interaction = self.interaction_norm(interaction.squeeze(1))\n",
    "\n",
    "        enc_clinical = self.clinical_encoder(clinical)\n",
    "        enc_pastwork = self.pastwork_encoder(pastwork)\n",
    "        enc_logistics = self.logistics_encoder(logistics)\n",
    "        enc_trust = self.trust_encoder(trust)\n",
    "\n",
    "        gate_input = torch.cat([interaction, context], dim=-1)\n",
    "        g_clinical = self.clinical_gate(gate_input)\n",
    "        g_pastwork = self.pastwork_gate(gate_input)\n",
    "        g_logistics = self.logistics_gate(gate_input)\n",
    "        g_trust = self.trust_gate(gate_input)\n",
    "\n",
    "        gated = torch.cat([\n",
    "            g_clinical * enc_clinical,\n",
    "            g_pastwork * enc_pastwork,\n",
    "            g_logistics * enc_logistics,\n",
    "            g_trust * enc_trust\n",
    "        ], dim=-1)\n",
    "\n",
    "        score = self.scoring_head(gated)\n",
    "\n",
    "        gate_means = {\n",
    "            'clinical': g_clinical.mean(dim=-1),\n",
    "            'pastwork': g_pastwork.mean(dim=-1),\n",
    "            'logistics': g_logistics.mean(dim=-1),\n",
    "            'trust': g_trust.mean(dim=-1)\n",
    "        }\n",
    "\n",
    "        return {\n",
    "            'score': score,\n",
    "            'gate_means': gate_means,\n",
    "            'attention_weights': attn_weights\n",
    "        }\n",
    "\n",
    "    def count_parameters(self):\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "\n",
    "model = DocMatchNetOriginal().to(device)\n",
    "print(f\"Model parameters: {model.count_parameters():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 5: Original Loss Function\n",
    "# ============================================================\n",
    "class DocMatchOriginalLoss(nn.Module):\n",
    "    \"\"\"Pairwise ranking + BCE + gate entropy regularization.\"\"\"\n",
    "\n",
    "    def __init__(self, margin=0.1, lambda_rank=1.0, lambda_bce=1.0, lambda_gate=0.01):\n",
    "        super().__init__()\n",
    "        self.margin = margin\n",
    "        self.lambda_rank = lambda_rank\n",
    "        self.lambda_bce = lambda_bce\n",
    "        self.lambda_gate = lambda_gate\n",
    "\n",
    "    def forward(self, pos_score, neg_score, gate_means):\n",
    "        rank_loss = F.relu(self.margin - (pos_score - neg_score)).mean()\n",
    "\n",
    "        bce_loss = (\n",
    "            F.binary_cross_entropy(pos_score, torch.ones_like(pos_score)) +\n",
    "            F.binary_cross_entropy(neg_score, torch.zeros_like(neg_score))\n",
    "        ) / 2\n",
    "\n",
    "        gate_entropy = 0\n",
    "        eps = 1e-8\n",
    "        for gate_vals in gate_means.values():\n",
    "            entropy = -(gate_vals * torch.log(gate_vals + eps) +\n",
    "                       (1 - gate_vals) * torch.log(1 - gate_vals + eps))\n",
    "            gate_entropy += entropy.mean()\n",
    "        gate_entropy = gate_entropy / len(gate_means)\n",
    "\n",
    "        total_loss = (\n",
    "            self.lambda_rank * rank_loss +\n",
    "            self.lambda_bce * bce_loss +\n",
    "            self.lambda_gate * gate_entropy\n",
    "        )\n",
    "\n",
    "        metrics = {\n",
    "            'total_loss': total_loss.item(),\n",
    "            'rank_loss': rank_loss.item(),\n",
    "            'bce_loss': bce_loss.item(),\n",
    "            'gate_entropy': gate_entropy.item()\n",
    "        }\n",
    "        return total_loss, metrics\n",
    "\n",
    "loss_fn = DocMatchOriginalLoss(margin=0.1, lambda_rank=1.0, lambda_bce=1.0, lambda_gate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 6: Evaluation Function\n",
    "# ============================================================\n",
    "def ndcg_at_k(scores, labels, k):\n",
    "    ranking = np.argsort(-scores)[:k]\n",
    "    dcg = sum((2**labels[r] - 1) / np.log2(i + 2) for i, r in enumerate(ranking))\n",
    "\n",
    "    ideal_ranking = np.argsort(-labels)[:k]\n",
    "    idcg = sum((2**labels[r] - 1) / np.log2(i + 2) for i, r in enumerate(ideal_ranking))\n",
    "    return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "\n",
    "def map_score(scores, labels, threshold=2):\n",
    "    ranking = np.argsort(-scores)\n",
    "    relevant = labels >= threshold\n",
    "\n",
    "    precisions = []\n",
    "    relevant_count = 0\n",
    "    for i, doc_idx in enumerate(ranking):\n",
    "        if relevant[doc_idx]:\n",
    "            relevant_count += 1\n",
    "            precisions.append(relevant_count / (i + 1))\n",
    "\n",
    "    return float(np.mean(precisions)) if precisions else 0.0\n",
    "\n",
    "\n",
    "def mrr_score(scores, labels, threshold=2):\n",
    "    ranking = np.argsort(-scores)\n",
    "    relevant = labels >= threshold\n",
    "    for i, doc_idx in enumerate(ranking):\n",
    "        if relevant[doc_idx]:\n",
    "            return 1.0 / (i + 1)\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def hit_rate_at_k(scores, labels, k, threshold=2):\n",
    "    top_k = np.argsort(-scores)[:k]\n",
    "    relevant = labels >= threshold\n",
    "    return float(relevant[top_k].any())\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "\n",
    "    all_results = {\n",
    "        'ndcg@1': [], 'ndcg@5': [], 'ndcg@10': [],\n",
    "        'map': [], 'mrr': [],\n",
    "        'hr@5': [], 'hr@10': [],\n",
    "        'p@3': [], 'p@5': []\n",
    "    }\n",
    "\n",
    "    context_results = {\n",
    "        'routine': {k: [] for k in all_results},\n",
    "        'complex': {k: [] for k in all_results},\n",
    "        'rare_disease': {k: [] for k in all_results},\n",
    "        'emergency': {k: [] for k in all_results},\n",
    "        'pediatric': {k: [] for k in all_results}\n",
    "    }\n",
    "\n",
    "    gate_activations = {g: [] for g in ['clinical', 'pastwork', 'logistics', 'trust']}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc='Evaluating'):\n",
    "            case_emb = batch['case_embedding'].to(device)\n",
    "            doc_embs = batch['doctor_embeddings'].squeeze(0).to(device)\n",
    "            clinical = batch['clinical'].squeeze(0).to(device)\n",
    "            pastwork = batch['pastwork'].squeeze(0).to(device)\n",
    "            logistics = batch['logistics'].squeeze(0).to(device)\n",
    "            trust = batch['trust'].squeeze(0).to(device)\n",
    "            context = batch['context'].to(device)\n",
    "            relevance = batch['relevance'].squeeze(0).cpu().numpy()\n",
    "            ctx_cat = batch['context_category'][0]\n",
    "\n",
    "            scores = []\n",
    "            for i in range(doc_embs.shape[0]):\n",
    "                output = model(\n",
    "                    case_emb, doc_embs[i:i+1],\n",
    "                    clinical[i:i+1], pastwork[i:i+1],\n",
    "                    logistics[i:i+1], trust[i:i+1],\n",
    "                    context\n",
    "                )\n",
    "                scores.append(output['score'].item())\n",
    "                if i == 0:\n",
    "                    for g_name, g_val in output['gate_means'].items():\n",
    "                        gate_activations[g_name].append(g_val.item())\n",
    "\n",
    "            scores = np.array(scores)\n",
    "            case_metrics = {\n",
    "                'ndcg@1': ndcg_at_k(scores, relevance, 1),\n",
    "                'ndcg@5': ndcg_at_k(scores, relevance, 5),\n",
    "                'ndcg@10': ndcg_at_k(scores, relevance, 10),\n",
    "                'map': map_score(scores, relevance),\n",
    "                'mrr': mrr_score(scores, relevance),\n",
    "                'hr@5': hit_rate_at_k(scores, relevance, 5),\n",
    "                'hr@10': hit_rate_at_k(scores, relevance, 10),\n",
    "                'p@3': float((relevance[np.argsort(-scores)[:3]] >= 2).sum() / 3),\n",
    "                'p@5': float((relevance[np.argsort(-scores)[:5]] >= 2).sum() / 5),\n",
    "            }\n",
    "\n",
    "            for metric, value in case_metrics.items():\n",
    "                all_results[metric].append(value)\n",
    "                if ctx_cat in context_results:\n",
    "                    context_results[ctx_cat][metric].append(value)\n",
    "\n",
    "    results = {k: (float(np.mean(v)), float(np.std(v))) for k, v in all_results.items()}\n",
    "\n",
    "    # Keep stratified compatible with later table code (NDCG@5 only)\n",
    "    stratified = {\n",
    "        ctx: {\n",
    "            'mean': float(np.mean(vals['ndcg@5'])) if vals['ndcg@5'] else 0.0,\n",
    "            'std': float(np.std(vals['ndcg@5'])) if vals['ndcg@5'] else 0.0,\n",
    "        }\n",
    "        for ctx, vals in context_results.items()\n",
    "    }\n",
    "\n",
    "    gate_stats = {\n",
    "        g: {\n",
    "            'mean': float(np.mean(vals)) if vals else 0.0,\n",
    "            'std': float(np.std(vals)) if vals else 0.0,\n",
    "        }\n",
    "        for g, vals in gate_activations.items()\n",
    "    }\n",
    "\n",
    "    return results, stratified, gate_stats, all_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 7: Single-Stage Training Loop\n",
    "# ============================================================\n",
    "EPOCHS = 60\n",
    "LR = 1e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "PATIENCE = 10\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
    "\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'rank_loss': [],\n",
    "    'bce_loss': [],\n",
    "    'gate_entropy': [],\n",
    "    'val_ndcg5': [],\n",
    "    'gate_stats': []\n",
    "}\n",
    "\n",
    "print('=' * 60)\n",
    "print('SINGLE-STAGE TRAINING: DocMatchNet-Original')\n",
    "print('=' * 60)\n",
    "\n",
    "best_ndcg = 0.0\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    epoch_total = 0.0\n",
    "    epoch_rank = 0.0\n",
    "    epoch_bce = 0.0\n",
    "    epoch_gate = 0.0\n",
    "    n_batches = 0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=f'Epoch {epoch}', leave=False):\n",
    "        case_emb = batch['case_embedding'].to(device)\n",
    "        pos_doc = batch['pos_doctor_embedding'].to(device)\n",
    "        neg_doc = batch['neg_doctor_embedding'].to(device)\n",
    "\n",
    "        pos_clinical = batch['pos_clinical'].to(device)\n",
    "        neg_clinical = batch['neg_clinical'].to(device)\n",
    "        pos_pastwork = batch['pos_pastwork'].to(device)\n",
    "        neg_pastwork = batch['neg_pastwork'].to(device)\n",
    "        pos_logistics = batch['pos_logistics'].to(device)\n",
    "        neg_logistics = batch['neg_logistics'].to(device)\n",
    "        pos_trust = batch['pos_trust'].to(device)\n",
    "        neg_trust = batch['neg_trust'].to(device)\n",
    "        context = batch['context'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pos_out = model(case_emb, pos_doc, pos_clinical, pos_pastwork, pos_logistics, pos_trust, context)\n",
    "        neg_out = model(case_emb, neg_doc, neg_clinical, neg_pastwork, neg_logistics, neg_trust, context)\n",
    "\n",
    "        merged_gates = {\n",
    "            key: torch.cat([pos_out['gate_means'][key], neg_out['gate_means'][key]], dim=0)\n",
    "            for key in pos_out['gate_means']\n",
    "        }\n",
    "\n",
    "        loss, metrics = loss_fn(pos_out['score'], neg_out['score'], merged_gates)\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_total += metrics['total_loss']\n",
    "        epoch_rank += metrics['rank_loss']\n",
    "        epoch_bce += metrics['bce_loss']\n",
    "        epoch_gate += metrics['gate_entropy']\n",
    "        n_batches += 1\n",
    "\n",
    "    avg_total = epoch_total / n_batches\n",
    "    avg_rank = epoch_rank / n_batches\n",
    "    avg_bce = epoch_bce / n_batches\n",
    "    avg_gate = epoch_gate / n_batches\n",
    "\n",
    "    history['train_loss'].append(avg_total)\n",
    "    history['rank_loss'].append(avg_rank)\n",
    "    history['bce_loss'].append(avg_bce)\n",
    "    history['gate_entropy'].append(avg_gate)\n",
    "\n",
    "    val_results, stratified, gate_stats, _ = evaluate(model, val_loader, device)\n",
    "    val_ndcg = val_results['ndcg@5'][0]\n",
    "    history['val_ndcg5'].append(val_ndcg)\n",
    "    history['gate_stats'].append(gate_stats)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch}: Loss={avg_total:.4f}, Rank={avg_rank:.4f}, \"\n",
    "        f\"BCE={avg_bce:.4f}, GateEnt={avg_gate:.4f}, Val NDCG@5={val_ndcg:.4f}\"\n",
    "    )\n",
    "\n",
    "    if val_ndcg > best_ndcg:\n",
    "        best_ndcg = val_ndcg\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), f'{RUN_DIR}/best_original_model_seed{SEED}.pt')\n",
    "        print('  -> New best model saved!')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= PATIENCE:\n",
    "            print(f'Early stopping at epoch {epoch}')\n",
    "            break\n",
    "\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 8: Final Evaluation and Save\n",
    "# ============================================================\n",
    "print('\\n' + '=' * 60)\n",
    "print('FINAL EVALUATION ON TEST SET')\n",
    "print('=' * 60)\n",
    "\n",
    "model.load_state_dict(torch.load(f'{RUN_DIR}/best_original_model_seed{SEED}.pt'))\n",
    "\n",
    "test_results, test_stratified, test_gates, test_per_case = evaluate(model, test_loader, device)\n",
    "\n",
    "print('\\nOverall Results:')\n",
    "for metric, (mean, std) in test_results.items():\n",
    "    print(f'  {metric}: {mean:.4f} \u00b1 {std:.4f}')\n",
    "\n",
    "print('\\nStratified Results (NDCG@5):')\n",
    "for ctx, stats in test_stratified.items():\n",
    "    print(f\"  {ctx}: {stats['mean']:.4f} \u00b1 {stats['std']:.4f}\")\n",
    "\n",
    "print('\\nGate Activations:')\n",
    "for gate, stats in test_gates.items():\n",
    "    print(f\"  {gate}: {stats['mean']:.4f} \u00b1 {stats['std']:.4f}\")\n",
    "\n",
    "results = {\n",
    "    'seed': SEED,\n",
    "    'overall': {k: {'mean': v[0], 'std': v[1]} for k, v in test_results.items()},\n",
    "    'stratified': test_stratified,\n",
    "    'gate_stats': test_gates,\n",
    "    'per_case': test_per_case,\n",
    "    'history': history\n",
    "}\n",
    "\n",
    "with open(f'{RUN_DIR}/original_seed{SEED}_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"\\n\u2705 Results saved to {RUN_DIR}/original_seed{SEED}_results.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 9: Visualizations\n",
    "# ============================================================\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "ax = axes[0, 0]\n",
    "ax.plot(history['train_loss'])\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Total Loss')\n",
    "ax.set_title('Training Loss')\n",
    "\n",
    "ax = axes[0, 1]\n",
    "ax.plot(history['rank_loss'], label='Rank')\n",
    "ax.plot(history['bce_loss'], label='BCE')\n",
    "ax.plot(history['gate_entropy'], label='Gate Entropy')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss Components')\n",
    "ax.set_title('Loss Decomposition')\n",
    "ax.legend()\n",
    "\n",
    "ax = axes[1, 0]\n",
    "ax.plot(history['val_ndcg5'])\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('NDCG@5')\n",
    "ax.set_title('Validation NDCG@5')\n",
    "\n",
    "ax = axes[1, 1]\n",
    "gates = ['clinical', 'pastwork', 'logistics', 'trust']\n",
    "x = np.arange(len(gates))\n",
    "ax.bar(x, [test_gates[g]['mean'] for g in gates])\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(gates, rotation=45)\n",
    "ax.set_ylabel('Mean Activation')\n",
    "ax.set_title('Gate Activations')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{RUN_DIR}/original_seed{SEED}_training_curves.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print('\\n\u2705 Training complete!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}