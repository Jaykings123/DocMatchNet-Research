{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DocMatchNet-JEPA Ablation Studies\n",
    "=================================\n",
    "Test contribution of each component across seeds `[42, 123, 456]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 1: Setup\n",
    "# ============================================================\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name()}')\n",
    "\n",
    "os.makedirs('/kaggle/working/results', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 2: Load Data\n",
    "# ============================================================\n",
    "DATA_DIR = '/kaggle/input/docmatchnet-jepa-data/data'\n",
    "\n",
    "doctor_embeddings = torch.load(f'{DATA_DIR}/doctor_embeddings.pt', weights_only=False)\n",
    "case_embeddings = torch.load(f'{DATA_DIR}/case_embeddings.pt', weights_only=False)\n",
    "clinical_features = torch.load(f'{DATA_DIR}/clinical_features.pt', weights_only=False)\n",
    "pastwork_features = torch.load(f'{DATA_DIR}/pastwork_features.pt', weights_only=False)\n",
    "logistics_features = torch.load(f'{DATA_DIR}/logistics_features.pt', weights_only=False)\n",
    "trust_features = torch.load(f'{DATA_DIR}/trust_features.pt', weights_only=False)\n",
    "context_features = torch.load(f'{DATA_DIR}/context_features.pt', weights_only=False)\n",
    "relevance_labels = torch.load(f'{DATA_DIR}/relevance_labels.pt', weights_only=False)\n",
    "doctor_indices = torch.load(f'{DATA_DIR}/doctor_indices.pt', weights_only=False)\n",
    "case_metadata = torch.load(f'{DATA_DIR}/case_metadata.pt', weights_only=False)\n",
    "splits = torch.load(f'{DATA_DIR}/splits.pt', weights_only=False)\n",
    "\n",
    "print('Loaded data successfully')\n",
    "print(f\"Train/Val/Test: {len(splits['train'])}/{len(splits['val'])}/{len(splits['test'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 3: Datasets\n",
    "# ============================================================\n",
    "class AblationTrainDataset(Dataset):\n",
    "    def __init__(self, indices, case_emb, doc_emb, doc_indices, clinical, pastwork, logistics, trust, context, relevance):\n",
    "        self.indices = indices\n",
    "        self.case_emb = case_emb\n",
    "        self.doc_emb = doc_emb\n",
    "        self.doc_indices = doc_indices\n",
    "        self.clinical = clinical\n",
    "        self.pastwork = pastwork\n",
    "        self.logistics = logistics\n",
    "        self.trust = trust\n",
    "        self.context = context\n",
    "        self.relevance = relevance\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        case_idx = self.indices[idx]\n",
    "        rel = self.relevance[case_idx]\n",
    "\n",
    "        pos_mask = rel >= 3\n",
    "        if pos_mask.sum() == 0:\n",
    "            pos_mask = rel == rel.max()\n",
    "\n",
    "        neg_mask = rel <= 1\n",
    "        if neg_mask.sum() == 0:\n",
    "            neg_mask = rel < rel.max()\n",
    "\n",
    "        hard_neg_mask = rel == 2\n",
    "\n",
    "        pos_pool = torch.where(pos_mask)[0]\n",
    "        neg_pool = torch.where(neg_mask)[0]\n",
    "        hard_pool = torch.where(hard_neg_mask)[0]\n",
    "\n",
    "        pos_local = pos_pool[torch.randint(len(pos_pool), (1,))].item()\n",
    "\n",
    "        if len(hard_pool) > 0 and torch.rand(1).item() < 0.2:\n",
    "            neg_local = hard_pool[torch.randint(len(hard_pool), (1,))].item()\n",
    "        else:\n",
    "            neg_local = neg_pool[torch.randint(len(neg_pool), (1,))].item()\n",
    "\n",
    "        pos_global = self.doc_indices[case_idx, pos_local]\n",
    "        neg_global = self.doc_indices[case_idx, neg_local]\n",
    "\n",
    "        return {\n",
    "            'case_embedding': self.case_emb[case_idx],\n",
    "            'pos_doctor_embedding': self.doc_emb[pos_global],\n",
    "            'neg_doctor_embedding': self.doc_emb[neg_global],\n",
    "            'pos_clinical': self.clinical[case_idx, pos_local],\n",
    "            'neg_clinical': self.clinical[case_idx, neg_local],\n",
    "            'pos_pastwork': self.pastwork[case_idx, pos_local],\n",
    "            'neg_pastwork': self.pastwork[case_idx, neg_local],\n",
    "            'pos_logistics': self.logistics[case_idx, pos_local],\n",
    "            'neg_logistics': self.logistics[case_idx, neg_local],\n",
    "            'pos_trust': self.trust[case_idx, pos_local],\n",
    "            'neg_trust': self.trust[case_idx, neg_local],\n",
    "            'context': self.context[case_idx]\n",
    "        }\n",
    "\n",
    "class AblationEvalDataset(Dataset):\n",
    "    def __init__(self, indices, case_emb, doc_emb, doc_indices, clinical, pastwork, logistics, trust, context, relevance):\n",
    "        self.indices = indices\n",
    "        self.case_emb = case_emb\n",
    "        self.doc_emb = doc_emb\n",
    "        self.doc_indices = doc_indices\n",
    "        self.clinical = clinical\n",
    "        self.pastwork = pastwork\n",
    "        self.logistics = logistics\n",
    "        self.trust = trust\n",
    "        self.context = context\n",
    "        self.relevance = relevance\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        case_idx = self.indices[idx]\n",
    "        global_docs = self.doc_indices[case_idx]\n",
    "        return {\n",
    "            'case_embedding': self.case_emb[case_idx],\n",
    "            'doctor_embeddings': self.doc_emb[global_docs],\n",
    "            'clinical': self.clinical[case_idx],\n",
    "            'pastwork': self.pastwork[case_idx],\n",
    "            'logistics': self.logistics[case_idx],\n",
    "            'trust': self.trust[case_idx],\n",
    "            'context': self.context[case_idx],\n",
    "            'relevance': self.relevance[case_idx]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 4: Model + Losses + Metrics\n",
    "# ============================================================\n",
    "class DocMatchNetJEPA(nn.Module):\n",
    "    def __init__(self, embed_dim=384, latent_dim=256, gate_dim=32, context_dim=8, dropout=0.1, no_gates=False):\n",
    "        super().__init__()\n",
    "        self.gate_dim = gate_dim\n",
    "        self.no_gates = no_gates\n",
    "\n",
    "        self.patient_encoder = nn.Sequential(\n",
    "            nn.Linear(embed_dim, 512), nn.LayerNorm(512), nn.GELU(), nn.Dropout(dropout),\n",
    "            nn.Linear(512, latent_dim), nn.LayerNorm(latent_dim)\n",
    "        )\n",
    "        self.doctor_encoder = nn.Sequential(\n",
    "            nn.Linear(embed_dim, 512), nn.LayerNorm(512), nn.GELU(), nn.Dropout(dropout),\n",
    "            nn.Linear(512, latent_dim), nn.LayerNorm(latent_dim)\n",
    "        )\n",
    "\n",
    "        self.clinical_encoder = self._make_encoder(4, gate_dim)\n",
    "        self.pastwork_encoder = self._make_encoder(5, gate_dim)\n",
    "        self.logistics_encoder = self._make_encoder(5, gate_dim)\n",
    "        self.trust_encoder = self._make_encoder(3, gate_dim)\n",
    "\n",
    "        gate_input_dim = latent_dim + context_dim\n",
    "        self.clinical_gate = self._make_gate(gate_input_dim, gate_dim)\n",
    "        self.pastwork_gate = self._make_gate(gate_input_dim, gate_dim)\n",
    "        self.logistics_gate = self._make_gate(gate_input_dim, gate_dim)\n",
    "        self.trust_gate = self._make_gate(gate_input_dim, gate_dim)\n",
    "        self._init_gate_biases()\n",
    "\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(latent_dim + gate_dim * 4, 256),\n",
    "            nn.LayerNorm(256), nn.GELU(), nn.Dropout(dropout),\n",
    "            nn.Linear(256, 256), nn.LayerNorm(256), nn.GELU(), nn.Dropout(dropout),\n",
    "            nn.Linear(256, latent_dim)\n",
    "        )\n",
    "\n",
    "        self.predictor_proj = nn.Sequential(nn.Linear(latent_dim, latent_dim), nn.GELU(), nn.Linear(latent_dim, 128))\n",
    "        self.doctor_proj = nn.Sequential(nn.Linear(latent_dim, latent_dim), nn.GELU(), nn.Linear(latent_dim, 128))\n",
    "        self.log_temperature = nn.Parameter(torch.log(torch.tensor(0.07)))\n",
    "\n",
    "    def _make_encoder(self, in_d, out_d):\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(in_d, out_d), nn.BatchNorm1d(out_d), nn.GELU(),\n",
    "            nn.Linear(out_d, out_d), nn.BatchNorm1d(out_d), nn.GELU()\n",
    "        )\n",
    "\n",
    "    def _make_gate(self, in_d, out_d):\n",
    "        return nn.Sequential(nn.Linear(in_d, 64), nn.GELU(), nn.Linear(64, out_d), nn.Sigmoid())\n",
    "\n",
    "    def _init_gate_biases(self):\n",
    "        nn.init.constant_(self.clinical_gate[-2].bias, 0.4)\n",
    "        nn.init.constant_(self.pastwork_gate[-2].bias, 0.0)\n",
    "        nn.init.constant_(self.logistics_gate[-2].bias, 0.0)\n",
    "        nn.init.constant_(self.trust_gate[-2].bias, -0.4)\n",
    "\n",
    "    def compute_gates(self, patient_latent, context):\n",
    "        if self.no_gates:\n",
    "            batch = patient_latent.shape[0]\n",
    "            g = torch.full((batch, self.gate_dim), 0.5, device=patient_latent.device, dtype=patient_latent.dtype)\n",
    "            return {'clinical': g, 'pastwork': g, 'logistics': g, 'trust': g}\n",
    "        gate_input = torch.cat([patient_latent, context], dim=-1)\n",
    "        return {\n",
    "            'clinical': self.clinical_gate(gate_input),\n",
    "            'pastwork': self.pastwork_gate(gate_input),\n",
    "            'logistics': self.logistics_gate(gate_input),\n",
    "            'trust': self.trust_gate(gate_input)\n",
    "        }\n",
    "\n",
    "    def forward(self, patient_emb, doctor_emb, clinical, pastwork, logistics, trust, context):\n",
    "        patient_latent = self.patient_encoder(patient_emb)\n",
    "        doctor_latent = self.doctor_encoder(doctor_emb)\n",
    "\n",
    "        enc_clinical = self.clinical_encoder(clinical)\n",
    "        enc_pastwork = self.pastwork_encoder(pastwork)\n",
    "        enc_logistics = self.logistics_encoder(logistics)\n",
    "        enc_trust = self.trust_encoder(trust)\n",
    "\n",
    "        gates = self.compute_gates(patient_latent, context)\n",
    "\n",
    "        gated = torch.cat([\n",
    "            gates['clinical'] * enc_clinical,\n",
    "            gates['pastwork'] * enc_pastwork,\n",
    "            gates['logistics'] * enc_logistics,\n",
    "            gates['trust'] * enc_trust\n",
    "        ], dim=-1)\n",
    "\n",
    "        pred = self.predictor(torch.cat([patient_latent, gated], dim=-1))\n",
    "        pred_proj = self.predictor_proj(pred)\n",
    "        doc_proj = self.doctor_proj(doctor_latent)\n",
    "\n",
    "        p = F.normalize(pred_proj, dim=-1)\n",
    "        d = F.normalize(doc_proj, dim=-1)\n",
    "        score = ((p * d).sum(dim=-1, keepdim=True) + 1) / 2\n",
    "\n",
    "        return {\n",
    "            'score': score,\n",
    "            'predicted_ideal': pred_proj,\n",
    "            'doctor_embedding': doc_proj,\n",
    "            'temperature': self.log_temperature.exp(),\n",
    "            'gates': gates\n",
    "        }\n",
    "\n",
    "    def get_parameter_groups(self, base_lr, doctor_lr_mult=0.05):\n",
    "        doc_params = list(self.doctor_encoder.parameters()) + list(self.doctor_proj.parameters())\n",
    "        doc_ids = set(id(p) for p in doc_params)\n",
    "        other = [p for p in self.parameters() if id(p) not in doc_ids]\n",
    "        return [\n",
    "            {'params': other, 'lr': base_lr},\n",
    "            {'params': doc_params, 'lr': base_lr * doctor_lr_mult}\n",
    "        ]\n",
    "\n",
    "def infonce_loss(pred, target, temperature):\n",
    "    p = F.normalize(pred, dim=-1)\n",
    "    t = F.normalize(target, dim=-1)\n",
    "    logits = p @ t.T / torch.clamp(temperature, min=1e-8)\n",
    "    labels = torch.arange(logits.shape[0], device=logits.device)\n",
    "    return (F.cross_entropy(logits, labels) + F.cross_entropy(logits.T, labels)) / 2\n",
    "\n",
    "def mse_loss(pred, target):\n",
    "    return F.mse_loss(pred, target)\n",
    "\n",
    "def ranking_loss(pos_score, neg_score, margin=0.1):\n",
    "    return F.relu(margin - (pos_score - neg_score)).mean()\n",
    "\n",
    "def vicreg_gate_loss(gates_dict):\n",
    "    total = 0.0\n",
    "    for gate_vals in gates_dict.values():\n",
    "        var = F.relu(1.0 - gate_vals.var(dim=0, unbiased=False)).mean()\n",
    "        centered = gate_vals - gate_vals.mean(dim=0, keepdim=True)\n",
    "        if gate_vals.shape[0] > 1 and gate_vals.shape[1] > 1:\n",
    "            cov = (centered.T @ centered) / (gate_vals.shape[0] - 1)\n",
    "            off = cov - torch.diag(torch.diag(cov))\n",
    "            cov_loss = off.pow(2).mean()\n",
    "        else:\n",
    "            cov_loss = torch.tensor(0.0, device=gate_vals.device)\n",
    "        total = total + var + 0.1 * cov_loss\n",
    "    return total / len(gates_dict)\n",
    "\n",
    "def map_score(scores, labels, threshold=2):\n",
    "    order = np.argsort(-scores)\n",
    "    relevant = labels >= threshold\n",
    "    precisions = []\n",
    "    rel_count = 0\n",
    "    for i, idx in enumerate(order):\n",
    "        if relevant[idx]:\n",
    "            rel_count += 1\n",
    "            precisions.append(rel_count / (i + 1))\n",
    "    return float(np.mean(precisions)) if len(precisions) else 0.0\n",
    "\n",
    "def mrr_score(scores, labels, threshold=2):\n",
    "    order = np.argsort(-scores)\n",
    "    relevant = labels >= threshold\n",
    "    for i, idx in enumerate(order):\n",
    "        if relevant[idx]:\n",
    "            return 1.0 / (i + 1)\n",
    "    return 0.0\n",
    "\n",
    "def ndcg_at_k(scores, labels, k=5):\n",
    "    order = np.argsort(-scores)[:k]\n",
    "    dcg = sum((2**labels[i] - 1) / np.log2(rank + 2) for rank, i in enumerate(order))\n",
    "    ideal = np.argsort(-labels)[:k]\n",
    "    idcg = sum((2**labels[i] - 1) / np.log2(rank + 2) for rank, i in enumerate(ideal))\n",
    "    return float(dcg / idcg) if idcg > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 5: Training + Evaluation Runner\n",
    "# ============================================================\n",
    "BASE_CFG = {\n",
    "    'stage1_epochs': 10,\n",
    "    'stage2_epochs': 20,\n",
    "    'single_stage_epochs': 30,\n",
    "    'batch_size': 128,\n",
    "    'lr': 1e-4,\n",
    "    'weight_decay': 1e-5,\n",
    "    'doctor_lr_mult': 0.05,\n",
    "    'lambda_gate': 0.05,\n",
    "    'patience': 6,\n",
    "    'loss_type': 'infonce',\n",
    "    'two_stage': True,\n",
    "    'gate_dim': 32,\n",
    "    'no_gates': False\n",
    "}\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def build_loaders(seed, batch_size):\n",
    "    train_ds = AblationTrainDataset(\n",
    "        splits['train'], case_embeddings, doctor_embeddings, doctor_indices,\n",
    "        clinical_features, pastwork_features, logistics_features, trust_features,\n",
    "        context_features, relevance_labels\n",
    "    )\n",
    "    val_ds = AblationEvalDataset(\n",
    "        splits['val'], case_embeddings, doctor_embeddings, doctor_indices,\n",
    "        clinical_features, pastwork_features, logistics_features, trust_features,\n",
    "        context_features, relevance_labels\n",
    "    )\n",
    "    test_ds = AblationEvalDataset(\n",
    "        splits['test'], case_embeddings, doctor_embeddings, doctor_indices,\n",
    "        clinical_features, pastwork_features, logistics_features, trust_features,\n",
    "        context_features, relevance_labels\n",
    "    )\n",
    "\n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(seed)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2, generator=g)\n",
    "    val_loader = DataLoader(val_ds, batch_size=1, shuffle=False)\n",
    "    test_loader = DataLoader(test_ds, batch_size=1, shuffle=False)\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "def evaluate_model(model, loader):\n",
    "    model.eval()\n",
    "    ndcg5_vals, map_vals, mrr_vals = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            case_emb = batch['case_embedding'].to(device)\n",
    "            docs = batch['doctor_embeddings'].squeeze(0).to(device)\n",
    "            clinical = batch['clinical'].squeeze(0).to(device)\n",
    "            pastwork = batch['pastwork'].squeeze(0).to(device)\n",
    "            logistics = batch['logistics'].squeeze(0).to(device)\n",
    "            trust = batch['trust'].squeeze(0).to(device)\n",
    "            context = batch['context'].to(device)\n",
    "            labels = batch['relevance'].squeeze(0).cpu().numpy()\n",
    "\n",
    "            scores = []\n",
    "            for i in range(docs.shape[0]):\n",
    "                out = model(case_emb, docs[i:i+1], clinical[i:i+1], pastwork[i:i+1], logistics[i:i+1], trust[i:i+1], context)\n",
    "                scores.append(out['score'].item())\n",
    "            scores = np.array(scores)\n",
    "\n",
    "            ndcg5_vals.append(ndcg_at_k(scores, labels, 5))\n",
    "            map_vals.append(map_score(scores, labels))\n",
    "            mrr_vals.append(mrr_score(scores, labels))\n",
    "\n",
    "    return {\n",
    "        'ndcg@5': float(np.mean(ndcg5_vals)),\n",
    "        'map': float(np.mean(map_vals)),\n",
    "        'mrr': float(np.mean(mrr_vals))\n",
    "    }\n",
    "\n",
    "def train_with_config(cfg, seed):\n",
    "    set_seed(seed)\n",
    "    train_loader, val_loader, test_loader = build_loaders(seed, cfg['batch_size'])\n",
    "\n",
    "    model = DocMatchNetJEPA(gate_dim=cfg['gate_dim'], no_gates=cfg['no_gates']).to(device)\n",
    "    groups = model.get_parameter_groups(cfg['lr'], doctor_lr_mult=cfg['doctor_lr_mult'])\n",
    "    optimizer = AdamW(groups, weight_decay=cfg['weight_decay'])\n",
    "    scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
    "\n",
    "    best_state = None\n",
    "    best_val = -1.0\n",
    "    patience_counter = 0\n",
    "\n",
    "    def train_epoch(epoch_idx):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        n = 0\n",
    "        for batch in tqdm(train_loader, desc=f'Seed {seed} Epoch {epoch_idx}', leave=False):\n",
    "            case_emb = batch['case_embedding'].to(device)\n",
    "            pos_doc = batch['pos_doctor_embedding'].to(device)\n",
    "            neg_doc = batch['neg_doctor_embedding'].to(device)\n",
    "            pos_c = batch['pos_clinical'].to(device)\n",
    "            neg_c = batch['neg_clinical'].to(device)\n",
    "            pos_p = batch['pos_pastwork'].to(device)\n",
    "            neg_p = batch['neg_pastwork'].to(device)\n",
    "            pos_l = batch['pos_logistics'].to(device)\n",
    "            neg_l = batch['neg_logistics'].to(device)\n",
    "            pos_t = batch['pos_trust'].to(device)\n",
    "            neg_t = batch['neg_trust'].to(device)\n",
    "            context = batch['context'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            pos_out = model(case_emb, pos_doc, pos_c, pos_p, pos_l, pos_t, context)\n",
    "            neg_out = model(case_emb, neg_doc, neg_c, neg_p, neg_l, neg_t, context)\n",
    "\n",
    "            if cfg['loss_type'] == 'infonce':\n",
    "                core = infonce_loss(pos_out['predicted_ideal'], pos_out['doctor_embedding'], pos_out['temperature'])\n",
    "            elif cfg['loss_type'] == 'mse':\n",
    "                core = mse_loss(pos_out['predicted_ideal'], pos_out['doctor_embedding'])\n",
    "            elif cfg['loss_type'] == 'ranking':\n",
    "                core = ranking_loss(pos_out['score'], neg_out['score'])\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown loss_type: {cfg['loss_type']}\")\n",
    "\n",
    "            gate_reg = vicreg_gate_loss(pos_out['gates'])\n",
    "            loss = core + cfg['lambda_gate'] * gate_reg\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            n += 1\n",
    "\n",
    "        scheduler.step()\n",
    "        return total_loss / max(n, 1)\n",
    "\n",
    "    if cfg['two_stage']:\n",
    "        for name, p in model.named_parameters():\n",
    "            if 'gate' in name:\n",
    "                p.requires_grad = False\n",
    "\n",
    "        for ep in range(cfg['stage1_epochs']):\n",
    "            train_epoch(ep)\n",
    "\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "        for ep in range(cfg['stage2_epochs']):\n",
    "            train_epoch(cfg['stage1_epochs'] + ep)\n",
    "            val_metrics = evaluate_model(model, val_loader)\n",
    "            v = val_metrics['ndcg@5']\n",
    "            if v > best_val:\n",
    "                best_val = v\n",
    "                best_state = {k: t.detach().cpu().clone() for k, t in model.state_dict().items()}\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= cfg['patience']:\n",
    "                    break\n",
    "    else:\n",
    "        for ep in range(cfg['single_stage_epochs']):\n",
    "            train_epoch(ep)\n",
    "            val_metrics = evaluate_model(model, val_loader)\n",
    "            v = val_metrics['ndcg@5']\n",
    "            if v > best_val:\n",
    "                best_val = v\n",
    "                best_state = {k: t.detach().cpu().clone() for k, t in model.state_dict().items()}\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= cfg['patience']:\n",
    "                    break\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    return evaluate_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 6: Define Ablations and Run\n",
    "# ============================================================\n",
    "SEEDS = [42, 123, 456]\n",
    "\n",
    "ABLATIONS = {\n",
    "    'full_docmatchnet_jepa': {},\n",
    "    'no_gates': {'no_gates': True},\n",
    "    'no_twostage': {'two_stage': False},\n",
    "    'mse_loss': {'loss_type': 'mse'},\n",
    "    'ranking_loss': {'loss_type': 'ranking'},\n",
    "    'symmetric_lr': {'doctor_lr_mult': 1.0},\n",
    "    'no_vicreg': {'lambda_gate': 0.0},\n",
    "    'gate_dim_16': {'gate_dim': 16},\n",
    "    'gate_dim_64': {'gate_dim': 64}\n",
    "}\n",
    "\n",
    "ablation_results = {}\n",
    "\n",
    "for ablation_name, override in ABLATIONS.items():\n",
    "    print('\\n' + '=' * 70)\n",
    "    print(f'Running ablation: {ablation_name}')\n",
    "    print('=' * 70)\n",
    "\n",
    "    cfg = copy.deepcopy(BASE_CFG)\n",
    "    cfg.update(override)\n",
    "\n",
    "    ndcg_runs, map_runs, mrr_runs, time_runs = [], [], [], []\n",
    "\n",
    "    for seed in SEEDS:\n",
    "        print(f'  Seed: {seed}')\n",
    "        start = time.time()\n",
    "        metrics = train_with_config(cfg, seed)\n",
    "        elapsed_min = (time.time() - start) / 60.0\n",
    "\n",
    "        ndcg_runs.append(float(metrics['ndcg@5']))\n",
    "        map_runs.append(float(metrics['map']))\n",
    "        mrr_runs.append(float(metrics['mrr']))\n",
    "        time_runs.append(float(elapsed_min))\n",
    "\n",
    "        print(f\"    NDCG@5={metrics['ndcg@5']:.4f}, MAP={metrics['map']:.4f}, MRR={metrics['mrr']:.4f}, Time={elapsed_min:.1f} min\")\n",
    "\n",
    "    ablation_results[ablation_name] = {\n",
    "        'ndcg@5': {\n",
    "            'mean': float(np.mean(ndcg_runs)),\n",
    "            'std': float(np.std(ndcg_runs)),\n",
    "            'runs': ndcg_runs\n",
    "        },\n",
    "        'map': {\n",
    "            'mean': float(np.mean(map_runs)),\n",
    "            'std': float(np.std(map_runs)),\n",
    "            'runs': map_runs\n",
    "        },\n",
    "        'mrr': {\n",
    "            'mean': float(np.mean(mrr_runs)),\n",
    "            'std': float(np.std(mrr_runs)),\n",
    "            'runs': mrr_runs\n",
    "        },\n",
    "        'training_time_min': float(np.mean(time_runs))\n",
    "    }\n",
    "\n",
    "print('\\nAblation runs complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 7: Save Results\n",
    "# ============================================================\n",
    "out_path = '/kaggle/working/results/ablation_results.json'\n",
    "with open(out_path, 'w') as f:\n",
    "    json.dump(ablation_results, f, indent=2)\n",
    "\n",
    "print(f'Saved: {out_path}')\n",
    "print('\\nSummary (NDCG@5 mean \u00b1 std):')\n",
    "for name, metrics in ablation_results.items():\n",
    "    print(f\"  {name}: {metrics['ndcg@5']['mean']:.4f} \u00b1 {metrics['ndcg@5']['std']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}