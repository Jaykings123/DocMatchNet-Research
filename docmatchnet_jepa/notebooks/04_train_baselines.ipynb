{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14828461,"sourceType":"datasetVersion","datasetId":9483689,"isSourceIdPinned":true}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"72c25e82-bc7f-453c-bbf5-a72aab37e848","cell_type":"markdown","source":"# Baseline Training and Evaluation\n===============================\nTrain and evaluate: StaticMCDA, SimpleMLP, NeuralRanker, DINModel\n\nGPU Recommended for neural baselines","metadata":{}},{"id":"60d2247e-4d6f-4c89-9fff-0080ea3ba8db","cell_type":"code","source":"# ============================================================\n# CELL 1: Setup\n# ============================================================\nimport os\nimport json\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import AdamW\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\nfrom tqdm import tqdm\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f'Using device: {device}')\nif torch.cuda.is_available():\n    print(f'GPU: {torch.cuda.get_device_name()}')\n\ntorch.manual_seed(42)\nnp.random.seed(42)\n\nos.makedirs('/kaggle/working/results', exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T05:18:11.741518Z","iopub.execute_input":"2026-02-16T05:18:11.742040Z","iopub.status.idle":"2026-02-16T05:18:18.720807Z","shell.execute_reply.started":"2026-02-16T05:18:11.742013Z","shell.execute_reply":"2026-02-16T05:18:18.720178Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nGPU: Tesla T4\n","output_type":"stream"}],"execution_count":1},{"id":"d5a614a8-5eb1-40e0-ab95-abd8eef4f2f0","cell_type":"code","source":"# ============================================================\n# CELL 2: Load Data\n# ============================================================\nDATA_DIR = '/kaggle/input/docmatchnet-jepa-data/data'\n\ndoctor_embeddings = torch.load(f'{DATA_DIR}/doctor_embeddings.pt', weights_only=False)\ncase_embeddings = torch.load(f'{DATA_DIR}/case_embeddings.pt', weights_only=False)\nclinical_features = torch.load(f'{DATA_DIR}/clinical_features.pt', weights_only=False)\npastwork_features = torch.load(f'{DATA_DIR}/pastwork_features.pt', weights_only=False)\nlogistics_features = torch.load(f'{DATA_DIR}/logistics_features.pt', weights_only=False)\ntrust_features = torch.load(f'{DATA_DIR}/trust_features.pt', weights_only=False)\ncontext_features = torch.load(f'{DATA_DIR}/context_features.pt', weights_only=False)\nrelevance_labels = torch.load(f'{DATA_DIR}/relevance_labels.pt', weights_only=False)\ndoctor_indices = torch.load(f'{DATA_DIR}/doctor_indices.pt', weights_only=False)\nsplits = torch.load(f'{DATA_DIR}/splits.pt', weights_only=False)\ncase_metadata = torch.load(f'{DATA_DIR}/case_metadata.pt', weights_only=False)\n\nprint('Loaded tensors successfully')\nprint(f\"Train/Val/Test: {len(splits['train'])}/{len(splits['val'])}/{len(splits['test'])}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T05:18:27.974286Z","iopub.execute_input":"2026-02-16T05:18:27.974740Z","iopub.status.idle":"2026-02-16T05:18:29.936129Z","shell.execute_reply.started":"2026-02-16T05:18:27.974710Z","shell.execute_reply":"2026-02-16T05:18:29.935415Z"}},"outputs":[{"name":"stdout","text":"Loaded tensors successfully\nTrain/Val/Test: 10500/2250/2250\n","output_type":"stream"}],"execution_count":2},{"id":"4a1e8294-6500-43c3-850f-4d84712b3e9f","cell_type":"code","source":"# ============================================================\n# CELL 3: Datasets\n# ============================================================\nclass PairwiseBaselineDataset(Dataset):\n    def __init__(self, indices, case_emb, doc_emb, doc_indices, clinical, pastwork, logistics, trust, context, relevance):\n        self.indices = indices\n        self.case_emb = case_emb\n        self.doc_emb = doc_emb\n        self.doc_indices = doc_indices\n        self.clinical = clinical\n        self.pastwork = pastwork\n        self.logistics = logistics\n        self.trust = trust\n        self.context = context\n        self.relevance = relevance\n\n    def __len__(self):\n        return len(self.indices)\n\n    def __getitem__(self, idx):\n        case_idx = self.indices[idx]\n        rel = self.relevance[case_idx]\n\n        pos_mask = rel >= 3\n        if pos_mask.sum() == 0:\n            pos_mask = rel == rel.max()\n\n        neg_mask = rel <= 1\n        if neg_mask.sum() == 0:\n            neg_mask = rel < rel.max()\n\n        pos_pool = torch.where(pos_mask)[0]\n        neg_pool = torch.where(neg_mask)[0]\n\n        pos_local = pos_pool[torch.randint(len(pos_pool), (1,))].item()\n        neg_local = neg_pool[torch.randint(len(neg_pool), (1,))].item()\n\n        pos_global = self.doc_indices[case_idx, pos_local]\n        neg_global = self.doc_indices[case_idx, neg_local]\n\n        return {\n            'case_embedding': self.case_emb[case_idx],\n            'pos_doctor_embedding': self.doc_emb[pos_global],\n            'neg_doctor_embedding': self.doc_emb[neg_global],\n            'pos_clinical': self.clinical[case_idx, pos_local],\n            'neg_clinical': self.clinical[case_idx, neg_local],\n            'pos_pastwork': self.pastwork[case_idx, pos_local],\n            'neg_pastwork': self.pastwork[case_idx, neg_local],\n            'pos_logistics': self.logistics[case_idx, pos_local],\n            'neg_logistics': self.logistics[case_idx, neg_local],\n            'pos_trust': self.trust[case_idx, pos_local],\n            'neg_trust': self.trust[case_idx, neg_local],\n            'context': self.context[case_idx]\n        }\n\nclass EvalDataset(Dataset):\n    def __init__(self, indices, case_emb, doc_emb, doc_indices, clinical, pastwork, logistics, trust, context, relevance, metadata):\n        self.indices = indices\n        self.case_emb = case_emb\n        self.doc_emb = doc_emb\n        self.doc_indices = doc_indices\n        self.clinical = clinical\n        self.pastwork = pastwork\n        self.logistics = logistics\n        self.trust = trust\n        self.context = context\n        self.relevance = relevance\n        self.metadata = metadata\n\n    def __len__(self):\n        return len(self.indices)\n\n    def __getitem__(self, idx):\n        case_idx = self.indices[idx]\n        global_docs = self.doc_indices[case_idx]\n        return {\n            'case_embedding': self.case_emb[case_idx],\n            'doctor_embeddings': self.doc_emb[global_docs],\n            'clinical': self.clinical[case_idx],\n            'pastwork': self.pastwork[case_idx],\n            'logistics': self.logistics[case_idx],\n            'trust': self.trust[case_idx],\n            'context': self.context[case_idx],\n            'relevance': self.relevance[case_idx],\n            'context_category': self.metadata['context_category'][case_idx]\n        }\n\ntrain_ds = PairwiseBaselineDataset(\n    splits['train'], case_embeddings, doctor_embeddings, doctor_indices,\n    clinical_features, pastwork_features, logistics_features, trust_features,\n    context_features, relevance_labels\n)\nval_ds = EvalDataset(\n    splits['val'], case_embeddings, doctor_embeddings, doctor_indices,\n    clinical_features, pastwork_features, logistics_features, trust_features,\n    context_features, relevance_labels, case_metadata\n)\ntest_ds = EvalDataset(\n    splits['test'], case_embeddings, doctor_embeddings, doctor_indices,\n    clinical_features, pastwork_features, logistics_features, trust_features,\n    context_features, relevance_labels, case_metadata\n)\n\ntrain_loader = DataLoader(train_ds, batch_size=128, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_ds, batch_size=1, shuffle=False)\ntest_loader = DataLoader(test_ds, batch_size=1, shuffle=False)\n\nprint(f'Train batches: {len(train_loader)}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T05:18:52.618599Z","iopub.execute_input":"2026-02-16T05:18:52.619191Z","iopub.status.idle":"2026-02-16T05:18:52.632647Z","shell.execute_reply.started":"2026-02-16T05:18:52.619162Z","shell.execute_reply":"2026-02-16T05:18:52.631833Z"}},"outputs":[{"name":"stdout","text":"Train batches: 83\n","output_type":"stream"}],"execution_count":3},{"id":"d621a5a6-b25e-4c59-a6db-e45c6e5bd7ca","cell_type":"code","source":"# ============================================================\n# CELL 4: Baseline Models\n# ============================================================\nclass StaticMCDA:\n    def __init__(self):\n        self.weights = {'clinical': 0.40, 'pastwork': 0.25, 'logistics': 0.25, 'trust': 0.10}\n        self.clinical_weights = [0.55, 0.20, 0.15, 0.10]\n        self.pastwork_weights = [0.30, 0.25, 0.20, 0.15, 0.10]\n        self.logistics_weights = [0.30, 0.25, 0.20, 0.15, 0.10]\n        self.trust_weights = [0.50, 0.30, 0.20]\n\n    def score(self, clinical, pastwork, logistics, trust):\n        c_w = torch.tensor(self.clinical_weights, dtype=clinical.dtype, device=clinical.device)\n        p_w = torch.tensor(self.pastwork_weights, dtype=pastwork.dtype, device=pastwork.device)\n        l_w = torch.tensor(self.logistics_weights, dtype=logistics.dtype, device=logistics.device)\n        t_w = torch.tensor(self.trust_weights, dtype=trust.dtype, device=trust.device)\n\n        c_score = (clinical * c_w).sum(-1)\n        p_score = (pastwork * p_w).sum(-1)\n        l_score = (logistics * l_w).sum(-1)\n        t_score = (trust * t_w).sum(-1)\n\n        return self.weights['clinical'] * c_score + self.weights['pastwork'] * p_score + self.weights['logistics'] * l_score + self.weights['trust'] * t_score\n\nclass SimpleMLP(nn.Module):\n    def __init__(self, embed_dim=384):\n        super().__init__()\n        input_dim = embed_dim + embed_dim + 4 + 5 + 5 + 3 + 8\n        self.network = nn.Sequential(\n            nn.Linear(input_dim, 256), nn.ReLU(), nn.Dropout(0.2),\n            nn.Linear(256, 128), nn.ReLU(), nn.Dropout(0.2),\n            nn.Linear(128, 64), nn.ReLU(), nn.Dropout(0.2),\n            nn.Linear(64, 1), nn.Sigmoid()\n        )\n\n    def forward(self, patient_emb, doctor_emb, clinical, pastwork, logistics, trust, context):\n        x = torch.cat([patient_emb, doctor_emb, clinical, pastwork, logistics, trust, context], dim=-1)\n        return {'score': self.network(x)}\n\nclass NeuralRanker(nn.Module):\n    def __init__(self, embed_dim=384, hidden_dim=256):\n        super().__init__()\n        self.patient_proj = nn.Linear(embed_dim, hidden_dim)\n        self.doctor_proj = nn.Linear(embed_dim, hidden_dim)\n        self.cross_attention = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=4, batch_first=True)\n        self.layer_norm = nn.LayerNorm(hidden_dim)\n        self.feature_encoder = nn.Sequential(nn.Linear(25, 64), nn.ReLU(), nn.Linear(64, 64))\n        self.scorer = nn.Sequential(\n            nn.Linear(hidden_dim + 64, 128), nn.ReLU(), nn.Dropout(0.2),\n            nn.Linear(128, 64), nn.ReLU(), nn.Linear(64, 1), nn.Sigmoid()\n        )\n\n    def forward(self, patient_emb, doctor_emb, clinical, pastwork, logistics, trust, context):\n        p = self.patient_proj(patient_emb).unsqueeze(1)\n        d = self.doctor_proj(doctor_emb).unsqueeze(1)\n        interaction, _ = self.cross_attention(p, d, d)\n        interaction = self.layer_norm(interaction.squeeze(1))\n        feat = torch.cat([clinical, pastwork, logistics, trust, context], dim=-1)\n        feat_enc = self.feature_encoder(feat)\n        return {'score': self.scorer(torch.cat([interaction, feat_enc], dim=-1))}\n\nclass DINModel(nn.Module):\n    def __init__(self, embed_dim=384):\n        super().__init__()\n        self.case_encoder = nn.Linear(embed_dim + 8, 128)\n        self.doctor_encoder = nn.Linear(embed_dim + 17, 128)\n        self.attention = nn.Sequential(nn.Linear(128 * 3, 64), nn.ReLU(), nn.Linear(64, 1))\n        self.scorer = nn.Sequential(nn.Linear(128, 64), nn.ReLU(), nn.Linear(64, 1), nn.Sigmoid())\n\n    def forward(self, patient_emb, doctor_emb, clinical, pastwork, logistics, trust, context):\n        case_enc = F.relu(self.case_encoder(torch.cat([patient_emb, context], dim=-1)))\n        doc_feat = torch.cat([clinical, pastwork, logistics, trust], dim=-1)\n        doc_enc = F.relu(self.doctor_encoder(torch.cat([doctor_emb, doc_feat], dim=-1)))\n        attn = torch.sigmoid(self.attention(torch.cat([case_enc, doc_enc, case_enc * doc_enc], dim=-1)))\n        return {'score': self.scorer(attn * doc_enc)}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T05:19:06.170153Z","iopub.execute_input":"2026-02-16T05:19:06.170744Z","iopub.status.idle":"2026-02-16T05:19:06.184938Z","shell.execute_reply.started":"2026-02-16T05:19:06.170717Z","shell.execute_reply":"2026-02-16T05:19:06.184397Z"}},"outputs":[],"execution_count":6},{"id":"f379861e-7815-43d4-861c-b276f1ec02fb","cell_type":"code","source":"# ============================================================\n# CELL 5: Metrics and Evaluation\n# ============================================================\ndef ndcg_at_k(scores, labels, k):\n    ranking = np.argsort(-scores)[:k]\n    dcg = sum((2**labels[r] - 1) / np.log2(i + 2) for i, r in enumerate(ranking))\n    ideal = np.argsort(-labels)[:k]\n    idcg = sum((2**labels[r] - 1) / np.log2(i + 2) for i, r in enumerate(ideal))\n    return dcg / idcg if idcg > 0 else 0.0\n\ndef evaluate_model(model_or_mcda, dataloader, device, is_mcda=False):\n    if not is_mcda:\n        model_or_mcda.eval()\n\n    ndcg5, ndcg10 = [], []\n    context_res = {}\n\n    with torch.no_grad():\n        for batch in tqdm(dataloader, desc='Evaluating', leave=False):\n            case_emb = batch['case_embedding'].to(device)\n            docs = batch['doctor_embeddings'].squeeze(0).to(device)\n            clinical = batch['clinical'].squeeze(0).to(device)\n            pastwork = batch['pastwork'].squeeze(0).to(device)\n            logistics = batch['logistics'].squeeze(0).to(device)\n            trust = batch['trust'].squeeze(0).to(device)\n            context = batch['context'].to(device)\n            labels = batch['relevance'].squeeze(0).numpy()\n            ctx = batch['context_category'][0]\n\n            scores = []\n            for i in range(docs.shape[0]):\n                if is_mcda:\n                    s = model_or_mcda.score(\n                        clinical[i:i+1], pastwork[i:i+1], logistics[i:i+1], trust[i:i+1]\n                    ).item()\n                else:\n                    s = model_or_mcda(\n                        case_emb, docs[i:i+1], clinical[i:i+1], pastwork[i:i+1],\n                        logistics[i:i+1], trust[i:i+1], context\n                    )['score'].item()\n                scores.append(s)\n\n            scores = np.array(scores)\n            n5 = ndcg_at_k(scores, labels, 5)\n            n10 = ndcg_at_k(scores, labels, 10)\n            ndcg5.append(n5)\n            ndcg10.append(n10)\n            context_res.setdefault(ctx, []).append(n5)\n\n    overall = {\n        'ndcg@5': {'mean': float(np.mean(ndcg5)), 'std': float(np.std(ndcg5))},\n        'ndcg@10': {'mean': float(np.mean(ndcg10)), 'std': float(np.std(ndcg10))}\n    }\n    stratified = {k: {'mean': float(np.mean(v)), 'std': float(np.std(v))} for k, v in context_res.items()}\n    return {'overall': overall, 'stratified': stratified}\n\ndef ranking_loss(pos_score, neg_score, margin=0.1):\n    return F.relu(margin - (pos_score - neg_score)).mean()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T05:19:20.499446Z","iopub.execute_input":"2026-02-16T05:19:20.500064Z","iopub.status.idle":"2026-02-16T05:19:20.510497Z","shell.execute_reply.started":"2026-02-16T05:19:20.500037Z","shell.execute_reply":"2026-02-16T05:19:20.509896Z"}},"outputs":[],"execution_count":7},{"id":"b620ba84-51b8-46c6-9f6f-7aa183f7ccd0","cell_type":"code","source":"# ============================================================\n# CELL 6: Training Utilities\n# ============================================================\ndef train_baseline(model, train_loader, val_loader, device, mode='bce', epochs=50, patience=10, lr=1e-4):\n    model = model.to(device)\n    optimizer = AdamW(model.parameters(), lr=lr, weight_decay=1e-5)\n    scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n\n    best_ndcg = -1.0\n    patience_counter = 0\n    best_state = None\n    history = {'train_loss': [], 'val_ndcg5': []}\n\n    for epoch in range(epochs):\n        model.train()\n        total_loss = 0.0\n        n_batches = 0\n\n        for batch in tqdm(train_loader, desc=f'Train {mode} epoch {epoch}', leave=False):\n            case_emb = batch['case_embedding'].to(device)\n            pos_doc = batch['pos_doctor_embedding'].to(device)\n            neg_doc = batch['neg_doctor_embedding'].to(device)\n            pos_clinical = batch['pos_clinical'].to(device)\n            neg_clinical = batch['neg_clinical'].to(device)\n            pos_pastwork = batch['pos_pastwork'].to(device)\n            neg_pastwork = batch['neg_pastwork'].to(device)\n            pos_logistics = batch['pos_logistics'].to(device)\n            neg_logistics = batch['neg_logistics'].to(device)\n            pos_trust = batch['pos_trust'].to(device)\n            neg_trust = batch['neg_trust'].to(device)\n            context = batch['context'].to(device)\n\n            optimizer.zero_grad()\n\n            pos_out = model(case_emb, pos_doc, pos_clinical, pos_pastwork, pos_logistics, pos_trust, context)['score']\n            neg_out = model(case_emb, neg_doc, neg_clinical, neg_pastwork, neg_logistics, neg_trust, context)['score']\n\n            if mode == 'bce':\n                loss = (\n                    F.binary_cross_entropy(pos_out, torch.ones_like(pos_out)) +\n                    F.binary_cross_entropy(neg_out, torch.zeros_like(neg_out))\n                ) / 2.0\n            else:\n                loss = ranking_loss(pos_out, neg_out, margin=0.1)\n\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n\n            total_loss += loss.item()\n            n_batches += 1\n\n        avg_loss = total_loss / max(n_batches, 1)\n        val = evaluate_model(model, val_loader, device, is_mcda=False)\n        val_ndcg5 = val['overall']['ndcg@5']['mean']\n        history['train_loss'].append(avg_loss)\n        history['val_ndcg5'].append(val_ndcg5)\n\n        print(f'Epoch {epoch}: loss={avg_loss:.4f}, val_ndcg5={val_ndcg5:.4f}')\n\n        if val_ndcg5 > best_ndcg:\n            best_ndcg = val_ndcg5\n            patience_counter = 0\n            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n        else:\n            patience_counter += 1\n            if patience_counter >= patience:\n                print(f'Early stopping at epoch {epoch}')\n                break\n\n        scheduler.step()\n\n    if best_state is not None:\n        model.load_state_dict(best_state)\n    return model, history","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T05:19:31.710288Z","iopub.execute_input":"2026-02-16T05:19:31.711026Z","iopub.status.idle":"2026-02-16T05:19:31.720879Z","shell.execute_reply.started":"2026-02-16T05:19:31.710996Z","shell.execute_reply":"2026-02-16T05:19:31.720162Z"}},"outputs":[],"execution_count":8},{"id":"94fc2285-c7b0-42b2-8574-bb45544e445b","cell_type":"code","source":"# ============================================================\n# CELL 7: Run All Baselines\n# ============================================================\nall_results = {}\n\nprint('\\n[1/4] StaticMCDA')\nmcda = StaticMCDA()\nall_results['StaticMCDA'] = evaluate_model(mcda, test_loader, device, is_mcda=True)\nall_results['StaticMCDA']['history'] = {'train_loss': [], 'val_ndcg5': []}\n\nprint('\\n[2/4] SimpleMLP (BCE)')\nmlp = SimpleMLP()\nmlp, mlp_hist = train_baseline(mlp, train_loader, val_loader, device, mode='bce', epochs=50, patience=10, lr=1e-4)\ntorch.save(mlp.state_dict(), '/kaggle/working/results/best_simple_mlp.pt')\nall_results['SimpleMLP'] = evaluate_model(mlp, test_loader, device, is_mcda=False)\nall_results['SimpleMLP']['history'] = mlp_hist\n\nprint('\\n[3/4] NeuralRanker (Ranking Loss)')\nranker = NeuralRanker()\nranker, ranker_hist = train_baseline(ranker, train_loader, val_loader, device, mode='ranking', epochs=50, patience=10, lr=1e-4)\ntorch.save(ranker.state_dict(), '/kaggle/working/results/best_neural_ranker.pt')\nall_results['NeuralRanker'] = evaluate_model(ranker, test_loader, device, is_mcda=False)\nall_results['NeuralRanker']['history'] = ranker_hist\n\nprint('\\n[4/4] DINModel (Ranking Loss)')\ndin = DINModel()\ndin, din_hist = train_baseline(din, train_loader, val_loader, device, mode='ranking', epochs=50, patience=10, lr=1e-4)\ntorch.save(din.state_dict(), '/kaggle/working/results/best_din_model.pt')\nall_results['DINModel'] = evaluate_model(din, test_loader, device, is_mcda=False)\nall_results['DINModel']['history'] = din_hist\n\nprint('\\nAll baselines finished.')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T05:19:42.154079Z","iopub.execute_input":"2026-02-16T05:19:42.154401Z","iopub.status.idle":"2026-02-16T08:39:28.402735Z","shell.execute_reply.started":"2026-02-16T05:19:42.154374Z","shell.execute_reply":"2026-02-16T08:39:28.401828Z"}},"outputs":[{"name":"stdout","text":"\n[1/4] StaticMCDA\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"\n[2/4] SimpleMLP (BCE)\n","output_type":"stream"},{"name":"stderr","text":"                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 0: loss=0.6771, val_ndcg5=0.8876\n","output_type":"stream"},{"name":"stderr","text":"                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1: loss=0.5063, val_ndcg5=0.9108\n","output_type":"stream"},{"name":"stderr","text":"                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2: loss=0.1991, val_ndcg5=0.9383\n","output_type":"stream"},{"name":"stderr","text":"                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3: loss=0.0789, val_ndcg5=0.9452\n","output_type":"stream"},{"name":"stderr","text":"                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4: loss=0.0480, val_ndcg5=0.9484\n","output_type":"stream"},{"name":"stderr","text":"                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5: loss=0.0349, val_ndcg5=0.9504\n","output_type":"stream"},{"name":"stderr","text":"                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6: loss=0.0288, val_ndcg5=0.9514\n","output_type":"stream"},{"name":"stderr","text":"                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7: loss=0.0265, val_ndcg5=0.9507\n","output_type":"stream"},{"name":"stderr","text":"                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8: loss=0.0253, val_ndcg5=0.9511\n","output_type":"stream"},{"name":"stderr","text":"                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 9: loss=0.0246, val_ndcg5=0.9514\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 10: loss=0.0210, val_ndcg5=0.9504\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 11: loss=0.0175, val_ndcg5=0.9517\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 12: loss=0.0139, val_ndcg5=0.9545\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 13: loss=0.0127, val_ndcg5=0.9536\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 14: loss=0.0111, val_ndcg5=0.9574\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 15: loss=0.0092, val_ndcg5=0.9563\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 16: loss=0.0104, val_ndcg5=0.9556\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 17: loss=0.0091, val_ndcg5=0.9580\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 18: loss=0.0088, val_ndcg5=0.9559\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 19: loss=0.0088, val_ndcg5=0.9563\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 20: loss=0.0089, val_ndcg5=0.9568\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 21: loss=0.0072, val_ndcg5=0.9581\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 22: loss=0.0091, val_ndcg5=0.9577\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 23: loss=0.0079, val_ndcg5=0.9582\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 24: loss=0.0096, val_ndcg5=0.9583\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 25: loss=0.0083, val_ndcg5=0.9584\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 26: loss=0.0086, val_ndcg5=0.9585\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 27: loss=0.0057, val_ndcg5=0.9584\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 28: loss=0.0079, val_ndcg5=0.9585\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 29: loss=0.0065, val_ndcg5=0.9585\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 30: loss=0.0079, val_ndcg5=0.9611\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 31: loss=0.0077, val_ndcg5=0.9611\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 32: loss=0.0065, val_ndcg5=0.9619\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 33: loss=0.0080, val_ndcg5=0.9617\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 34: loss=0.0072, val_ndcg5=0.9600\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 35: loss=0.0072, val_ndcg5=0.9621\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 36: loss=0.0071, val_ndcg5=0.9620\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 37: loss=0.0053, val_ndcg5=0.9632\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 38: loss=0.0078, val_ndcg5=0.9645\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 39: loss=0.0067, val_ndcg5=0.9647\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 40: loss=0.0075, val_ndcg5=0.9650\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 41: loss=0.0062, val_ndcg5=0.9642\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 42: loss=0.0065, val_ndcg5=0.9665\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 43: loss=0.0047, val_ndcg5=0.9666\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 44: loss=0.0068, val_ndcg5=0.9676\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 45: loss=0.0069, val_ndcg5=0.9679\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 46: loss=0.0058, val_ndcg5=0.9689\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 47: loss=0.0061, val_ndcg5=0.9701\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 48: loss=0.0057, val_ndcg5=0.9708\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 49: loss=0.0048, val_ndcg5=0.9728\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"\n[3/4] NeuralRanker (Ranking Loss)\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 0: loss=0.0741, val_ndcg5=0.5032\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1: loss=0.0355, val_ndcg5=0.9024\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2: loss=0.0024, val_ndcg5=0.9532\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3: loss=0.0006, val_ndcg5=0.9534\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4: loss=0.0004, val_ndcg5=0.9538\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5: loss=0.0003, val_ndcg5=0.9559\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6: loss=0.0002, val_ndcg5=0.9542\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7: loss=0.0002, val_ndcg5=0.9560\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8: loss=0.0002, val_ndcg5=0.9561\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 9: loss=0.0002, val_ndcg5=0.9562\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 10: loss=0.0002, val_ndcg5=0.9534\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 11: loss=0.0002, val_ndcg5=0.9607\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 12: loss=0.0001, val_ndcg5=0.9580\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 13: loss=0.0001, val_ndcg5=0.9552\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 14: loss=0.0001, val_ndcg5=0.9585\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 15: loss=0.0006, val_ndcg5=0.9544\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 16: loss=0.0003, val_ndcg5=0.9541\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 17: loss=0.0001, val_ndcg5=0.9592\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 18: loss=0.0001, val_ndcg5=0.9592\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 19: loss=0.0002, val_ndcg5=0.9569\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 20: loss=0.0002, val_ndcg5=0.9591\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 21: loss=0.0001, val_ndcg5=0.9583\nEarly stopping at epoch 21\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"\n[4/4] DINModel (Ranking Loss)\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 0: loss=0.0942, val_ndcg5=0.8583\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1: loss=0.0488, val_ndcg5=0.8617\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2: loss=0.0073, val_ndcg5=0.9249\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3: loss=0.0017, val_ndcg5=0.9309\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4: loss=0.0009, val_ndcg5=0.9359\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5: loss=0.0007, val_ndcg5=0.9358\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6: loss=0.0006, val_ndcg5=0.9366\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7: loss=0.0005, val_ndcg5=0.9372\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8: loss=0.0005, val_ndcg5=0.9368\n","output_type":"stream"},{"name":"stderr","text":"                                                                      \r","output_type":"stream"},{"name":"stdout","text":"Epoch 9: loss=0.0005, val_ndcg5=0.9370\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 10: loss=0.0004, val_ndcg5=0.9419\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 11: loss=0.0002, val_ndcg5=0.9407\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 12: loss=0.0003, val_ndcg5=0.9430\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 13: loss=0.0002, val_ndcg5=0.9409\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 14: loss=0.0002, val_ndcg5=0.9434\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 15: loss=0.0002, val_ndcg5=0.9420\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 16: loss=0.0002, val_ndcg5=0.9411\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 17: loss=0.0001, val_ndcg5=0.9427\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 18: loss=0.0001, val_ndcg5=0.9440\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 19: loss=0.0002, val_ndcg5=0.9430\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 20: loss=0.0001, val_ndcg5=0.9432\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 21: loss=0.0001, val_ndcg5=0.9452\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 22: loss=0.0001, val_ndcg5=0.9456\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 23: loss=0.0001, val_ndcg5=0.9465\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 24: loss=0.0001, val_ndcg5=0.9467\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 25: loss=0.0001, val_ndcg5=0.9467\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 26: loss=0.0001, val_ndcg5=0.9472\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 27: loss=0.0002, val_ndcg5=0.9467\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 28: loss=0.0002, val_ndcg5=0.9470\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 29: loss=0.0001, val_ndcg5=0.9471\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 30: loss=0.0002, val_ndcg5=0.9446\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 31: loss=0.0001, val_ndcg5=0.9454\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 32: loss=0.0001, val_ndcg5=0.9507\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 33: loss=0.0002, val_ndcg5=0.9483\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 34: loss=0.0001, val_ndcg5=0.9527\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 35: loss=0.0001, val_ndcg5=0.9509\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 36: loss=0.0002, val_ndcg5=0.9461\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 37: loss=0.0001, val_ndcg5=0.9494\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 38: loss=0.0001, val_ndcg5=0.9465\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 39: loss=0.0001, val_ndcg5=0.9473\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 40: loss=0.0001, val_ndcg5=0.9492\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 41: loss=0.0001, val_ndcg5=0.9482\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 42: loss=0.0001, val_ndcg5=0.9511\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 43: loss=0.0001, val_ndcg5=0.9503\n","output_type":"stream"},{"name":"stderr","text":"                                                                       \r","output_type":"stream"},{"name":"stdout","text":"Epoch 44: loss=0.0001, val_ndcg5=0.9497\nEarly stopping at epoch 44\n","output_type":"stream"},{"name":"stderr","text":"                                                               ","output_type":"stream"},{"name":"stdout","text":"\nAll baselines finished.\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}],"execution_count":9},{"id":"6f6c913c-0483-467c-b194-2546e4751dee","cell_type":"code","source":"# ============================================================\n# CELL 8: Save and Summary\n# ============================================================\nwith open('/kaggle/working/results/baseline_results.json', 'w') as f:\n    json.dump(all_results, f, indent=2)\n\nprint('Saved: /kaggle/working/results/baseline_results.json')\nprint('\\nSummary (NDCG@5 mean ± std):')\nfor name, res in all_results.items():\n    m = res['overall']['ndcg@5']['mean']\n    s = res['overall']['ndcg@5']['std']\n    print(f'  {name}: {m:.4f} ± {s:.4f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T08:40:13.919729Z","iopub.execute_input":"2026-02-16T08:40:13.920061Z","iopub.status.idle":"2026-02-16T08:40:13.927277Z","shell.execute_reply.started":"2026-02-16T08:40:13.920031Z","shell.execute_reply":"2026-02-16T08:40:13.926531Z"}},"outputs":[{"name":"stdout","text":"Saved: /kaggle/working/results/baseline_results.json\n\nSummary (NDCG@5 mean ± std):\n  StaticMCDA: 0.8896 ± 0.1251\n  SimpleMLP: 0.9755 ± 0.0507\n  NeuralRanker: 0.9639 ± 0.0617\n  DINModel: 0.9566 ± 0.0711\n","output_type":"stream"}],"execution_count":10},{"id":"5b93faf2-a8ae-406c-bf6b-dc310991d3ce","cell_type":"code","source":"import os\nimport shutil\n\nSEED = 42\nBASE = \"/kaggle/working/results\"\nSEED_DIR = f\"{BASE}/baselines/seed_{SEED}\"\nos.makedirs(SEED_DIR, exist_ok=True)\n\n# Files we want in seed folder\nexpected = [\n    f\"baseline_seed{SEED}_results.json\",\n    f\"best_simple_mlp_seed{SEED}.pt\",\n    f\"best_neural_ranker_seed{SEED}.pt\",\n    f\"best_din_model_seed{SEED}.pt\",\n]\n\n# 1) Ensure seed-named copies exist (if top-level exists)\nrename_map = {\n    f\"{BASE}/baseline_results.json\": f\"{SEED_DIR}/baseline_seed{SEED}_results.json\",\n    f\"{BASE}/best_simple_mlp.pt\": f\"{SEED_DIR}/best_simple_mlp_seed{SEED}.pt\",\n    f\"{BASE}/best_neural_ranker.pt\": f\"{SEED_DIR}/best_neural_ranker_seed{SEED}.pt\",\n    f\"{BASE}/best_din_model.pt\": f\"{SEED_DIR}/best_din_model_seed{SEED}.pt\",\n}\nfor src, dst in rename_map.items():\n    if os.path.exists(src) and not os.path.exists(dst):\n        shutil.copy2(src, dst)\n        print(\"copied:\", dst)\n\n# 2) Remove unnecessary top-level baseline files\nto_delete = [\n    f\"{BASE}/baseline_results.json\",\n    f\"{BASE}/best_simple_mlp.pt\",\n    f\"{BASE}/best_neural_ranker.pt\",\n    f\"{BASE}/best_din_model.pt\",\n]\nfor p in to_delete:\n    if os.path.exists(p):\n        os.remove(p)\n        print(\"removed:\", p)\n\n# 3) Remove unexpected files inside seed folder (keep only expected existing ones)\nfor name in os.listdir(SEED_DIR):\n    p = os.path.join(SEED_DIR, name)\n    if os.path.isfile(p) and name not in expected:\n        os.remove(p)\n        print(\"removed extra:\", p)\n\nprint(\"\\nFinal seed folder contents:\")\nfor f in sorted(os.listdir(SEED_DIR)):\n    print(\" -\", f)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T08:53:47.945285Z","iopub.execute_input":"2026-02-16T08:53:47.945957Z","iopub.status.idle":"2026-02-16T08:53:47.957258Z","shell.execute_reply.started":"2026-02-16T08:53:47.945926Z","shell.execute_reply":"2026-02-16T08:53:47.956707Z"}},"outputs":[{"name":"stdout","text":"copied: /kaggle/working/results/baselines/seed_42/best_simple_mlp_seed42.pt\ncopied: /kaggle/working/results/baselines/seed_42/best_neural_ranker_seed42.pt\nremoved: /kaggle/working/results/baseline_results.json\nremoved: /kaggle/working/results/best_simple_mlp.pt\nremoved: /kaggle/working/results/best_neural_ranker.pt\nremoved: /kaggle/working/results/best_din_model.pt\n\nFinal seed folder contents:\n - baseline_seed42_results.json\n - best_din_model_seed42.pt\n - best_neural_ranker_seed42.pt\n - best_simple_mlp_seed42.pt\n","output_type":"stream"}],"execution_count":12}]}