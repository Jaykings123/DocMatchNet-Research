{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DocMatchNet-JEPA: Data Generation\n",
    "=================================\n",
    "This notebook generates synthetic doctor-patient matching data.\n",
    "\n",
    "Runtime: ~2-3 hours on Kaggle CPU  \n",
    "Output: Saved as Kaggle Dataset for other notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 1: Setup and Imports\n",
    "# ============================================================\n",
    "!pip install sentence-transformers -q\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs('/kaggle/working/data', exist_ok=True)\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 2: Define Constants\n",
    "# ============================================================\n",
    "SPECIALTIES = [\n",
    "    \"General Medicine\", \"Cardiology\", \"Neurology\", \"Orthopedics\",\n",
    "    \"Dermatology\", \"Pediatrics\", \"Gynecology\", \"Ophthalmology\",\n",
    "    \"ENT\", \"Psychiatry\", \"Urology\", \"Nephrology\", \"Pulmonology\",\n",
    "    \"Gastroenterology\", \"Endocrinology\", \"Rheumatology\",\n",
    "    \"Oncology\", \"Hematology\", \"Infectious Disease\",\n",
    "    \"General Surgery\", \"Cardiac Surgery\", \"Neurosurgery\",\n",
    "    \"Plastic Surgery\", \"Vascular Surgery\", \"Radiology\",\n",
    "    \"Anesthesiology\", \"Emergency Medicine\", \"Family Medicine\",\n",
    "    \"Sports Medicine\", \"Pain Medicine\", \"Allergy & Immunology\",\n",
    "    \"Geriatrics\", \"Neonatology\", \"Hepatology\", \"Critical Care\",\n",
    "    \"Palliative Care\", \"Physical Medicine\", \"Preventive Medicine\",\n",
    "    \"Sleep Medicine\", \"Tropical Medicine\"\n",
    "]\n",
    "\n",
    "# Specialty distribution (more common ones have higher probability)\n",
    "SPECIALTY_PROBS = [0.12, 0.05, 0.04, 0.05, 0.06, 0.07, 0.06, 0.04,\n",
    "                   0.04, 0.03, 0.02, 0.02, 0.03, 0.03, 0.02, 0.01,\n",
    "                   0.02, 0.01, 0.02, 0.04, 0.01, 0.01, 0.01, 0.01,\n",
    "                   0.02, 0.02, 0.03, 0.04, 0.01, 0.01, 0.01, 0.02,\n",
    "                   0.01, 0.01, 0.02, 0.01, 0.01, 0.01, 0.005, 0.005]\n",
    "SPECIALTY_PROBS = np.array(SPECIALTY_PROBS)\n",
    "SPECIALTY_PROBS = SPECIALTY_PROBS / SPECIALTY_PROBS.sum()\n",
    "\n",
    "CITIES = [\n",
    "    (\"Mumbai\", \"Maharashtra\", 19.0760, 72.8777),\n",
    "    (\"Delhi\", \"Delhi\", 28.6139, 77.2090),\n",
    "    (\"Bangalore\", \"Karnataka\", 12.9716, 77.5946),\n",
    "    (\"Chennai\", \"Tamil Nadu\", 13.0827, 80.2707),\n",
    "    (\"Kolkata\", \"West Bengal\", 22.5726, 88.3639),\n",
    "    (\"Hyderabad\", \"Telangana\", 17.3850, 78.4867),\n",
    "    (\"Pune\", \"Maharashtra\", 18.5204, 73.8567),\n",
    "    (\"Ahmedabad\", \"Gujarat\", 23.0225, 72.5714),\n",
    "    (\"Jaipur\", \"Rajasthan\", 26.9124, 75.7873),\n",
    "    (\"Lucknow\", \"Uttar Pradesh\", 26.8467, 80.9462),\n",
    "    (\"Chandigarh\", \"Punjab\", 30.7333, 76.7794),\n",
    "    (\"Kochi\", \"Kerala\", 9.9312, 76.2673),\n",
    "    (\"Bhopal\", \"Madhya Pradesh\", 23.2599, 77.4126),\n",
    "    (\"Patna\", \"Bihar\", 25.5941, 85.1376),\n",
    "    (\"Indore\", \"Madhya Pradesh\", 22.7196, 75.8577),\n",
    "    (\"Nagpur\", \"Maharashtra\", 21.1458, 79.0882),\n",
    "    (\"Coimbatore\", \"Tamil Nadu\", 11.0168, 76.9558),\n",
    "    (\"Vizag\", \"Andhra Pradesh\", 17.6868, 83.2185),\n",
    "    (\"Guwahati\", \"Assam\", 26.1445, 91.7362),\n",
    "    (\"Thiruvananthapuram\", \"Kerala\", 8.5241, 76.9366)\n",
    "]\n",
    "\n",
    "LANGUAGES = [\"English\", \"Hindi\", \"Tamil\", \"Telugu\", \"Bengali\", \n",
    "             \"Marathi\", \"Kannada\", \"Malayalam\", \"Gujarati\"]\n",
    "\n",
    "FIRST_NAMES = [\"Rajesh\", \"Priya\", \"Amit\", \"Sunita\", \"Vikram\", \"Anita\",\n",
    "               \"Suresh\", \"Kavita\", \"Ramesh\", \"Meera\", \"Arun\", \"Deepa\",\n",
    "               \"Sanjay\", \"Lakshmi\", \"Vijay\", \"Pooja\", \"Manoj\", \"Neha\"]\n",
    "               \n",
    "LAST_NAMES = [\"Sharma\", \"Patel\", \"Kumar\", \"Singh\", \"Gupta\", \"Reddy\",\n",
    "              \"Iyer\", \"Nair\", \"Joshi\", \"Verma\", \"Rao\", \"Menon\", \"Das\"]\n",
    "\n",
    "N_DOCTORS = 500\n",
    "N_CASES = 15000\n",
    "DOCTORS_PER_CASE = 100  # Top 50 + 50 random\n",
    "\n",
    "print(f\"Will generate {N_DOCTORS} doctors and {N_CASES} cases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 3: Generate Doctors\n",
    "# ============================================================\n",
    "def generate_doctors(n_doctors=500):\n",
    "    \"\"\"Generate synthetic doctor profiles.\"\"\"\n",
    "    doctors = []\n",
    "    \n",
    "    for i in tqdm(range(n_doctors), desc=\"Generating doctors\"):\n",
    "        # Basic info\n",
    "        specialty = np.random.choice(SPECIALTIES, p=SPECIALTY_PROBS)\n",
    "        years_exp = np.random.randint(1, 35)\n",
    "        city_idx = np.random.randint(len(CITIES))\n",
    "        city, state, lat, lon = CITIES[city_idx]\n",
    "        \n",
    "        # Add some noise to location\n",
    "        lat += np.random.normal(0, 0.1)\n",
    "        lon += np.random.normal(0, 0.1)\n",
    "        \n",
    "        # Languages (English + regional)\n",
    "        langs = [\"English\"]\n",
    "        n_extra_langs = np.random.randint(1, 4)\n",
    "        extra_langs = np.random.choice(LANGUAGES[1:], n_extra_langs, replace=False)\n",
    "        langs.extend(extra_langs.tolist())\n",
    "        \n",
    "        # Publications (higher for experienced doctors)\n",
    "        if years_exp > 10:\n",
    "            pubs = np.random.poisson(years_exp * 2)\n",
    "        else:\n",
    "            pubs = np.random.poisson(years_exp * 0.5)\n",
    "        \n",
    "        # Create expertise description\n",
    "        expertise_desc = f\"Dr. {np.random.choice(FIRST_NAMES)} {np.random.choice(LAST_NAMES)} \" \\\n",
    "                        f\"is a {specialty} specialist with {years_exp} years of experience. \" \\\n",
    "                        f\"Specializes in diagnosis and treatment of conditions related to {specialty.lower()}. \"\n",
    "        \n",
    "        if pubs > 10:\n",
    "            expertise_desc += f\"Published {pubs} research papers in the field. \"\n",
    "        \n",
    "        doctor = {\n",
    "            'doctor_id': f'DOC_{i:04d}',\n",
    "            'name': f\"Dr. {np.random.choice(FIRST_NAMES)} {np.random.choice(LAST_NAMES)}\",\n",
    "            'specialty': specialty,\n",
    "            'specialty_idx': SPECIALTIES.index(specialty),\n",
    "            'years_experience': years_exp,\n",
    "            'languages': langs,\n",
    "            'city': city,\n",
    "            'state': state,\n",
    "            'lat': lat,\n",
    "            'lon': lon,\n",
    "            'consultation_fee': np.random.randint(3, 51) * 100,  # 300-5000\n",
    "            'available_modes': np.random.choice(['online', 'in_person', 'both'], \n",
    "                                                p=[0.2, 0.3, 0.5]),\n",
    "            'availability_score': np.random.uniform(0.3, 1.0),\n",
    "            'nmc_verified': np.random.random() < 0.9,\n",
    "            'profile_completeness': np.random.uniform(0.4, 1.0),\n",
    "            'review_score': np.clip(np.random.normal(4.0, 0.5), 2.5, 5.0),\n",
    "            'num_reviews': np.random.randint(0, 500),\n",
    "            'publications_count': pubs,\n",
    "            'consultation_completion_rate': np.random.uniform(0.75, 1.0),\n",
    "            'expertise_description': expertise_desc\n",
    "        }\n",
    "        doctors.append(doctor)\n",
    "    \n",
    "    return pd.DataFrame(doctors)\n",
    "\n",
    "doctors_df = generate_doctors(N_DOCTORS)\n",
    "print(f\"\\nGenerated {len(doctors_df)} doctors\")\n",
    "print(f\"Specialty distribution:\\n{doctors_df['specialty'].value_counts().head(10)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 4: Generate Patient Cases\n",
    "# ============================================================\n",
    "# Symptom templates by specialty\n",
    "SYMPTOM_TEMPLATES = {\n",
    "    \"General Medicine\": [\n",
    "        \"fever and body aches for {duration}\",\n",
    "        \"persistent fatigue and weakness\",\n",
    "        \"recurring headaches and dizziness\",\n",
    "        \"unexplained weight loss\",\n",
    "        \"general weakness and loss of appetite\"\n",
    "    ],\n",
    "    \"Cardiology\": [\n",
    "        \"chest pain radiating to left arm\",\n",
    "        \"shortness of breath on exertion\",\n",
    "        \"palpitations and irregular heartbeat\",\n",
    "        \"swelling in legs and ankles\",\n",
    "        \"high blood pressure symptoms\"\n",
    "    ],\n",
    "    \"Neurology\": [\n",
    "        \"severe migraine headaches\",\n",
    "        \"numbness in extremities\",\n",
    "        \"difficulty with balance and coordination\",\n",
    "        \"memory problems and confusion\",\n",
    "        \"seizures and loss of consciousness\"\n",
    "    ],\n",
    "    \"Orthopedics\": [\n",
    "        \"chronic back pain\",\n",
    "        \"knee pain when climbing stairs\",\n",
    "        \"shoulder pain limiting movement\",\n",
    "        \"joint stiffness in the morning\",\n",
    "        \"pain after sports injury\"\n",
    "    ],\n",
    "    \"Dermatology\": [\n",
    "        \"persistent skin rash\",\n",
    "        \"acne that won't clear\",\n",
    "        \"unexplained hair loss\",\n",
    "        \"skin discoloration patches\",\n",
    "        \"itching and dry skin\"\n",
    "    ],\n",
    "    \"Pediatrics\": [\n",
    "        \"child has high fever\",\n",
    "        \"child not eating properly\",\n",
    "        \"delayed developmental milestones\",\n",
    "        \"frequent ear infections\",\n",
    "        \"child has persistent cough\"\n",
    "    ],\n",
    "    # Add more as needed - use General Medicine as default\n",
    "}\n",
    "\n",
    "def get_symptom_description(specialty, severity, duration):\n",
    "    \"\"\"Generate symptom description based on specialty.\"\"\"\n",
    "    templates = SYMPTOM_TEMPLATES.get(specialty, SYMPTOM_TEMPLATES[\"General Medicine\"])\n",
    "    base_symptom = np.random.choice(templates).format(duration=duration)\n",
    "    \n",
    "    if severity == \"severe\":\n",
    "        prefix = \"Experiencing severe \"\n",
    "        suffix = \" This is significantly affecting daily activities.\"\n",
    "    elif severity == \"moderate\":\n",
    "        prefix = \"Having \"\n",
    "        suffix = \" Looking for treatment options.\"\n",
    "    else:\n",
    "        prefix = \"Mild \"\n",
    "        suffix = \" Would like to get it checked.\"\n",
    "    \n",
    "    return prefix + base_symptom + suffix\n",
    "\n",
    "def generate_cases(n_cases=15000, doctors_df=None):\n",
    "    \"\"\"Generate synthetic patient cases.\"\"\"\n",
    "    cases = []\n",
    "    \n",
    "    # Context distribution\n",
    "    context_probs = {\n",
    "        'routine': 0.60,\n",
    "        'complex': 0.15,\n",
    "        'rare_disease': 0.10,\n",
    "        'emergency': 0.10,\n",
    "        'pediatric': 0.05\n",
    "    }\n",
    "    contexts = list(context_probs.keys())\n",
    "    probs = list(context_probs.values())\n",
    "    \n",
    "    for i in tqdm(range(n_cases), desc=\"Generating cases\"):\n",
    "        # Determine context\n",
    "        context = np.random.choice(contexts, p=probs)\n",
    "        \n",
    "        # Age based on context\n",
    "        if context == 'pediatric':\n",
    "            age = np.random.randint(0, 18)\n",
    "        elif context == 'geriatric':\n",
    "            age = np.random.randint(65, 90)\n",
    "        else:\n",
    "            age = np.random.randint(18, 80)\n",
    "        \n",
    "        # Urgency based on context\n",
    "        if context == 'emergency':\n",
    "            urgency = 'emergency'\n",
    "        elif context == 'complex':\n",
    "            urgency = np.random.choice(['semi_urgent', 'urgent'], p=[0.6, 0.4])\n",
    "        else:\n",
    "            urgency = np.random.choice(['routine', 'semi_urgent'], p=[0.7, 0.3])\n",
    "        \n",
    "        # Severity\n",
    "        if context == 'emergency':\n",
    "            severity = np.random.choice(['severe', 'critical'], p=[0.4, 0.6])\n",
    "        elif context == 'complex':\n",
    "            severity = np.random.choice(['moderate', 'severe'], p=[0.5, 0.5])\n",
    "        else:\n",
    "            severity = np.random.choice(['mild', 'moderate'], p=[0.6, 0.4])\n",
    "        \n",
    "        # Target specialty\n",
    "        if context == 'pediatric':\n",
    "            target_specialty = 'Pediatrics'\n",
    "        elif context == 'rare_disease':\n",
    "            # Rare specialties\n",
    "            rare_specs = ['Rheumatology', 'Hematology', 'Oncology', \n",
    "                         'Neurosurgery', 'Tropical Medicine']\n",
    "            target_specialty = np.random.choice(rare_specs)\n",
    "        else:\n",
    "            target_specialty = np.random.choice(SPECIALTIES, p=SPECIALTY_PROBS)\n",
    "        \n",
    "        # Location\n",
    "        city_idx = np.random.randint(len(CITIES))\n",
    "        city, state, lat, lon = CITIES[city_idx]\n",
    "        lat += np.random.normal(0, 0.15)\n",
    "        lon += np.random.normal(0, 0.15)\n",
    "        \n",
    "        # Duration\n",
    "        duration = np.random.choice(['2 days', '3 days', '1 week', \n",
    "                                     '2 weeks', '1 month', '3 months'])\n",
    "        \n",
    "        # Symptom description\n",
    "        symptom_desc = get_symptom_description(target_specialty, severity, duration)\n",
    "        \n",
    "        # Comorbidities (more for complex cases)\n",
    "        if context == 'complex':\n",
    "            comorbidity_count = np.random.randint(2, 5)\n",
    "        elif age > 60:\n",
    "            comorbidity_count = np.random.randint(0, 3)\n",
    "        else:\n",
    "            comorbidity_count = np.random.randint(0, 2)\n",
    "        \n",
    "        # Disease rarity score\n",
    "        if context == 'rare_disease':\n",
    "            rarity_score = np.random.uniform(0.7, 1.0)\n",
    "        else:\n",
    "            rarity_score = np.random.uniform(0.0, 0.3)\n",
    "        \n",
    "        # Red flag score\n",
    "        if context == 'emergency':\n",
    "            red_flag = np.random.uniform(0.7, 1.0)\n",
    "        elif severity in ['severe', 'critical']:\n",
    "            red_flag = np.random.uniform(0.4, 0.8)\n",
    "        else:\n",
    "            red_flag = np.random.uniform(0.0, 0.3)\n",
    "        \n",
    "        case = {\n",
    "            'case_id': f'CASE_{i:05d}',\n",
    "            'patient_age': age,\n",
    "            'patient_gender': np.random.choice(['M', 'F', 'Other'], p=[0.48, 0.50, 0.02]),\n",
    "            'symptom_description': symptom_desc,\n",
    "            'duration': duration,\n",
    "            'severity': severity,\n",
    "            'city': city,\n",
    "            'state': state,\n",
    "            'lat': lat,\n",
    "            'lon': lon,\n",
    "            'preferred_language': np.random.choice(LANGUAGES, p=[0.4, 0.25, 0.08, 0.07, \n",
    "                                                                  0.06, 0.05, 0.04, 0.03, 0.02]),\n",
    "            'preferred_mode': np.random.choice(['online', 'in_person', 'no_preference'],\n",
    "                                               p=[0.35, 0.25, 0.40]),\n",
    "            'budget_min': np.random.randint(2, 10) * 100,\n",
    "            'budget_max': np.random.randint(20, 50) * 100,\n",
    "            'urgency_level': urgency,\n",
    "            'context_category': context,\n",
    "            'target_specialty': target_specialty,\n",
    "            'target_specialty_idx': SPECIALTIES.index(target_specialty),\n",
    "            'red_flag_score': red_flag,\n",
    "            'comorbidity_count': comorbidity_count,\n",
    "            'disease_rarity_score': rarity_score,\n",
    "            'symptom_count': np.random.randint(1, 8)\n",
    "        }\n",
    "        cases.append(case)\n",
    "    \n",
    "    return pd.DataFrame(cases)\n",
    "\n",
    "cases_df = generate_cases(N_CASES, doctors_df)\n",
    "print(f\"\\nGenerated {len(cases_df)} cases\")\n",
    "print(f\"Context distribution:\\n{cases_df['context_category'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 5: Compute Embeddings\n",
    "# ============================================================\n",
    "print(\"Loading embedding model...\")\n",
    "encoder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(f\"Embedding dimension: {encoder.get_sentence_embedding_dimension()}\")\n",
    "\n",
    "# Doctor embeddings\n",
    "print(\"\\nComputing doctor embeddings...\")\n",
    "doctor_texts = doctors_df['expertise_description'].tolist()\n",
    "doctor_embeddings = encoder.encode(doctor_texts, show_progress_bar=True, \n",
    "                                   convert_to_tensor=True)\n",
    "print(f\"Doctor embeddings shape: {doctor_embeddings.shape}\")\n",
    "\n",
    "# Case embeddings\n",
    "print(\"\\nComputing case embeddings...\")\n",
    "case_texts = cases_df['symptom_description'].tolist()\n",
    "case_embeddings = encoder.encode(case_texts, show_progress_bar=True,\n",
    "                                 convert_to_tensor=True, batch_size=64)\n",
    "print(f\"Case embeddings shape: {case_embeddings.shape}\")\n",
    "\n",
    "# Save embeddings\n",
    "torch.save(doctor_embeddings, '/kaggle/working/data/doctor_embeddings.pt')\n",
    "torch.save(case_embeddings, '/kaggle/working/data/case_embeddings.pt')\n",
    "print(\"Embeddings saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 6: Compute Relevance Labels and Select Doctors per Case\n",
    "# ============================================================\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Compute haversine distance in km.\"\"\"\n",
    "    R = 6371  # Earth radius in km\n",
    "    \n",
    "    lat1, lat2 = np.radians(lat1), np.radians(lat2)\n",
    "    lon1, lon2 = np.radians(lon1), np.radians(lon2)\n",
    "    \n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    \n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    \n",
    "    return R * c\n",
    "\n",
    "def compute_relevance(case, doctor):\n",
    "    \"\"\"\n",
    "    Compute relevance score (0-4) for a doctor-case pair.\n",
    "    \n",
    "    4 = Perfect match\n",
    "    3 = Good match  \n",
    "    2 = Fair match\n",
    "    1 = Marginal match\n",
    "    0 = Not relevant\n",
    "    \"\"\"\n",
    "    score = 0\n",
    "    \n",
    "    # Specialty match (most important)\n",
    "    if doctor['specialty'] == case['target_specialty']:\n",
    "        score += 2.0\n",
    "    elif doctor['specialty_idx'] // 5 == case['target_specialty_idx'] // 5:\n",
    "        # Same specialty group\n",
    "        score += 1.0\n",
    "    \n",
    "    # Availability\n",
    "    if doctor['availability_score'] > 0.7:\n",
    "        score += 0.5\n",
    "    elif doctor['availability_score'] > 0.5:\n",
    "        score += 0.25\n",
    "    \n",
    "    # Location (for non-online preference)\n",
    "    if case['preferred_mode'] != 'online':\n",
    "        dist = haversine_distance(case['lat'], case['lon'], \n",
    "                                  doctor['lat'], doctor['lon'])\n",
    "        if dist < 20:\n",
    "            score += 0.5\n",
    "        elif dist < 50:\n",
    "            score += 0.25\n",
    "    \n",
    "    # Language match\n",
    "    if case['preferred_language'] in doctor['languages']:\n",
    "        score += 0.3\n",
    "    \n",
    "    # Mode match\n",
    "    if case['preferred_mode'] == 'no_preference':\n",
    "        score += 0.2\n",
    "    elif doctor['available_modes'] == 'both':\n",
    "        score += 0.2\n",
    "    elif doctor['available_modes'] == case['preferred_mode']:\n",
    "        score += 0.3\n",
    "    \n",
    "    # Fee match\n",
    "    if doctor['consultation_fee'] <= case['budget_max']:\n",
    "        if doctor['consultation_fee'] >= case['budget_min']:\n",
    "            score += 0.2\n",
    "        else:\n",
    "            score += 0.1\n",
    "    \n",
    "    # Trust factors\n",
    "    if doctor['nmc_verified']:\n",
    "        score += 0.2\n",
    "    if doctor['review_score'] > 4.0:\n",
    "        score += 0.2\n",
    "    \n",
    "    # Experience for complex/rare cases\n",
    "    if case['context_category'] in ['complex', 'rare_disease']:\n",
    "        if doctor['years_experience'] > 15:\n",
    "            score += 0.3\n",
    "        if doctor['publications_count'] > 20:\n",
    "            score += 0.2\n",
    "    \n",
    "    # Convert to 0-4 scale\n",
    "    if score >= 3.0:\n",
    "        return 4\n",
    "    elif score >= 2.0:\n",
    "        return 3\n",
    "    elif score >= 1.0:\n",
    "        return 2\n",
    "    elif score >= 0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "print(\"Computing relevance labels and selecting doctors per case...\")\n",
    "\n",
    "# For each case, compute relevance for all doctors, then select top-50 + 50 random\n",
    "all_doctor_indices = []\n",
    "all_relevance_labels = []\n",
    "\n",
    "doctors_array = doctors_df.to_dict('records')\n",
    "cases_array = cases_df.to_dict('records')\n",
    "\n",
    "for case_idx in tqdm(range(N_CASES), desc=\"Processing cases\"):\n",
    "    case = cases_array[case_idx]\n",
    "    \n",
    "    # Compute relevance for all doctors\n",
    "    relevances = []\n",
    "    for doc_idx in range(N_DOCTORS):\n",
    "        doctor = doctors_array[doc_idx]\n",
    "        rel = compute_relevance(case, doctor)\n",
    "        relevances.append(rel)\n",
    "    \n",
    "    relevances = np.array(relevances)\n",
    "    \n",
    "    # Get top-50 by relevance\n",
    "    top_50_indices = np.argsort(-relevances)[:50]\n",
    "    \n",
    "    # Get 50 random from remaining\n",
    "    remaining = np.setdiff1d(np.arange(N_DOCTORS), top_50_indices)\n",
    "    random_50_indices = np.random.choice(remaining, 50, replace=False)\n",
    "    \n",
    "    # Combine\n",
    "    selected_indices = np.concatenate([top_50_indices, random_50_indices])\n",
    "    selected_relevances = relevances[selected_indices]\n",
    "    \n",
    "    all_doctor_indices.append(selected_indices)\n",
    "    all_relevance_labels.append(selected_relevances)\n",
    "\n",
    "doctor_indices = np.stack(all_doctor_indices)  # (15000, 100)\n",
    "relevance_labels = np.stack(all_relevance_labels)  # (15000, 100)\n",
    "\n",
    "print(f\"Doctor indices shape: {doctor_indices.shape}\")\n",
    "print(f\"Relevance labels shape: {relevance_labels.shape}\")\n",
    "print(f\"Relevance distribution: {np.bincount(relevance_labels.flatten())}\")\n",
    "\n",
    "# Save\n",
    "np.save('/kaggle/working/data/doctor_indices.npy', doctor_indices)\n",
    "np.save('/kaggle/working/data/relevance_labels.npy', relevance_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 7: Extract Features for Selected Doctor-Case Pairs\n",
    "# ============================================================\n",
    "def extract_features(case_idx, doc_local_idx, cases_df, doctors_df,\n",
    "                     case_embeddings, doctor_embeddings, doctor_indices):\n",
    "    \"\"\"Extract all features for a doctor-case pair.\"\"\"\n",
    "    case = cases_df.iloc[case_idx]\n",
    "    doc_global_idx = doctor_indices[case_idx, doc_local_idx]\n",
    "    doctor = doctors_df.iloc[doc_global_idx]\n",
    "    \n",
    "    case_emb = case_embeddings[case_idx]\n",
    "    doc_emb = doctor_embeddings[doc_global_idx]\n",
    "    \n",
    "    # Clinical features (4)\n",
    "    cos_sim = torch.nn.functional.cosine_similarity(\n",
    "        case_emb.unsqueeze(0), doc_emb.unsqueeze(0)\n",
    "    ).item()\n",
    "    \n",
    "    specialty_match = 1.0 if doctor['specialty'] == case['target_specialty'] else \\\n",
    "                      0.5 if doctor['specialty_idx'] // 5 == case['target_specialty_idx'] // 5 else 0.0\n",
    "    subspecialty_match = 0.5 if specialty_match > 0 else 0.0  # Simplified\n",
    "    keyword_overlap = 0.3  # Placeholder - would compute properly with tokenization\n",
    "    \n",
    "    clinical = [cos_sim, specialty_match, subspecialty_match, keyword_overlap]\n",
    "    \n",
    "    # PastWork features (5)\n",
    "    pub_impact = min(doctor['publications_count'] / 50, 1.0)\n",
    "    topic_relevance = cos_sim * 0.8  # Simplified\n",
    "    experience = min(doctor['years_experience'] / 25, 1.0)\n",
    "    platform_perf = doctor['consultation_completion_rate']\n",
    "    reputation = (doctor['review_score'] - 2.5) / 2.5 * 0.7 + 0.3\n",
    "    \n",
    "    pastwork = [pub_impact, topic_relevance, experience, platform_perf, reputation]\n",
    "    \n",
    "    # Logistics features (5)\n",
    "    availability = doctor['availability_score']\n",
    "    language_match = 1.0 if case['preferred_language'] in doctor['languages'] else \\\n",
    "                     0.5 if 'English' in doctor['languages'] else 0.0\n",
    "    \n",
    "    dist = haversine_distance(case['lat'], case['lon'], doctor['lat'], doctor['lon'])\n",
    "    proximity = 1.0 - min(dist / 100, 1.0)\n",
    "    \n",
    "    fee = doctor['consultation_fee']\n",
    "    if case['budget_min'] <= fee <= case['budget_max']:\n",
    "        fee_match = 1.0\n",
    "    elif fee < case['budget_min']:\n",
    "        fee_match = 0.8\n",
    "    else:\n",
    "        fee_match = max(0, 1.0 - (fee - case['budget_max']) / case['budget_max'])\n",
    "    \n",
    "    if case['preferred_mode'] == 'no_preference' or doctor['available_modes'] == 'both':\n",
    "        mode_match = 1.0\n",
    "    elif case['preferred_mode'] == doctor['available_modes']:\n",
    "        mode_match = 1.0\n",
    "    else:\n",
    "        mode_match = 0.3\n",
    "    \n",
    "    logistics = [availability, language_match, proximity, fee_match, mode_match]\n",
    "    \n",
    "    # Trust features (3)\n",
    "    nmc = 1.0 if doctor['nmc_verified'] else 0.0\n",
    "    completeness = doctor['profile_completeness']\n",
    "    review = (doctor['review_score'] - 2.5) / 2.5\n",
    "    \n",
    "    trust = [nmc, completeness, review]\n",
    "    \n",
    "    return clinical, pastwork, logistics, trust\n",
    "\n",
    "# Extract features for all selected pairs\n",
    "print(\"Extracting features for all selected doctor-case pairs...\")\n",
    "\n",
    "clinical_features = np.zeros((N_CASES, DOCTORS_PER_CASE, 4), dtype=np.float32)\n",
    "pastwork_features = np.zeros((N_CASES, DOCTORS_PER_CASE, 5), dtype=np.float32)\n",
    "logistics_features = np.zeros((N_CASES, DOCTORS_PER_CASE, 5), dtype=np.float32)\n",
    "trust_features = np.zeros((N_CASES, DOCTORS_PER_CASE, 3), dtype=np.float32)\n",
    "\n",
    "for case_idx in tqdm(range(N_CASES), desc=\"Extracting features\"):\n",
    "    for doc_local_idx in range(DOCTORS_PER_CASE):\n",
    "        clinical, pastwork, logistics, trust = extract_features(\n",
    "            case_idx, doc_local_idx, cases_df, doctors_df,\n",
    "            case_embeddings, doctor_embeddings, doctor_indices\n",
    "        )\n",
    "        clinical_features[case_idx, doc_local_idx] = clinical\n",
    "        pastwork_features[case_idx, doc_local_idx] = pastwork\n",
    "        logistics_features[case_idx, doc_local_idx] = logistics\n",
    "        trust_features[case_idx, doc_local_idx] = trust\n",
    "\n",
    "# Context features (8) - per case\n",
    "context_features = np.zeros((N_CASES, 8), dtype=np.float32)\n",
    "urgency_map = {'routine': 0, 'semi_urgent': 1, 'urgent': 2, 'emergency': 3}\n",
    "\n",
    "for i, case in cases_df.iterrows():\n",
    "    context_features[i] = [\n",
    "        urgency_map[case['urgency_level']] / 3.0,\n",
    "        case['symptom_count'] / 8.0,\n",
    "        case['red_flag_score'],\n",
    "        case['patient_age'] / 90.0,\n",
    "        case['comorbidity_count'] / 5.0,\n",
    "        case['disease_rarity_score'],\n",
    "        1.0 if case['patient_age'] < 18 else 0.0,\n",
    "        1.0 if case['urgency_level'] == 'emergency' else 0.0\n",
    "    ]\n",
    "\n",
    "print(f\"Clinical features shape: {clinical_features.shape}\")\n",
    "print(f\"Context features shape: {context_features.shape}\")\n",
    "\n",
    "# Save all features\n",
    "torch.save(torch.tensor(clinical_features), '/kaggle/working/data/clinical_features.pt')\n",
    "torch.save(torch.tensor(pastwork_features), '/kaggle/working/data/pastwork_features.pt')\n",
    "torch.save(torch.tensor(logistics_features), '/kaggle/working/data/logistics_features.pt')\n",
    "torch.save(torch.tensor(trust_features), '/kaggle/working/data/trust_features.pt')\n",
    "torch.save(torch.tensor(context_features), '/kaggle/working/data/context_features.pt')\n",
    "torch.save(torch.tensor(relevance_labels), '/kaggle/working/data/relevance_labels.pt')\n",
    "torch.save(torch.tensor(doctor_indices), '/kaggle/working/data/doctor_indices.pt')\n",
    "\n",
    "# Save metadata\n",
    "case_metadata = {\n",
    "    'context_category': cases_df['context_category'].tolist(),\n",
    "    'urgency_level': cases_df['urgency_level'].tolist(),\n",
    "    'target_specialty': cases_df['target_specialty'].tolist()\n",
    "}\n",
    "torch.save(case_metadata, '/kaggle/working/data/case_metadata.pt')\n",
    "\n",
    "# Save dataframes\n",
    "doctors_df.to_parquet('/kaggle/working/data/doctors.parquet')\n",
    "cases_df.to_parquet('/kaggle/working/data/cases.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 8: Compute MCDA Teacher Scores\n",
    "# ============================================================\n",
    "print(\"Computing MCDA teacher scores...\")\n",
    "\n",
    "def compute_mcda_score(clinical, pastwork, logistics, trust):\n",
    "    \"\"\"Compute static MCDA score.\"\"\"\n",
    "    c_weights = [0.55, 0.20, 0.15, 0.10]\n",
    "    p_weights = [0.30, 0.25, 0.20, 0.15, 0.10]\n",
    "    l_weights = [0.30, 0.25, 0.20, 0.15, 0.10]\n",
    "    t_weights = [0.50, 0.30, 0.20]\n",
    "    \n",
    "    c_score = sum(c * w for c, w in zip(clinical, c_weights))\n",
    "    p_score = sum(p * w for p, w in zip(pastwork, p_weights))\n",
    "    l_score = sum(l * w for l, w in zip(logistics, l_weights))\n",
    "    t_score = sum(t * w for t, w in zip(trust, t_weights))\n",
    "    \n",
    "    return 0.40 * c_score + 0.25 * p_score + 0.25 * l_score + 0.10 * t_score\n",
    "\n",
    "mcda_scores = np.zeros((N_CASES, DOCTORS_PER_CASE), dtype=np.float32)\n",
    "\n",
    "for i in tqdm(range(N_CASES), desc=\"Computing MCDA scores\"):\n",
    "    for j in range(DOCTORS_PER_CASE):\n",
    "        mcda_scores[i, j] = compute_mcda_score(\n",
    "            clinical_features[i, j],\n",
    "            pastwork_features[i, j],\n",
    "            logistics_features[i, j],\n",
    "            trust_features[i, j]\n",
    "        )\n",
    "\n",
    "torch.save(torch.tensor(mcda_scores), '/kaggle/working/data/mcda_scores.pt')\n",
    "print(f\"MCDA scores shape: {mcda_scores.shape}\")\n",
    "print(f\"MCDA score range: [{mcda_scores.min():.3f}, {mcda_scores.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 9: Create Train/Val/Test Splits\n",
    "# ============================================================\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Stratified split by context category\n",
    "contexts = cases_df['context_category'].values\n",
    "indices = np.arange(N_CASES)\n",
    "\n",
    "# First split: train+val vs test\n",
    "train_val_idx, test_idx = train_test_split(\n",
    "    indices, test_size=0.15, stratify=contexts, random_state=42\n",
    ")\n",
    "\n",
    "# Second split: train vs val\n",
    "train_idx, val_idx = train_test_split(\n",
    "    train_val_idx, test_size=0.15/0.85, \n",
    "    stratify=contexts[train_val_idx], random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train size: {len(train_idx)}\")\n",
    "print(f\"Val size: {len(val_idx)}\")\n",
    "print(f\"Test size: {len(test_idx)}\")\n",
    "\n",
    "# Verify stratification\n",
    "for split_name, split_idx in [('Train', train_idx), ('Val', val_idx), ('Test', test_idx)]:\n",
    "    split_contexts = contexts[split_idx]\n",
    "    print(f\"\\n{split_name} context distribution:\")\n",
    "    unique, counts = np.unique(split_contexts, return_counts=True)\n",
    "    for ctx, cnt in zip(unique, counts):\n",
    "        print(f\"  {ctx}: {cnt} ({cnt/len(split_idx)*100:.1f}%)\")\n",
    "\n",
    "# Save splits\n",
    "splits = {\n",
    "    'train': train_idx.tolist(),\n",
    "    'val': val_idx.tolist(),\n",
    "    'test': test_idx.tolist()\n",
    "}\n",
    "torch.save(splits, '/kaggle/working/data/splits.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 10: Summary and Verification\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DATA GENERATION COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "import os\n",
    "data_dir = '/kaggle/working/data'\n",
    "files = os.listdir(data_dir)\n",
    "print(f\"\\nGenerated files:\")\n",
    "total_size = 0\n",
    "for f in sorted(files):\n",
    "    path = os.path.join(data_dir, f)\n",
    "    size = os.path.getsize(path) / (1024 * 1024)  # MB\n",
    "    total_size += size\n",
    "    print(f\"  {f}: {size:.2f} MB\")\n",
    "print(f\"\\nTotal size: {total_size:.2f} MB\")\n",
    "\n",
    "print(f\"\\nDataset Statistics:\")\n",
    "print(f\"  - Doctors: {N_DOCTORS}\")\n",
    "print(f\"  - Cases: {N_CASES}\")\n",
    "print(f\"  - Doctors per case: {DOCTORS_PER_CASE}\")\n",
    "print(f\"  - Total pairs: {N_CASES * DOCTORS_PER_CASE:,}\")\n",
    "print(f\"  - Embedding dimension: 384\")\n",
    "print(f\"  - Feature dimensions: clinical(4), pastwork(5), logistics(5), trust(3)\")\n",
    "print(f\"  - Context dimension: 8\")\n",
    "\n",
    "print(f\"\\nSplits:\")\n",
    "print(f\"  - Train: {len(train_idx)} cases ({len(train_idx)/N_CASES*100:.1f}%)\")\n",
    "print(f\"  - Val: {len(val_idx)} cases ({len(val_idx)/N_CASES*100:.1f}%)\")\n",
    "print(f\"  - Test: {len(test_idx)} cases ({len(test_idx)/N_CASES*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nâœ… Data ready! Save this notebook output as a Kaggle Dataset.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
