{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14828461,"sourceType":"datasetVersion","datasetId":9483689}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"635e2fb2-a21b-4071-935d-866526e26832","cell_type":"markdown","source":"# DocMatchNet-JEPA: Data Generation\n=================================\nThis notebook generates synthetic doctor-patient matching data.\n\nRuntime: ~2-3 hours on Kaggle CPU  \nOutput: Saved as Kaggle Dataset for other notebooks","metadata":{}},{"id":"923aa585-9fc1-4076-ab50-f13bc116c0a0","cell_type":"code","source":"# ============================================================\n# CELL 1: Setup and Imports\n# ============================================================\n!pip install sentence-transformers -q\n\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom sentence_transformers import SentenceTransformer\nfrom tqdm import tqdm\nimport json\nimport os\n\n# Set seeds for reproducibility\nnp.random.seed(42)\ntorch.manual_seed(42)\n\n# Create output directory\nos.makedirs('/kaggle/working/data', exist_ok=True)\n\nprint(\"Setup complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T10:27:18.836527Z","iopub.execute_input":"2026-02-13T10:27:18.837093Z","iopub.status.idle":"2026-02-13T10:28:13.777095Z","shell.execute_reply.started":"2026-02-13T10:27:18.837061Z","shell.execute_reply":"2026-02-13T10:28:13.776198Z"}},"outputs":[{"name":"stderr","text":"2026-02-13 10:27:49.784388: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1770978470.089267      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1770978470.176802      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1770978470.854816      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770978470.854868      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770978470.854875      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770978470.854878      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"name":"stdout","text":"Setup complete!\n","output_type":"stream"}],"execution_count":1},{"id":"ef5af32b-caab-46fa-b52c-71d21d6bd609","cell_type":"code","source":"# ============================================================\n# CELL 2: Define Constants\n# ============================================================\nSPECIALTIES = [\n    \"General Medicine\", \"Cardiology\", \"Neurology\", \"Orthopedics\",\n    \"Dermatology\", \"Pediatrics\", \"Gynecology\", \"Ophthalmology\",\n    \"ENT\", \"Psychiatry\", \"Urology\", \"Nephrology\", \"Pulmonology\",\n    \"Gastroenterology\", \"Endocrinology\", \"Rheumatology\",\n    \"Oncology\", \"Hematology\", \"Infectious Disease\",\n    \"General Surgery\", \"Cardiac Surgery\", \"Neurosurgery\",\n    \"Plastic Surgery\", \"Vascular Surgery\", \"Radiology\",\n    \"Anesthesiology\", \"Emergency Medicine\", \"Family Medicine\",\n    \"Sports Medicine\", \"Pain Medicine\", \"Allergy & Immunology\",\n    \"Geriatrics\", \"Neonatology\", \"Hepatology\", \"Critical Care\",\n    \"Palliative Care\", \"Physical Medicine\", \"Preventive Medicine\",\n    \"Sleep Medicine\", \"Tropical Medicine\"\n]\n\n# Specialty distribution (more common ones have higher probability)\nSPECIALTY_PROBS = [0.12, 0.05, 0.04, 0.05, 0.06, 0.07, 0.06, 0.04,\n                   0.04, 0.03, 0.02, 0.02, 0.03, 0.03, 0.02, 0.01,\n                   0.02, 0.01, 0.02, 0.04, 0.01, 0.01, 0.01, 0.01,\n                   0.02, 0.02, 0.03, 0.04, 0.01, 0.01, 0.01, 0.02,\n                   0.01, 0.01, 0.02, 0.01, 0.01, 0.01, 0.005, 0.005]\nSPECIALTY_PROBS = np.array(SPECIALTY_PROBS)\nSPECIALTY_PROBS = SPECIALTY_PROBS / SPECIALTY_PROBS.sum()\n\nCITIES = [\n    (\"Mumbai\", \"Maharashtra\", 19.0760, 72.8777),\n    (\"Delhi\", \"Delhi\", 28.6139, 77.2090),\n    (\"Bangalore\", \"Karnataka\", 12.9716, 77.5946),\n    (\"Chennai\", \"Tamil Nadu\", 13.0827, 80.2707),\n    (\"Kolkata\", \"West Bengal\", 22.5726, 88.3639),\n    (\"Hyderabad\", \"Telangana\", 17.3850, 78.4867),\n    (\"Pune\", \"Maharashtra\", 18.5204, 73.8567),\n    (\"Ahmedabad\", \"Gujarat\", 23.0225, 72.5714),\n    (\"Jaipur\", \"Rajasthan\", 26.9124, 75.7873),\n    (\"Lucknow\", \"Uttar Pradesh\", 26.8467, 80.9462),\n    (\"Chandigarh\", \"Punjab\", 30.7333, 76.7794),\n    (\"Kochi\", \"Kerala\", 9.9312, 76.2673),\n    (\"Bhopal\", \"Madhya Pradesh\", 23.2599, 77.4126),\n    (\"Patna\", \"Bihar\", 25.5941, 85.1376),\n    (\"Indore\", \"Madhya Pradesh\", 22.7196, 75.8577),\n    (\"Nagpur\", \"Maharashtra\", 21.1458, 79.0882),\n    (\"Coimbatore\", \"Tamil Nadu\", 11.0168, 76.9558),\n    (\"Vizag\", \"Andhra Pradesh\", 17.6868, 83.2185),\n    (\"Guwahati\", \"Assam\", 26.1445, 91.7362),\n    (\"Thiruvananthapuram\", \"Kerala\", 8.5241, 76.9366)\n]\n\nLANGUAGES = [\"English\", \"Hindi\", \"Tamil\", \"Telugu\", \"Bengali\", \n             \"Marathi\", \"Kannada\", \"Malayalam\", \"Gujarati\"]\n\nFIRST_NAMES = [\"Rajesh\", \"Priya\", \"Amit\", \"Sunita\", \"Vikram\", \"Anita\",\n               \"Suresh\", \"Kavita\", \"Ramesh\", \"Meera\", \"Arun\", \"Deepa\",\n               \"Sanjay\", \"Lakshmi\", \"Vijay\", \"Pooja\", \"Manoj\", \"Neha\"]\n               \nLAST_NAMES = [\"Sharma\", \"Patel\", \"Kumar\", \"Singh\", \"Gupta\", \"Reddy\",\n              \"Iyer\", \"Nair\", \"Joshi\", \"Verma\", \"Rao\", \"Menon\", \"Das\"]\n\nN_DOCTORS = 500\nN_CASES = 15000\nDOCTORS_PER_CASE = 100  # Top 50 + 50 random\n\nprint(f\"Will generate {N_DOCTORS} doctors and {N_CASES} cases\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T10:28:13.778903Z","iopub.execute_input":"2026-02-13T10:28:13.779660Z","iopub.status.idle":"2026-02-13T10:28:13.793774Z","shell.execute_reply.started":"2026-02-13T10:28:13.779624Z","shell.execute_reply":"2026-02-13T10:28:13.792030Z"}},"outputs":[{"name":"stdout","text":"Will generate 500 doctors and 15000 cases\n","output_type":"stream"}],"execution_count":2},{"id":"b5287e71-6d42-4640-804d-64fb866116d5","cell_type":"code","source":"# ============================================================\n# CELL 3: Generate Doctors\n# ============================================================\ndef generate_doctors(n_doctors=500):\n    \"\"\"Generate synthetic doctor profiles.\"\"\"\n    doctors = []\n    \n    for i in tqdm(range(n_doctors), desc=\"Generating doctors\"):\n        # Basic info\n        specialty = np.random.choice(SPECIALTIES, p=SPECIALTY_PROBS)\n        years_exp = np.random.randint(1, 35)\n        city_idx = np.random.randint(len(CITIES))\n        city, state, lat, lon = CITIES[city_idx]\n        \n        # Add some noise to location\n        lat += np.random.normal(0, 0.1)\n        lon += np.random.normal(0, 0.1)\n        \n        # Languages (English + regional)\n        langs = [\"English\"]\n        n_extra_langs = np.random.randint(1, 4)\n        extra_langs = np.random.choice(LANGUAGES[1:], n_extra_langs, replace=False)\n        langs.extend(extra_langs.tolist())\n        \n        # Publications (higher for experienced doctors)\n        if years_exp > 10:\n            pubs = np.random.poisson(years_exp * 2)\n        else:\n            pubs = np.random.poisson(years_exp * 0.5)\n        \n        # Create expertise description\n        expertise_desc = f\"Dr. {np.random.choice(FIRST_NAMES)} {np.random.choice(LAST_NAMES)} \" \\\n                        f\"is a {specialty} specialist with {years_exp} years of experience. \" \\\n                        f\"Specializes in diagnosis and treatment of conditions related to {specialty.lower()}. \"\n        \n        if pubs > 10:\n            expertise_desc += f\"Published {pubs} research papers in the field. \"\n        \n        doctor = {\n            'doctor_id': f'DOC_{i:04d}',\n            'name': f\"Dr. {np.random.choice(FIRST_NAMES)} {np.random.choice(LAST_NAMES)}\",\n            'specialty': specialty,\n            'specialty_idx': SPECIALTIES.index(specialty),\n            'years_experience': years_exp,\n            'languages': langs,\n            'city': city,\n            'state': state,\n            'lat': lat,\n            'lon': lon,\n            'consultation_fee': np.random.randint(3, 51) * 100,  # 300-5000\n            'available_modes': np.random.choice(['online', 'in_person', 'both'], \n                                                p=[0.2, 0.3, 0.5]),\n            'availability_score': np.random.uniform(0.3, 1.0),\n            'nmc_verified': np.random.random() < 0.9,\n            'profile_completeness': np.random.uniform(0.4, 1.0),\n            'review_score': np.clip(np.random.normal(4.0, 0.5), 2.5, 5.0),\n            'num_reviews': np.random.randint(0, 500),\n            'publications_count': pubs,\n            'consultation_completion_rate': np.random.uniform(0.75, 1.0),\n            'expertise_description': expertise_desc\n        }\n        doctors.append(doctor)\n    \n    return pd.DataFrame(doctors)\n\ndoctors_df = generate_doctors(N_DOCTORS)\nprint(f\"\\nGenerated {len(doctors_df)} doctors\")\nprint(f\"Specialty distribution:\\n{doctors_df['specialty'].value_counts().head(10)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T10:28:13.795188Z","iopub.execute_input":"2026-02-13T10:28:13.795505Z","iopub.status.idle":"2026-02-13T10:28:14.014086Z","shell.execute_reply.started":"2026-02-13T10:28:13.795473Z","shell.execute_reply":"2026-02-13T10:28:14.012978Z"}},"outputs":[{"name":"stderr","text":"Generating doctors: 100%|██████████| 500/500 [00:00<00:00, 3039.75it/s]","output_type":"stream"},{"name":"stdout","text":"\nGenerated 500 doctors\nSpecialty distribution:\nspecialty\nGeneral Medicine    59\nPediatrics          39\nGynecology          33\nENT                 26\nDermatology         25\nOrthopedics         23\nGeneral Surgery     23\nNeurology           22\nOphthalmology       22\nCardiology          17\nName: count, dtype: int64\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":3},{"id":"87aa8c51-0114-427f-b04a-3192b5a51f95","cell_type":"code","source":"# ============================================================\n# CELL 4: Generate Patient Cases\n# ============================================================\n# Symptom templates by specialty\nSYMPTOM_TEMPLATES = {\n    \"General Medicine\": [\n        \"fever and body aches for {duration}\",\n        \"persistent fatigue and weakness\",\n        \"recurring headaches and dizziness\",\n        \"unexplained weight loss\",\n        \"general weakness and loss of appetite\"\n    ],\n    \"Cardiology\": [\n        \"chest pain radiating to left arm\",\n        \"shortness of breath on exertion\",\n        \"palpitations and irregular heartbeat\",\n        \"swelling in legs and ankles\",\n        \"high blood pressure symptoms\"\n    ],\n    \"Neurology\": [\n        \"severe migraine headaches\",\n        \"numbness in extremities\",\n        \"difficulty with balance and coordination\",\n        \"memory problems and confusion\",\n        \"seizures and loss of consciousness\"\n    ],\n    \"Orthopedics\": [\n        \"chronic back pain\",\n        \"knee pain when climbing stairs\",\n        \"shoulder pain limiting movement\",\n        \"joint stiffness in the morning\",\n        \"pain after sports injury\"\n    ],\n    \"Dermatology\": [\n        \"persistent skin rash\",\n        \"acne that won't clear\",\n        \"unexplained hair loss\",\n        \"skin discoloration patches\",\n        \"itching and dry skin\"\n    ],\n    \"Pediatrics\": [\n        \"child has high fever\",\n        \"child not eating properly\",\n        \"delayed developmental milestones\",\n        \"frequent ear infections\",\n        \"child has persistent cough\"\n    ],\n    # Add more as needed - use General Medicine as default\n}\n\ndef get_symptom_description(specialty, severity, duration):\n    \"\"\"Generate symptom description based on specialty.\"\"\"\n    templates = SYMPTOM_TEMPLATES.get(specialty, SYMPTOM_TEMPLATES[\"General Medicine\"])\n    base_symptom = np.random.choice(templates).format(duration=duration)\n    \n    if severity == \"severe\":\n        prefix = \"Experiencing severe \"\n        suffix = \" This is significantly affecting daily activities.\"\n    elif severity == \"moderate\":\n        prefix = \"Having \"\n        suffix = \" Looking for treatment options.\"\n    else:\n        prefix = \"Mild \"\n        suffix = \" Would like to get it checked.\"\n    \n    return prefix + base_symptom + suffix\n\ndef generate_cases(n_cases=15000, doctors_df=None):\n    \"\"\"Generate synthetic patient cases.\"\"\"\n    cases = []\n    \n    # Context distribution\n    context_probs = {\n        'routine': 0.60,\n        'complex': 0.15,\n        'rare_disease': 0.10,\n        'emergency': 0.10,\n        'pediatric': 0.05\n    }\n    contexts = list(context_probs.keys())\n    probs = list(context_probs.values())\n    \n    for i in tqdm(range(n_cases), desc=\"Generating cases\"):\n        # Determine context\n        context = np.random.choice(contexts, p=probs)\n        \n        # Age based on context\n        if context == 'pediatric':\n            age = np.random.randint(0, 18)\n        elif context == 'geriatric':\n            age = np.random.randint(65, 90)\n        else:\n            age = np.random.randint(18, 80)\n        \n        # Urgency based on context\n        if context == 'emergency':\n            urgency = 'emergency'\n        elif context == 'complex':\n            urgency = np.random.choice(['semi_urgent', 'urgent'], p=[0.6, 0.4])\n        else:\n            urgency = np.random.choice(['routine', 'semi_urgent'], p=[0.7, 0.3])\n        \n        # Severity\n        if context == 'emergency':\n            severity = np.random.choice(['severe', 'critical'], p=[0.4, 0.6])\n        elif context == 'complex':\n            severity = np.random.choice(['moderate', 'severe'], p=[0.5, 0.5])\n        else:\n            severity = np.random.choice(['mild', 'moderate'], p=[0.6, 0.4])\n        \n        # Target specialty\n        if context == 'pediatric':\n            target_specialty = 'Pediatrics'\n        elif context == 'rare_disease':\n            # Rare specialties\n            rare_specs = ['Rheumatology', 'Hematology', 'Oncology', \n                         'Neurosurgery', 'Tropical Medicine']\n            target_specialty = np.random.choice(rare_specs)\n        else:\n            target_specialty = np.random.choice(SPECIALTIES, p=SPECIALTY_PROBS)\n        \n        # Location\n        city_idx = np.random.randint(len(CITIES))\n        city, state, lat, lon = CITIES[city_idx]\n        lat += np.random.normal(0, 0.15)\n        lon += np.random.normal(0, 0.15)\n        \n        # Duration\n        duration = np.random.choice(['2 days', '3 days', '1 week', \n                                     '2 weeks', '1 month', '3 months'])\n        \n        # Symptom description\n        symptom_desc = get_symptom_description(target_specialty, severity, duration)\n        \n        # Comorbidities (more for complex cases)\n        if context == 'complex':\n            comorbidity_count = np.random.randint(2, 5)\n        elif age > 60:\n            comorbidity_count = np.random.randint(0, 3)\n        else:\n            comorbidity_count = np.random.randint(0, 2)\n        \n        # Disease rarity score\n        if context == 'rare_disease':\n            rarity_score = np.random.uniform(0.7, 1.0)\n        else:\n            rarity_score = np.random.uniform(0.0, 0.3)\n        \n        # Red flag score\n        if context == 'emergency':\n            red_flag = np.random.uniform(0.7, 1.0)\n        elif severity in ['severe', 'critical']:\n            red_flag = np.random.uniform(0.4, 0.8)\n        else:\n            red_flag = np.random.uniform(0.0, 0.3)\n        \n        case = {\n            'case_id': f'CASE_{i:05d}',\n            'patient_age': age,\n            'patient_gender': np.random.choice(['M', 'F', 'Other'], p=[0.48, 0.50, 0.02]),\n            'symptom_description': symptom_desc,\n            'duration': duration,\n            'severity': severity,\n            'city': city,\n            'state': state,\n            'lat': lat,\n            'lon': lon,\n            'preferred_language': np.random.choice(LANGUAGES, p=[0.4, 0.25, 0.08, 0.07, \n                                                                  0.06, 0.05, 0.04, 0.03, 0.02]),\n            'preferred_mode': np.random.choice(['online', 'in_person', 'no_preference'],\n                                               p=[0.35, 0.25, 0.40]),\n            'budget_min': np.random.randint(2, 10) * 100,\n            'budget_max': np.random.randint(20, 50) * 100,\n            'urgency_level': urgency,\n            'context_category': context,\n            'target_specialty': target_specialty,\n            'target_specialty_idx': SPECIALTIES.index(target_specialty),\n            'red_flag_score': red_flag,\n            'comorbidity_count': comorbidity_count,\n            'disease_rarity_score': rarity_score,\n            'symptom_count': np.random.randint(1, 8)\n        }\n        cases.append(case)\n    \n    return pd.DataFrame(cases)\n\ncases_df = generate_cases(N_CASES, doctors_df)\nprint(f\"\\nGenerated {len(cases_df)} cases\")\nprint(f\"Context distribution:\\n{cases_df['context_category'].value_counts()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T10:28:14.016479Z","iopub.execute_input":"2026-02-13T10:28:14.016947Z","iopub.status.idle":"2026-02-13T10:28:18.708292Z","shell.execute_reply.started":"2026-02-13T10:28:14.016914Z","shell.execute_reply":"2026-02-13T10:28:18.707444Z"}},"outputs":[{"name":"stderr","text":"Generating cases: 100%|██████████| 15000/15000 [00:04<00:00, 3289.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nGenerated 15000 cases\nContext distribution:\ncontext_category\nroutine         8993\ncomplex         2266\nrare_disease    1521\nemergency       1476\npediatric        744\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":4},{"id":"9e6541e0-ec8d-4f88-b1ca-2eda26ed4b33","cell_type":"code","source":"# ============================================================\n# CELL 5: Compute Embeddings\n# ============================================================\nprint(\"Loading embedding model...\")\nencoder = SentenceTransformer('all-MiniLM-L6-v2')\nprint(f\"Embedding dimension: {encoder.get_sentence_embedding_dimension()}\")\n\n# Doctor embeddings\nprint(\"\\nComputing doctor embeddings...\")\ndoctor_texts = doctors_df['expertise_description'].tolist()\ndoctor_embeddings = encoder.encode(doctor_texts, show_progress_bar=True, \n                                   convert_to_tensor=True)\nprint(f\"Doctor embeddings shape: {doctor_embeddings.shape}\")\n\n# Case embeddings\nprint(\"\\nComputing case embeddings...\")\ncase_texts = cases_df['symptom_description'].tolist()\ncase_embeddings = encoder.encode(case_texts, show_progress_bar=True,\n                                 convert_to_tensor=True, batch_size=64)\nprint(f\"Case embeddings shape: {case_embeddings.shape}\")\n\n# Save embeddings\ntorch.save(doctor_embeddings, '/kaggle/working/data/doctor_embeddings.pt')\ntorch.save(case_embeddings, '/kaggle/working/data/case_embeddings.pt')\nprint(\"Embeddings saved!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T10:28:18.709544Z","iopub.execute_input":"2026-02-13T10:28:18.710046Z","iopub.status.idle":"2026-02-13T10:29:21.673068Z","shell.execute_reply.started":"2026-02-13T10:28:18.710012Z","shell.execute_reply":"2026-02-13T10:29:21.672136Z"}},"outputs":[{"name":"stdout","text":"Loading embedding model...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6c4f60bc6b9438f8ea51c778aec6e5c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74770359f8a7436da206a1ef51520f19"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2a096515c5e44c29d6c1a5bbd671841"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af9dce0799934e79b28c587a12b750e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44b95a02e1c648c5b2ead12ac414d4f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68ea45363e9f498489f1d9fe8f3660e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02bde0c7cdf84e038fcbf38963d50697"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e494c42dc643445a80e559d1ca531e53"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d274beea5c941c0b3d9737a0b8cc6d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a8ba583f06c4913bb5a4f011fffe340"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c81864c38504c3484dbdfcb57a404af"}},"metadata":{}},{"name":"stdout","text":"Embedding dimension: 384\n\nComputing doctor embeddings...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/16 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11d1188cc8664275a996161827b47c27"}},"metadata":{}},{"name":"stdout","text":"Doctor embeddings shape: torch.Size([500, 384])\n\nComputing case embeddings...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/235 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df700c1c6f344fb18a555e0c5597bb9a"}},"metadata":{}},{"name":"stdout","text":"Case embeddings shape: torch.Size([15000, 384])\nEmbeddings saved!\n","output_type":"stream"}],"execution_count":5},{"id":"c98df4e0-c33f-4dec-a7ed-ce49f2a823de","cell_type":"code","source":"# ============================================================\n# CELL 6: Compute Relevance Labels and Select Doctors per Case\n# ============================================================\ndef haversine_distance(lat1, lon1, lat2, lon2):\n    \"\"\"Compute haversine distance in km.\"\"\"\n    R = 6371  # Earth radius in km\n    \n    lat1, lat2 = np.radians(lat1), np.radians(lat2)\n    lon1, lon2 = np.radians(lon1), np.radians(lon2)\n    \n    dlat = lat2 - lat1\n    dlon = lon2 - lon1\n    \n    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n    c = 2 * np.arcsin(np.sqrt(a))\n    \n    return R * c\n\ndef compute_relevance(case, doctor):\n    \"\"\"\n    Compute relevance score (0-4) for a doctor-case pair.\n    \n    4 = Perfect match\n    3 = Good match  \n    2 = Fair match\n    1 = Marginal match\n    0 = Not relevant\n    \"\"\"\n    score = 0\n    \n    # Specialty match (most important)\n    if doctor['specialty'] == case['target_specialty']:\n        score += 2.0\n    elif doctor['specialty_idx'] // 5 == case['target_specialty_idx'] // 5:\n        # Same specialty group\n        score += 1.0\n    \n    # Availability\n    if doctor['availability_score'] > 0.7:\n        score += 0.5\n    elif doctor['availability_score'] > 0.5:\n        score += 0.25\n    \n    # Location (for non-online preference)\n    if case['preferred_mode'] != 'online':\n        dist = haversine_distance(case['lat'], case['lon'], \n                                  doctor['lat'], doctor['lon'])\n        if dist < 20:\n            score += 0.5\n        elif dist < 50:\n            score += 0.25\n    \n    # Language match\n    if case['preferred_language'] in doctor['languages']:\n        score += 0.3\n    \n    # Mode match\n    if case['preferred_mode'] == 'no_preference':\n        score += 0.2\n    elif doctor['available_modes'] == 'both':\n        score += 0.2\n    elif doctor['available_modes'] == case['preferred_mode']:\n        score += 0.3\n    \n    # Fee match\n    if doctor['consultation_fee'] <= case['budget_max']:\n        if doctor['consultation_fee'] >= case['budget_min']:\n            score += 0.2\n        else:\n            score += 0.1\n    \n    # Trust factors\n    if doctor['nmc_verified']:\n        score += 0.2\n    if doctor['review_score'] > 4.0:\n        score += 0.2\n    \n    # Experience for complex/rare cases\n    if case['context_category'] in ['complex', 'rare_disease']:\n        if doctor['years_experience'] > 15:\n            score += 0.3\n        if doctor['publications_count'] > 20:\n            score += 0.2\n    \n    # Convert to 0-4 scale\n    if score >= 3.0:\n        return 4\n    elif score >= 2.0:\n        return 3\n    elif score >= 1.0:\n        return 2\n    elif score >= 0.5:\n        return 1\n    else:\n        return 0\n\nprint(\"Computing relevance labels and selecting doctors per case...\")\n\n# For each case, compute relevance for all doctors, then select top-50 + 50 random\nall_doctor_indices = []\nall_relevance_labels = []\n\ndoctors_array = doctors_df.to_dict('records')\ncases_array = cases_df.to_dict('records')\n\nfor case_idx in tqdm(range(N_CASES), desc=\"Processing cases\"):\n    case = cases_array[case_idx]\n    \n    # Compute relevance for all doctors\n    relevances = []\n    for doc_idx in range(N_DOCTORS):\n        doctor = doctors_array[doc_idx]\n        rel = compute_relevance(case, doctor)\n        relevances.append(rel)\n    \n    relevances = np.array(relevances)\n    \n    # Get top-50 by relevance\n    top_50_indices = np.argsort(-relevances)[:50]\n    \n    # Get 50 random from remaining\n    remaining = np.setdiff1d(np.arange(N_DOCTORS), top_50_indices)\n    random_50_indices = np.random.choice(remaining, 50, replace=False)\n    \n    # Combine\n    selected_indices = np.concatenate([top_50_indices, random_50_indices])\n    selected_relevances = relevances[selected_indices]\n    \n    all_doctor_indices.append(selected_indices)\n    all_relevance_labels.append(selected_relevances)\n\ndoctor_indices = np.stack(all_doctor_indices)  # (15000, 100)\nrelevance_labels = np.stack(all_relevance_labels)  # (15000, 100)\n\nprint(f\"Doctor indices shape: {doctor_indices.shape}\")\nprint(f\"Relevance labels shape: {relevance_labels.shape}\")\nprint(f\"Relevance distribution: {np.bincount(relevance_labels.flatten())}\")\n\n# Save\nnp.save('/kaggle/working/data/doctor_indices.npy', doctor_indices)\nnp.save('/kaggle/working/data/relevance_labels.npy', relevance_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T10:29:21.674600Z","iopub.execute_input":"2026-02-13T10:29:21.675610Z","iopub.status.idle":"2026-02-13T10:30:39.553015Z","shell.execute_reply.started":"2026-02-13T10:29:21.675576Z","shell.execute_reply":"2026-02-13T10:30:39.551930Z"}},"outputs":[{"name":"stdout","text":"Computing relevance labels and selecting doctors per case...\n","output_type":"stream"},{"name":"stderr","text":"Processing cases: 100%|██████████| 15000/15000 [01:17<00:00, 193.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Doctor indices shape: (15000, 100)\nRelevance labels shape: (15000, 100)\nRelevance distribution: [ 20831 227505 578733 467602 205329]\n","output_type":"stream"}],"execution_count":6},{"id":"34bc54b1-8bc0-4e7b-bf39-513e78fd0427","cell_type":"code","source":"# ============================================================\n# CELL 7: Extract Features for Selected Doctor-Case Pairs\n# ============================================================\ndef extract_features(case_idx, doc_local_idx, cases_df, doctors_df,\n                     case_embeddings, doctor_embeddings, doctor_indices):\n    \"\"\"Extract all features for a doctor-case pair.\"\"\"\n    case = cases_df.iloc[case_idx]\n    doc_global_idx = doctor_indices[case_idx, doc_local_idx]\n    doctor = doctors_df.iloc[doc_global_idx]\n    \n    case_emb = case_embeddings[case_idx]\n    doc_emb = doctor_embeddings[doc_global_idx]\n    \n    # Clinical features (4)\n    cos_sim = torch.nn.functional.cosine_similarity(\n        case_emb.unsqueeze(0), doc_emb.unsqueeze(0)\n    ).item()\n    \n    specialty_match = 1.0 if doctor['specialty'] == case['target_specialty'] else \\\n                      0.5 if doctor['specialty_idx'] // 5 == case['target_specialty_idx'] // 5 else 0.0\n    subspecialty_match = 0.5 if specialty_match > 0 else 0.0  # Simplified\n    keyword_overlap = 0.3  # Placeholder - would compute properly with tokenization\n    \n    clinical = [cos_sim, specialty_match, subspecialty_match, keyword_overlap]\n    \n    # PastWork features (5)\n    pub_impact = min(doctor['publications_count'] / 50, 1.0)\n    topic_relevance = cos_sim * 0.8  # Simplified\n    experience = min(doctor['years_experience'] / 25, 1.0)\n    platform_perf = doctor['consultation_completion_rate']\n    reputation = (doctor['review_score'] - 2.5) / 2.5 * 0.7 + 0.3\n    \n    pastwork = [pub_impact, topic_relevance, experience, platform_perf, reputation]\n    \n    # Logistics features (5)\n    availability = doctor['availability_score']\n    language_match = 1.0 if case['preferred_language'] in doctor['languages'] else \\\n                     0.5 if 'English' in doctor['languages'] else 0.0\n    \n    dist = haversine_distance(case['lat'], case['lon'], doctor['lat'], doctor['lon'])\n    proximity = 1.0 - min(dist / 100, 1.0)\n    \n    fee = doctor['consultation_fee']\n    if case['budget_min'] <= fee <= case['budget_max']:\n        fee_match = 1.0\n    elif fee < case['budget_min']:\n        fee_match = 0.8\n    else:\n        fee_match = max(0, 1.0 - (fee - case['budget_max']) / case['budget_max'])\n    \n    if case['preferred_mode'] == 'no_preference' or doctor['available_modes'] == 'both':\n        mode_match = 1.0\n    elif case['preferred_mode'] == doctor['available_modes']:\n        mode_match = 1.0\n    else:\n        mode_match = 0.3\n    \n    logistics = [availability, language_match, proximity, fee_match, mode_match]\n    \n    # Trust features (3)\n    nmc = 1.0 if doctor['nmc_verified'] else 0.0\n    completeness = doctor['profile_completeness']\n    review = (doctor['review_score'] - 2.5) / 2.5\n    \n    trust = [nmc, completeness, review]\n    \n    return clinical, pastwork, logistics, trust\n\n# Extract features for all selected pairs\nprint(\"Extracting features for all selected doctor-case pairs...\")\n\nclinical_features = np.zeros((N_CASES, DOCTORS_PER_CASE, 4), dtype=np.float32)\npastwork_features = np.zeros((N_CASES, DOCTORS_PER_CASE, 5), dtype=np.float32)\nlogistics_features = np.zeros((N_CASES, DOCTORS_PER_CASE, 5), dtype=np.float32)\ntrust_features = np.zeros((N_CASES, DOCTORS_PER_CASE, 3), dtype=np.float32)\n\nfor case_idx in tqdm(range(N_CASES), desc=\"Extracting features\"):\n    for doc_local_idx in range(DOCTORS_PER_CASE):\n        clinical, pastwork, logistics, trust = extract_features(\n            case_idx, doc_local_idx, cases_df, doctors_df,\n            case_embeddings, doctor_embeddings, doctor_indices\n        )\n        clinical_features[case_idx, doc_local_idx] = clinical\n        pastwork_features[case_idx, doc_local_idx] = pastwork\n        logistics_features[case_idx, doc_local_idx] = logistics\n        trust_features[case_idx, doc_local_idx] = trust\n\n# Context features (8) - per case\ncontext_features = np.zeros((N_CASES, 8), dtype=np.float32)\nurgency_map = {'routine': 0, 'semi_urgent': 1, 'urgent': 2, 'emergency': 3}\n\nfor i, case in cases_df.iterrows():\n    context_features[i] = [\n        urgency_map[case['urgency_level']] / 3.0,\n        case['symptom_count'] / 8.0,\n        case['red_flag_score'],\n        case['patient_age'] / 90.0,\n        case['comorbidity_count'] / 5.0,\n        case['disease_rarity_score'],\n        1.0 if case['patient_age'] < 18 else 0.0,\n        1.0 if case['urgency_level'] == 'emergency' else 0.0\n    ]\n\nprint(f\"Clinical features shape: {clinical_features.shape}\")\nprint(f\"Context features shape: {context_features.shape}\")\n\n# Save all features\ntorch.save(torch.tensor(clinical_features), '/kaggle/working/data/clinical_features.pt')\ntorch.save(torch.tensor(pastwork_features), '/kaggle/working/data/pastwork_features.pt')\ntorch.save(torch.tensor(logistics_features), '/kaggle/working/data/logistics_features.pt')\ntorch.save(torch.tensor(trust_features), '/kaggle/working/data/trust_features.pt')\ntorch.save(torch.tensor(context_features), '/kaggle/working/data/context_features.pt')\ntorch.save(torch.tensor(relevance_labels), '/kaggle/working/data/relevance_labels.pt')\ntorch.save(torch.tensor(doctor_indices), '/kaggle/working/data/doctor_indices.pt')\n\n# Save metadata\ncase_metadata = {\n    'context_category': cases_df['context_category'].tolist(),\n    'urgency_level': cases_df['urgency_level'].tolist(),\n    'target_specialty': cases_df['target_specialty'].tolist()\n}\ntorch.save(case_metadata, '/kaggle/working/data/case_metadata.pt')\n\n# Save dataframes\ndoctors_df.to_parquet('/kaggle/working/data/doctors.parquet')\ncases_df.to_parquet('/kaggle/working/data/cases.parquet')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T10:30:39.554106Z","iopub.execute_input":"2026-02-13T10:30:39.554375Z","iopub.status.idle":"2026-02-13T10:39:46.134993Z","shell.execute_reply.started":"2026-02-13T10:30:39.554350Z","shell.execute_reply":"2026-02-13T10:39:46.133941Z"}},"outputs":[{"name":"stdout","text":"Extracting features for all selected doctor-case pairs...\n","output_type":"stream"},{"name":"stderr","text":"Extracting features: 100%|██████████| 15000/15000 [09:04<00:00, 27.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Clinical features shape: (15000, 100, 4)\nContext features shape: (15000, 8)\n","output_type":"stream"}],"execution_count":7},{"id":"cc81e626-62ca-4ad7-b47f-b1a7b0e007c5","cell_type":"code","source":"# ============================================================\n# CELL 8: Compute MCDA Teacher Scores\n# ============================================================\nprint(\"Computing MCDA teacher scores...\")\n\ndef compute_mcda_score(clinical, pastwork, logistics, trust):\n    \"\"\"Compute static MCDA score.\"\"\"\n    c_weights = [0.55, 0.20, 0.15, 0.10]\n    p_weights = [0.30, 0.25, 0.20, 0.15, 0.10]\n    l_weights = [0.30, 0.25, 0.20, 0.15, 0.10]\n    t_weights = [0.50, 0.30, 0.20]\n    \n    c_score = sum(c * w for c, w in zip(clinical, c_weights))\n    p_score = sum(p * w for p, w in zip(pastwork, p_weights))\n    l_score = sum(l * w for l, w in zip(logistics, l_weights))\n    t_score = sum(t * w for t, w in zip(trust, t_weights))\n    \n    return 0.40 * c_score + 0.25 * p_score + 0.25 * l_score + 0.10 * t_score\n\nmcda_scores = np.zeros((N_CASES, DOCTORS_PER_CASE), dtype=np.float32)\n\nfor i in tqdm(range(N_CASES), desc=\"Computing MCDA scores\"):\n    for j in range(DOCTORS_PER_CASE):\n        mcda_scores[i, j] = compute_mcda_score(\n            clinical_features[i, j],\n            pastwork_features[i, j],\n            logistics_features[i, j],\n            trust_features[i, j]\n        )\n\ntorch.save(torch.tensor(mcda_scores), '/kaggle/working/data/mcda_scores.pt')\nprint(f\"MCDA scores shape: {mcda_scores.shape}\")\nprint(f\"MCDA score range: [{mcda_scores.min():.3f}, {mcda_scores.max():.3f}]\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T10:39:46.136162Z","iopub.execute_input":"2026-02-13T10:39:46.136506Z","iopub.status.idle":"2026-02-13T10:40:06.269411Z","shell.execute_reply.started":"2026-02-13T10:39:46.136477Z","shell.execute_reply":"2026-02-13T10:40:06.268451Z"}},"outputs":[{"name":"stdout","text":"Computing MCDA teacher scores...\n","output_type":"stream"},{"name":"stderr","text":"Computing MCDA scores: 100%|██████████| 15000/15000 [00:20<00:00, 745.96it/s]","output_type":"stream"},{"name":"stdout","text":"MCDA scores shape: (15000, 100)\nMCDA score range: [0.200, 0.730]\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":8},{"id":"ac587ff8-1d45-413c-b74c-12e7ab93daa7","cell_type":"code","source":"# ============================================================\n# CELL 9: Create Train/Val/Test Splits\n# ============================================================\nfrom sklearn.model_selection import train_test_split\n\n# Stratified split by context category\ncontexts = cases_df['context_category'].values\nindices = np.arange(N_CASES)\n\n# First split: train+val vs test\ntrain_val_idx, test_idx = train_test_split(\n    indices, test_size=0.15, stratify=contexts, random_state=42\n)\n\n# Second split: train vs val\ntrain_idx, val_idx = train_test_split(\n    train_val_idx, test_size=0.15/0.85, \n    stratify=contexts[train_val_idx], random_state=42\n)\n\nprint(f\"Train size: {len(train_idx)}\")\nprint(f\"Val size: {len(val_idx)}\")\nprint(f\"Test size: {len(test_idx)}\")\n\n# Verify stratification\nfor split_name, split_idx in [('Train', train_idx), ('Val', val_idx), ('Test', test_idx)]:\n    split_contexts = contexts[split_idx]\n    print(f\"\\n{split_name} context distribution:\")\n    unique, counts = np.unique(split_contexts, return_counts=True)\n    for ctx, cnt in zip(unique, counts):\n        print(f\"  {ctx}: {cnt} ({cnt/len(split_idx)*100:.1f}%)\")\n\n# Save splits\nsplits = {\n    'train': train_idx.tolist(),\n    'val': val_idx.tolist(),\n    'test': test_idx.tolist()\n}\ntorch.save(splits, '/kaggle/working/data/splits.pt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T10:40:06.270747Z","iopub.execute_input":"2026-02-13T10:40:06.271684Z","iopub.status.idle":"2026-02-13T10:40:06.384401Z","shell.execute_reply.started":"2026-02-13T10:40:06.271650Z","shell.execute_reply":"2026-02-13T10:40:06.383369Z"}},"outputs":[{"name":"stdout","text":"Train size: 10500\nVal size: 2250\nTest size: 2250\n\nTrain context distribution:\n  complex: 1586 (15.1%)\n  emergency: 1034 (9.8%)\n  pediatric: 520 (5.0%)\n  rare_disease: 1065 (10.1%)\n  routine: 6295 (60.0%)\n\nVal context distribution:\n  complex: 340 (15.1%)\n  emergency: 221 (9.8%)\n  pediatric: 112 (5.0%)\n  rare_disease: 228 (10.1%)\n  routine: 1349 (60.0%)\n\nTest context distribution:\n  complex: 340 (15.1%)\n  emergency: 221 (9.8%)\n  pediatric: 112 (5.0%)\n  rare_disease: 228 (10.1%)\n  routine: 1349 (60.0%)\n","output_type":"stream"}],"execution_count":9},{"id":"cebc173a-6fbf-4be5-afdd-f217f8366015","cell_type":"code","source":"# ============================================================\n# CELL 10: Summary and Verification\n# ============================================================\nprint(\"\\n\" + \"=\" * 60)\nprint(\"DATA GENERATION COMPLETE\")\nprint(\"=\" * 60)\n\nimport os\ndata_dir = '/kaggle/working/data'\nfiles = os.listdir(data_dir)\nprint(f\"\\nGenerated files:\")\ntotal_size = 0\nfor f in sorted(files):\n    path = os.path.join(data_dir, f)\n    size = os.path.getsize(path) / (1024 * 1024)  # MB\n    total_size += size\n    print(f\"  {f}: {size:.2f} MB\")\nprint(f\"\\nTotal size: {total_size:.2f} MB\")\n\nprint(f\"\\nDataset Statistics:\")\nprint(f\"  - Doctors: {N_DOCTORS}\")\nprint(f\"  - Cases: {N_CASES}\")\nprint(f\"  - Doctors per case: {DOCTORS_PER_CASE}\")\nprint(f\"  - Total pairs: {N_CASES * DOCTORS_PER_CASE:,}\")\nprint(f\"  - Embedding dimension: 384\")\nprint(f\"  - Feature dimensions: clinical(4), pastwork(5), logistics(5), trust(3)\")\nprint(f\"  - Context dimension: 8\")\n\nprint(f\"\\nSplits:\")\nprint(f\"  - Train: {len(train_idx)} cases ({len(train_idx)/N_CASES*100:.1f}%)\")\nprint(f\"  - Val: {len(val_idx)} cases ({len(val_idx)/N_CASES*100:.1f}%)\")\nprint(f\"  - Test: {len(test_idx)} cases ({len(test_idx)/N_CASES*100:.1f}%)\")\n\nprint(\"\\n✅ Data ready! Save this notebook output as a Kaggle Dataset.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T10:40:06.387296Z","iopub.execute_input":"2026-02-13T10:40:06.388863Z","iopub.status.idle":"2026-02-13T10:40:06.400406Z","shell.execute_reply.started":"2026-02-13T10:40:06.388824Z","shell.execute_reply":"2026-02-13T10:40:06.399201Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nDATA GENERATION COMPLETE\n============================================================\n\nGenerated files:\n  case_embeddings.pt: 21.97 MB\n  case_metadata.pt: 5.20 MB\n  cases.parquet: 0.79 MB\n  clinical_features.pt: 22.89 MB\n  context_features.pt: 0.46 MB\n  doctor_embeddings.pt: 0.73 MB\n  doctor_indices.npy: 11.44 MB\n  doctor_indices.pt: 11.45 MB\n  doctors.parquet: 0.06 MB\n  logistics_features.pt: 28.61 MB\n  mcda_scores.pt: 5.72 MB\n  pastwork_features.pt: 28.61 MB\n  relevance_labels.npy: 11.44 MB\n  relevance_labels.pt: 11.45 MB\n  splits.pt: 0.04 MB\n  trust_features.pt: 17.17 MB\n\nTotal size: 178.05 MB\n\nDataset Statistics:\n  - Doctors: 500\n  - Cases: 15000\n  - Doctors per case: 100\n  - Total pairs: 1,500,000\n  - Embedding dimension: 384\n  - Feature dimensions: clinical(4), pastwork(5), logistics(5), trust(3)\n  - Context dimension: 8\n\nSplits:\n  - Train: 10500 cases (70.0%)\n  - Val: 2250 cases (15.0%)\n  - Test: 2250 cases (15.0%)\n\n✅ Data ready! Save this notebook output as a Kaggle Dataset.\n","output_type":"stream"}],"execution_count":10}]}