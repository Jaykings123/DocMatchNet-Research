{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gate Activation Analysis\n",
    "========================\n",
    "Deep analysis of context-aware gate behavior for paper Section V.D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 1: Load Model and Data\n",
    "# ============================================================\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "DATA_DIR = '/kaggle/input/docmatchnet-jepa-data/data'\n",
    "\n",
    "doctor_embeddings = torch.load(f'{DATA_DIR}/doctor_embeddings.pt', weights_only=False)\n",
    "case_embeddings = torch.load(f'{DATA_DIR}/case_embeddings.pt', weights_only=False)\n",
    "clinical_features = torch.load(f'{DATA_DIR}/clinical_features.pt', weights_only=False)\n",
    "pastwork_features = torch.load(f'{DATA_DIR}/pastwork_features.pt', weights_only=False)\n",
    "logistics_features = torch.load(f'{DATA_DIR}/logistics_features.pt', weights_only=False)\n",
    "trust_features = torch.load(f'{DATA_DIR}/trust_features.pt', weights_only=False)\n",
    "context_features = torch.load(f'{DATA_DIR}/context_features.pt', weights_only=False)\n",
    "relevance_labels = torch.load(f'{DATA_DIR}/relevance_labels.pt', weights_only=False)\n",
    "doctor_indices = torch.load(f'{DATA_DIR}/doctor_indices.pt', weights_only=False)\n",
    "case_metadata = torch.load(f'{DATA_DIR}/case_metadata.pt', weights_only=False)\n",
    "splits = torch.load(f'{DATA_DIR}/splits.pt', weights_only=False)\n",
    "\n",
    "class DocMatchDatasetEval(Dataset):\n",
    "    def __init__(self, indices, case_emb, doc_emb, doc_indices,\n",
    "                 clinical, pastwork, logistics, trust, context,\n",
    "                 relevance, metadata):\n",
    "        self.indices = indices\n",
    "        self.case_emb = case_emb\n",
    "        self.doc_emb = doc_emb\n",
    "        self.doc_indices = doc_indices\n",
    "        self.clinical = clinical\n",
    "        self.pastwork = pastwork\n",
    "        self.logistics = logistics\n",
    "        self.trust = trust\n",
    "        self.context = context\n",
    "        self.relevance = relevance\n",
    "        self.metadata = metadata\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        case_idx = self.indices[idx]\n",
    "        doc_global_indices = self.doc_indices[case_idx]\n",
    "        return {\n",
    "            'case_embedding': self.case_emb[case_idx],\n",
    "            'doctor_embeddings': self.doc_emb[doc_global_indices],\n",
    "            'clinical': self.clinical[case_idx],\n",
    "            'pastwork': self.pastwork[case_idx],\n",
    "            'logistics': self.logistics[case_idx],\n",
    "            'trust': self.trust[case_idx],\n",
    "            'context': self.context[case_idx],\n",
    "            'relevance': self.relevance[case_idx],\n",
    "            'context_category': self.metadata['context_category'][case_idx]\n",
    "        }\n",
    "\n",
    "class DocMatchNetJEPA(nn.Module):\n",
    "    def __init__(self, embed_dim=384, latent_dim=256, gate_dim=32, context_dim=8, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.patient_encoder = nn.Sequential(\n",
    "            nn.Linear(embed_dim, 512), nn.LayerNorm(512), nn.GELU(), nn.Dropout(dropout),\n",
    "            nn.Linear(512, latent_dim), nn.LayerNorm(latent_dim)\n",
    "        )\n",
    "        self.doctor_encoder = nn.Sequential(\n",
    "            nn.Linear(embed_dim, 512), nn.LayerNorm(512), nn.GELU(), nn.Dropout(dropout),\n",
    "            nn.Linear(512, latent_dim), nn.LayerNorm(latent_dim)\n",
    "        )\n",
    "\n",
    "        self.clinical_encoder = self._make_encoder(4, gate_dim)\n",
    "        self.pastwork_encoder = self._make_encoder(5, gate_dim)\n",
    "        self.logistics_encoder = self._make_encoder(5, gate_dim)\n",
    "        self.trust_encoder = self._make_encoder(3, gate_dim)\n",
    "\n",
    "        gate_input_dim = latent_dim + context_dim\n",
    "        self.clinical_gate = self._make_gate(gate_input_dim, gate_dim)\n",
    "        self.pastwork_gate = self._make_gate(gate_input_dim, gate_dim)\n",
    "        self.logistics_gate = self._make_gate(gate_input_dim, gate_dim)\n",
    "        self.trust_gate = self._make_gate(gate_input_dim, gate_dim)\n",
    "        self._init_gate_biases()\n",
    "\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(latent_dim + gate_dim * 4, 256), nn.LayerNorm(256), nn.GELU(), nn.Dropout(dropout),\n",
    "            nn.Linear(256, 256), nn.LayerNorm(256), nn.GELU(), nn.Dropout(dropout),\n",
    "            nn.Linear(256, latent_dim)\n",
    "        )\n",
    "        self.predictor_proj = nn.Sequential(nn.Linear(latent_dim, latent_dim), nn.GELU(), nn.Linear(latent_dim, 128))\n",
    "        self.doctor_proj = nn.Sequential(nn.Linear(latent_dim, latent_dim), nn.GELU(), nn.Linear(latent_dim, 128))\n",
    "        self.log_temperature = nn.Parameter(torch.log(torch.tensor(0.07)))\n",
    "\n",
    "    def _make_encoder(self, input_dim, output_dim):\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim), nn.BatchNorm1d(output_dim), nn.GELU(),\n",
    "            nn.Linear(output_dim, output_dim), nn.BatchNorm1d(output_dim), nn.GELU()\n",
    "        )\n",
    "\n",
    "    def _make_gate(self, input_dim, output_dim):\n",
    "        return nn.Sequential(nn.Linear(input_dim, 64), nn.GELU(), nn.Linear(64, output_dim), nn.Sigmoid())\n",
    "\n",
    "    def _init_gate_biases(self):\n",
    "        nn.init.constant_(self.clinical_gate[-2].bias, 0.4)\n",
    "        nn.init.constant_(self.pastwork_gate[-2].bias, 0.0)\n",
    "        nn.init.constant_(self.logistics_gate[-2].bias, 0.0)\n",
    "        nn.init.constant_(self.trust_gate[-2].bias, -0.4)\n",
    "\n",
    "    def forward(self, patient_emb, doctor_emb, clinical, pastwork, logistics, trust, context):\n",
    "        patient_latent = self.patient_encoder(patient_emb)\n",
    "        doctor_latent = self.doctor_encoder(doctor_emb)\n",
    "\n",
    "        enc_clinical = self.clinical_encoder(clinical)\n",
    "        enc_pastwork = self.pastwork_encoder(pastwork)\n",
    "        enc_logistics = self.logistics_encoder(logistics)\n",
    "        enc_trust = self.trust_encoder(trust)\n",
    "\n",
    "        gate_input = torch.cat([patient_latent, context], dim=-1)\n",
    "        g_clinical = self.clinical_gate(gate_input)\n",
    "        g_pastwork = self.pastwork_gate(gate_input)\n",
    "        g_logistics = self.logistics_gate(gate_input)\n",
    "        g_trust = self.trust_gate(gate_input)\n",
    "\n",
    "        gated_features = torch.cat([\n",
    "            g_clinical * enc_clinical,\n",
    "            g_pastwork * enc_pastwork,\n",
    "            g_logistics * enc_logistics,\n",
    "            g_trust * enc_trust\n",
    "        ], dim=-1)\n",
    "\n",
    "        predictor_input = torch.cat([patient_latent, gated_features], dim=-1)\n",
    "        predicted_ideal = self.predictor(predictor_input)\n",
    "\n",
    "        pred_proj = self.predictor_proj(predicted_ideal)\n",
    "        doc_proj = self.doctor_proj(doctor_latent)\n",
    "\n",
    "        pred_norm = F.normalize(pred_proj, dim=-1)\n",
    "        doc_norm = F.normalize(doc_proj, dim=-1)\n",
    "        score = (pred_norm * doc_norm).sum(dim=-1, keepdim=True)\n",
    "        score = (score + 1) / 2\n",
    "\n",
    "        gate_means = {\n",
    "            'clinical': g_clinical.mean(dim=-1),\n",
    "            'pastwork': g_pastwork.mean(dim=-1),\n",
    "            'logistics': g_logistics.mean(dim=-1),\n",
    "            'trust': g_trust.mean(dim=-1)\n",
    "        }\n",
    "\n",
    "        return {\n",
    "            'score': score,\n",
    "            'predicted_ideal': pred_proj,\n",
    "            'doctor_embedding': doc_proj,\n",
    "            'gates': {\n",
    "                'clinical': g_clinical,\n",
    "                'pastwork': g_pastwork,\n",
    "                'logistics': g_logistics,\n",
    "                'trust': g_trust\n",
    "            },\n",
    "            'gate_means': gate_means,\n",
    "            'temperature': self.log_temperature.exp()\n",
    "        }\n",
    "\n",
    "# Load best JEPA model\n",
    "model = DocMatchNetJEPA().to(device)\n",
    "model.load_state_dict(torch.load('/kaggle/working/results/best_jepa_model.pt', map_location=device, weights_only=False))\n",
    "model.eval()\n",
    "\n",
    "# Load test data\n",
    "test_ds = DocMatchDatasetEval(\n",
    "    splits['test'], case_embeddings, doctor_embeddings, doctor_indices,\n",
    "    clinical_features, pastwork_features, logistics_features, trust_features,\n",
    "    context_features, relevance_labels, case_metadata\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 2: Collect Gate Activations for All Test Cases\n",
    "# ============================================================\n",
    "all_gate_activations = {\n",
    "    'clinical': [], 'pastwork': [], 'logistics': [], 'trust': []\n",
    "}\n",
    "all_contexts = []\n",
    "all_urgencies = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_ds)):\n",
    "        sample = test_ds[i]\n",
    "        case_emb = sample['case_embedding'].unsqueeze(0).to(device)\n",
    "        context = sample['context'].unsqueeze(0).to(device)\n",
    "\n",
    "        # Use first doctor's features to compute gates\n",
    "        # (gates depend on patient + context, not on specific doctor)\n",
    "        doc_emb = sample['doctor_embeddings'][0:1].to(device)\n",
    "        clinical = sample['clinical'][0:1].to(device)\n",
    "        pastwork = sample['pastwork'][0:1].to(device)\n",
    "        logistics = sample['logistics'][0:1].to(device)\n",
    "        trust = sample['trust'][0:1].to(device)\n",
    "\n",
    "        output = model(case_emb, doc_emb, clinical, pastwork,\n",
    "                      logistics, trust, context)\n",
    "\n",
    "        for gate_name in all_gate_activations:\n",
    "            all_gate_activations[gate_name].append(\n",
    "                output['gate_means'][gate_name].item()\n",
    "            )\n",
    "\n",
    "        all_contexts.append(sample['context_category'])\n",
    "        urgency_val = context[0, 0].item()  # First context feature = urgency\n",
    "        all_urgencies.append(urgency_val)\n",
    "\n",
    "# Convert to arrays\n",
    "for gate in all_gate_activations:\n",
    "    all_gate_activations[gate] = np.array(all_gate_activations[gate])\n",
    "all_contexts = np.array(all_contexts)\n",
    "\n",
    "print(f\"Collected gates for {len(all_contexts)} test cases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 3: Statistical Tests - Kruskal-Wallis\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"KRUSKAL-WALLIS TEST: Do gates differ across contexts?\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "contexts_unique = ['routine', 'complex', 'rare_disease', 'emergency', 'pediatric']\n",
    "statistical_results = {}\n",
    "\n",
    "for gate_name in ['clinical', 'pastwork', 'logistics', 'trust']:\n",
    "    groups = []\n",
    "    for ctx in contexts_unique:\n",
    "        mask = all_contexts == ctx\n",
    "        if mask.sum() > 5:\n",
    "            groups.append(all_gate_activations[gate_name][mask])\n",
    "\n",
    "    if len(groups) >= 2:\n",
    "        stat, p_value = stats.kruskal(*groups)\n",
    "\n",
    "        n_total = sum(len(g) for g in groups)\n",
    "        epsilon_sq = (stat - len(groups) + 1) / (n_total - len(groups))\n",
    "\n",
    "        statistical_results[gate_name] = {\n",
    "            'kruskal_stat': float(stat),\n",
    "            'p_value': float(p_value),\n",
    "            'epsilon_squared': float(epsilon_sq),\n",
    "            'significant': p_value < 0.05\n",
    "        }\n",
    "\n",
    "        sig = \"***\" if p_value < 0.001 else \"**\" if p_value < 0.01 else \"*\" if p_value < 0.05 else \"ns\"\n",
    "        print(f\"\\n{gate_name} gate:\")\n",
    "        print(f\"  H = {stat:.4f}, p = {p_value:.2e} {sig}\")\n",
    "        print(f\"  \u03b5\u00b2 = {epsilon_sq:.4f}\")\n",
    "\n",
    "        print(\"  Post-hoc pairwise comparisons:\")\n",
    "        for i, ctx_a in enumerate(contexts_unique):\n",
    "            for j, ctx_b in enumerate(contexts_unique):\n",
    "                if j <= i:\n",
    "                    continue\n",
    "                mask_a = all_contexts == ctx_a\n",
    "                mask_b = all_contexts == ctx_b\n",
    "                if mask_a.sum() > 5 and mask_b.sum() > 5:\n",
    "                    u_stat, u_p = stats.mannwhitneyu(\n",
    "                        all_gate_activations[gate_name][mask_a],\n",
    "                        all_gate_activations[gate_name][mask_b],\n",
    "                        alternative='two-sided'\n",
    "                    )\n",
    "                    sig_u = \"*\" if u_p < 0.05 / 10 else \"\"\n",
    "                    print(f\"    {ctx_a} vs {ctx_b}: U={u_stat:.0f}, p={u_p:.4e} {sig_u}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 4: Correlation Analysis\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"GATE CORRELATION ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "gate_matrix = np.column_stack([\n",
    "    all_gate_activations['clinical'],\n",
    "    all_gate_activations['pastwork'],\n",
    "    all_gate_activations['logistics'],\n",
    "    all_gate_activations['trust']\n",
    "])\n",
    "\n",
    "correlation_matrix = np.corrcoef(gate_matrix.T)\n",
    "gate_names = ['Clinical', 'PastWork', 'Logistics', 'Trust']\n",
    "\n",
    "print(\"\\nPearson Correlation Matrix:\")\n",
    "print(f\"{'':>12s}\", end=\"\")\n",
    "for name in gate_names:\n",
    "    print(f\"{name:>12s}\", end=\"\")\n",
    "print()\n",
    "\n",
    "for i, name_i in enumerate(gate_names):\n",
    "    print(f\"{name_i:>12s}\", end=\"\")\n",
    "    for j in range(len(gate_names)):\n",
    "        print(f\"{correlation_matrix[i, j]:>12.3f}\", end=\"\")\n",
    "    print()\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"Low correlations between gates = gates are learning DIFFERENT things (good!)\")\n",
    "print(\"High correlation would suggest redundancy (bad)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 5: Context-Specific Gate Statistics Table\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CONTEXT-SPECIFIC GATE MEANS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "context_gate_table = {}\n",
    "print(f\"\\n{'Context':<15} {'Clinical':>10} {'PastWork':>10} {'Logistics':>10} {'Trust':>10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for ctx in contexts_unique:\n",
    "    mask = all_contexts == ctx\n",
    "    if mask.sum() > 0:\n",
    "        row = {}\n",
    "        print(f\"{ctx:<15}\", end=\"\")\n",
    "        for gate in ['clinical', 'pastwork', 'logistics', 'trust']:\n",
    "            mean_val = all_gate_activations[gate][mask].mean()\n",
    "            row[gate] = float(mean_val)\n",
    "            print(f\"{mean_val:>10.4f}\", end=\"\")\n",
    "        print()\n",
    "        context_gate_table[ctx] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 6: Clinical Interpretation\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CLINICAL INTERPRETATION OF GATE PATTERNS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "interpretations = []\n",
    "\n",
    "if 'emergency' in context_gate_table:\n",
    "    emerg = context_gate_table['emergency']\n",
    "    routine = context_gate_table.get('routine', {})\n",
    "\n",
    "    if emerg.get('clinical', 0) > routine.get('clinical', 0):\n",
    "        interpretations.append(\n",
    "            \"Emergency cases show HIGHER clinical gate activation, \"\n",
    "            \"indicating the model prioritizes clinical expertise match \"\n",
    "            \"when urgency is high.\"\n",
    "        )\n",
    "\n",
    "    if emerg.get('logistics', 0) > routine.get('logistics', 0):\n",
    "        interpretations.append(\n",
    "            \"Emergency cases also elevate logistics gate, suggesting \"\n",
    "            \"proximity and availability become critical in emergencies.\"\n",
    "        )\n",
    "    elif emerg.get('logistics', 0) < routine.get('logistics', 0):\n",
    "        interpretations.append(\n",
    "            \"Emergency cases LOWER logistics gate, suggesting that \"\n",
    "            \"finding the RIGHT specialist matters more than convenience.\"\n",
    "        )\n",
    "\n",
    "if 'rare_disease' in context_gate_table:\n",
    "    rare = context_gate_table['rare_disease']\n",
    "\n",
    "    if rare.get('pastwork', 0) > context_gate_table.get('routine', {}).get('pastwork', 0):\n",
    "        interpretations.append(\n",
    "            \"Rare disease cases increase pastwork gate activation, \"\n",
    "            \"reflecting the importance of research publications and \"\n",
    "            \"specialized experience for rare conditions.\"\n",
    "        )\n",
    "\n",
    "if 'complex' in context_gate_table:\n",
    "    comp = context_gate_table['complex']\n",
    "\n",
    "    if comp.get('clinical', 0) > 0.5 and comp.get('pastwork', 0) > 0.5:\n",
    "        interpretations.append(\n",
    "            \"Complex multi-comorbidity cases activate BOTH clinical \"\n",
    "            \"and pastwork gates highly, indicating the model recognizes \"\n",
    "            \"that both expertise match and experience matter.\"\n",
    "        )\n",
    "\n",
    "print(\"\\nKey Findings:\")\n",
    "if len(interpretations) == 0:\n",
    "    print(\"\n1. No strong directional differences were detected under current checkpoints.\")\n",
    "else:\n",
    "    for i, interp in enumerate(interpretations, 1):\n",
    "        print(f\"\\n{i}. {interp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 7: Save Gate Analysis Results\n",
    "# ============================================================\n",
    "gate_analysis_results = {\n",
    "    'statistical_tests': statistical_results,\n",
    "    'correlation_matrix': correlation_matrix.tolist(),\n",
    "    'context_gate_table': context_gate_table,\n",
    "    'interpretations': interpretations,\n",
    "    'gate_per_case': {\n",
    "        gate: {ctx: all_gate_activations[gate][all_contexts == ctx].tolist()\n",
    "               for ctx in contexts_unique}\n",
    "        for gate in ['clinical', 'pastwork', 'logistics', 'trust']\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('/kaggle/working/results/gate_analysis_results.json', 'w') as f:\n",
    "    json.dump(gate_analysis_results, f, indent=2)\n",
    "\n",
    "print(\"\\n\u2705 Gate analysis results saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Clinical Case Studies\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "Clinical Case Studies\n",
    "=====================\n",
    "Detailed analysis of specific cases for paper Section V.G.\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================\n",
    "# Case Study 1: Emergency - Acute Chest Pain\n",
    "# ============================================================\n",
    "def analyze_case_study(case_idx, model, device):\n",
    "    \"\"\"\n",
    "    Detailed analysis of a single case.\n",
    "    Shows gate activations, top recommendations, and interpretation.\n",
    "    \"\"\"\n",
    "    sample = test_ds[case_idx]\n",
    "    case_emb = sample['case_embedding'].unsqueeze(0).to(device)\n",
    "    context = sample['context'].unsqueeze(0).to(device)\n",
    "    ctx_category = sample['context_category']\n",
    "    relevance = sample['relevance'].numpy()\n",
    "    \n",
    "    print(f\"\\n{'=' * 70}\")\n",
    "    print(f\"CASE STUDY: Case #{case_idx}\")\n",
    "    print(f\"Context Category: {ctx_category}\")\n",
    "    print(f\"Case Description: {cases_df.iloc[splits['test'][case_idx]]['symptom_description']}\")\n",
    "    print(f\"Target Specialty: {cases_df.iloc[splits['test'][case_idx]]['target_specialty']}\")\n",
    "    print(f\"Urgency: {cases_df.iloc[splits['test'][case_idx]]['urgency_level']}\")\n",
    "    print(f\"{'=' * 70}\")\n",
    "    \n",
    "    # Score all doctors\n",
    "    scores = []\n",
    "    gate_values = {g: [] for g in ['clinical', 'pastwork', 'logistics', 'trust']}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(sample['doctor_embeddings'].shape[0]):\n",
    "            doc_emb = sample['doctor_embeddings'][i:i+1].to(device)\n",
    "            clinical = sample['clinical'][i:i+1].to(device)\n",
    "            pastwork = sample['pastwork'][i:i+1].to(device)\n",
    "            logistics = sample['logistics'][i:i+1].to(device)\n",
    "            trust = sample['trust'][i:i+1].to(device)\n",
    "            \n",
    "            output = model(case_emb, doc_emb, clinical, pastwork,\n",
    "                          logistics, trust, context)\n",
    "            \n",
    "            scores.append(output['score'].item())\n",
    "            \n",
    "            if i == 0:  # Gates same for all doctors (depend on patient)\n",
    "                for g_name in gate_values:\n",
    "                    gate_values[g_name] = output['gate_means'][g_name].item()\n",
    "    \n",
    "    scores = np.array(scores)\n",
    "    \n",
    "    # Gate analysis\n",
    "    print(f\"\\nGate Activations:\")\n",
    "    for g_name, g_val in gate_values.items():\n",
    "        bar = '\u2588' * int(g_val * 30)\n",
    "        print(f\"  {g_name:>12s}: {g_val:.4f} |{bar}\")\n",
    "    \n",
    "    # Top 5 recommendations\n",
    "    top5_idx = np.argsort(-scores)[:5]\n",
    "    print(f\"\\nTop 5 Recommendations:\")\n",
    "    print(f\"{'Rank':>4s} {'Score':>8s} {'Relevance':>10s} {'Specialty':>25s} {'Experience':>12s}\")\n",
    "    print(\"-\" * 65)\n",
    "    \n",
    "    for rank, doc_local_idx in enumerate(top5_idx, 1):\n",
    "        doc_global_idx = doctor_indices[splits['test'][case_idx], doc_local_idx]\n",
    "        doctor = doctors_df.iloc[doc_global_idx]\n",
    "        \n",
    "        print(f\"{rank:>4d} {scores[doc_local_idx]:>8.4f} \"\n",
    "              f\"{relevance[doc_local_idx]:>10d} \"\n",
    "              f\"{doctor['specialty']:>25s} \"\n",
    "              f\"{doctor['years_experience']:>8d} yrs\")\n",
    "    \n",
    "    # Compare with MCDA ranking\n",
    "    mcda = mcda_scores[splits['test'][case_idx]]\n",
    "    mcda_top5 = np.argsort(-mcda)[:5]\n",
    "    \n",
    "    print(f\"\\nMCDA Top 5 for comparison:\")\n",
    "    for rank, doc_local_idx in enumerate(mcda_top5, 1):\n",
    "        doc_global_idx = doctor_indices[splits['test'][case_idx], doc_local_idx]\n",
    "        doctor = doctors_df.iloc[doc_global_idx]\n",
    "        print(f\"{rank:>4d} {mcda[doc_local_idx]:>8.4f} \"\n",
    "              f\"{relevance[doc_local_idx]:>10d} \"\n",
    "              f\"{doctor['specialty']:>25s}\")\n",
    "    \n",
    "    # NDCG comparison\n",
    "    jepa_ndcg5 = ndcg_at_k(scores, relevance, 5)\n",
    "    mcda_ndcg5 = ndcg_at_k(mcda, relevance, 5)\n",
    "    \n",
    "    print(f\"\\nNDCG@5: JEPA = {jepa_ndcg5:.4f}, MCDA = {mcda_ndcg5:.4f}\")\n",
    "    improvement = ((jepa_ndcg5 - mcda_ndcg5) / mcda_ndcg5 * 100) if mcda_ndcg5 > 0 else 0\n",
    "    print(f\"Improvement: {improvement:+.1f}%\")\n",
    "    \n",
    "    return {\n",
    "        'case_idx': case_idx,\n",
    "        'context': ctx_category,\n",
    "        'gate_activations': gate_values,\n",
    "        'jepa_ndcg5': jepa_ndcg5,\n",
    "        'mcda_ndcg5': mcda_ndcg5,\n",
    "        'improvement_pct': improvement\n",
    "    }\n",
    "\n",
    "\n",
    "# Find representative cases for each context\n",
    "case_studies = {}\n",
    "\n",
    "for target_ctx in ['emergency', 'rare_disease', 'routine', 'complex']:\n",
    "    # Find a case of this context type in test set\n",
    "    for i, ctx in enumerate(case_metadata['context_category']):\n",
    "        if i in splits['test'] and ctx == target_ctx:\n",
    "            test_local_idx = splits['test'].index(i)\n",
    "            result = analyze_case_study(test_local_idx, model, device)\n",
    "            case_studies[target_ctx] = result\n",
    "            break\n",
    "\n",
    "# Save case studies\n",
    "with open('/kaggle/working/results/case_studies.json', 'w') as f:\n",
    "    json.dump(case_studies, f, indent=2)\n",
    "\n",
    "print(\"\\n\u2705 Case studies complete!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}