{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate LaTeX Tables for Paper\n",
    "===============================\n",
    "Load all result JSONs and create publication-ready tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "RESULTS_DIR = '/kaggle/working/results'\n",
    "TABLE_DIR = '/kaggle/working/results/tables'\n",
    "os.makedirs(TABLE_DIR, exist_ok=True)\n",
    "\n",
    "def load_json(name):\n",
    "    candidates = [os.path.join(RESULTS_DIR, name), name]\n",
    "    for p in candidates:\n",
    "        if os.path.exists(p):\n",
    "            with open(p, 'r') as f:\n",
    "                return json.load(f)\n",
    "    raise FileNotFoundError(f'Could not find {name} in {candidates}')\n",
    "\n",
    "# Load all results\n",
    "jepa_results = load_json('jepa_results.json')\n",
    "original_results = load_json('original_results.json')\n",
    "baseline_results = load_json('baseline_results.json')\n",
    "ablation_results = load_json('ablation_results.json')\n",
    "sample_eff_results = load_json('sample_efficiency_results.json')\n",
    "\n",
    "def normalize_baseline(br):\n",
    "    aliases = {\n",
    "        'mcda': ['mcda', 'StaticMCDA'],\n",
    "        'mlp': ['mlp', 'SimpleMLP'],\n",
    "        'neural_ranker': ['neural_ranker', 'NeuralRanker'],\n",
    "        'din': ['din', 'DINModel']\n",
    "    }\n",
    "    out = {}\n",
    "    for key, keys in aliases.items():\n",
    "        found = {}\n",
    "        for k in keys:\n",
    "            if k in br:\n",
    "                found = br[k]\n",
    "                break\n",
    "        out[key] = found\n",
    "    return out\n",
    "\n",
    "baseline_results = normalize_baseline(baseline_results)\n",
    "\n",
    "print('Loaded all JSON files.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TABLE I: Main Results\n",
    "# ============================================================\n",
    "def _metric_mean(source, metric):\n",
    "    if source is None:\n",
    "        return np.nan\n",
    "    if 'overall' in source:\n",
    "        source = source['overall']\n",
    "    if metric in source and isinstance(source[metric], dict):\n",
    "        return float(source[metric].get('mean', np.nan))\n",
    "    if metric in source and isinstance(source[metric], (list, tuple)):\n",
    "        return float(source[metric][0])\n",
    "    return np.nan\n",
    "\n",
    "def generate_table_1():\n",
    "    methods = [\n",
    "        ('Rule-Based MCDA', baseline_results['mcda']),\n",
    "        ('Simple MLP', baseline_results['mlp']),\n",
    "        ('Neural Ranker', baseline_results['neural_ranker']),\n",
    "        ('DIN', baseline_results['din']),\n",
    "        ('DocMatchNet-Original', original_results.get('overall', original_results)),\n",
    "        ('DocMatchNet-JEPA-NoGate', ablation_results.get('no_gates', {})),\n",
    "        ('DocMatchNet-JEPA', jepa_results.get('overall', jepa_results))\n",
    "    ]\n",
    "\n",
    "    metrics = ['ndcg@1', 'ndcg@5', 'ndcg@10', 'map', 'mrr', 'hr@5']\n",
    "    col_vals = [[_metric_mean(mr, m) for _, mr in methods] for m in metrics]\n",
    "\n",
    "    def fmt(i, j):\n",
    "        vals = col_vals[j]\n",
    "        finite = [(idx, v) for idx, v in enumerate(vals) if np.isfinite(v)]\n",
    "        if not finite:\n",
    "            return '--'\n",
    "        sorted_idx = [x[0] for x in sorted(finite, key=lambda x: x[1], reverse=True)]\n",
    "        best = sorted_idx[0]\n",
    "        second = sorted_idx[1] if len(sorted_idx) > 1 else None\n",
    "        v = vals[i]\n",
    "        if not np.isfinite(v):\n",
    "            return '--'\n",
    "        s = f\"{v:.3f}\"\n",
    "        if i == best:\n",
    "            return f\"\\\\textbf{{{s}}}\"\n",
    "        if second is not None and i == second:\n",
    "            return f\"\\\\underline{{{s}}}\"\n",
    "        return s\n",
    "\n",
    "    latex = \"\"\"\n",
    "\\begin{table}[t]\n",
    "\\centering\n",
    "\\caption{Main Results: Doctor-Patient Matching Performance}\n",
    "\\label{tab:main_results}\n",
    "\\begin{tabular}{@{}lcccccc@{}}\n",
    "\\toprule\n",
    "\\textbf{Method} & \\textbf{NDCG@1} & \\textbf{NDCG@5} & \\textbf{NDCG@10} & \\textbf{MAP} & \\textbf{MRR} & \\textbf{HR@5} \\\\n",
    "\\midrule\n",
    "\"\"\"\n",
    "\n",
    "    for i, (method_name, _) in enumerate(methods):\n",
    "        row = method_name\n",
    "        for j, _ in enumerate(metrics):\n",
    "            row += f\" & {fmt(i, j)}\"\n",
    "        row += \" \\\\\\n\"\n",
    "        latex += row\n",
    "\n",
    "    latex += \"\"\"\\bottomrule\n",
    "\\end{tabular}\n",
    "\\end{table}\n",
    "\"\"\"\n",
    "    return latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TABLE II: Ablation Study\n",
    "# ============================================================\n",
    "def generate_table_2():\n",
    "    \"\"\"\n",
    "    Ablation study table.\n",
    "    9 variants × 3 metrics (NDCG@5, MAP, MRR)\n",
    "    Show delta from full model.\n",
    "    \"\"\"\n",
    "    variants = [\n",
    "        ('DocMatchNet-JEPA (Full)', 'full'),\n",
    "        ('\\quad w/o Context-Aware Gates', 'no_gates'),\n",
    "        ('\\quad w/o Two-Stage Training', 'no_twostage'),\n",
    "        ('\\quad w/ MSE Loss', 'mse_loss'),\n",
    "        ('\\quad w/ Pairwise Ranking Loss', 'ranking_loss'),\n",
    "        ('\\quad w/ Symmetric LR', 'symmetric_lr'),\n",
    "        ('\\quad w/o VICReg Gate Reg', 'no_vicreg'),\n",
    "        ('\\quad gate\\_dim = 16', 'gate_dim_16'),\n",
    "        ('\\quad gate\\_dim = 64', 'gate_dim_64')\n",
    "    ]\n",
    "\n",
    "    metrics = ['ndcg@5', 'map', 'mrr']\n",
    "\n",
    "    # Support both naming schemes for full model\n",
    "    full_results = ablation_results.get('full', ablation_results.get('full_docmatchnet_jepa', {}))\n",
    "\n",
    "    latex = \"\"\"\n",
    "\\begin{table}[t]\n",
    "\\centering\n",
    "\\caption{Ablation Study: Component Contribution Analysis}\n",
    "\\label{tab:ablation}\n",
    "\\begin{tabular}{@{}lccc|c@{}}\n",
    "\\toprule\n",
    "\\textbf{Variant} & \\textbf{NDCG@5} & \\textbf{MAP} & \\textbf{MRR} & \\textbf{$\\Delta$ NDCG@5} \\\\n",
    "\\midrule\n",
    "\"\"\"\n",
    "\n",
    "    for variant_name, variant_key in variants:\n",
    "        result = ablation_results.get(variant_key, {})\n",
    "        row = variant_name\n",
    "        for metric in metrics:\n",
    "            mean = result.get(metric, {}).get('mean', np.nan)\n",
    "            std = result.get(metric, {}).get('std', np.nan)\n",
    "            if np.isfinite(mean) and np.isfinite(std):\n",
    "                row += f\" & {mean:.3f}$\\pm${std:.3f}\"\n",
    "            else:\n",
    "                row += \" & --\"\n",
    "\n",
    "        full_ndcg = full_results.get('ndcg@5', {}).get('mean', np.nan)\n",
    "        cur_ndcg = result.get('ndcg@5', {}).get('mean', np.nan)\n",
    "\n",
    "        if variant_key in ['full', 'full_docmatchnet_jepa'] or not np.isfinite(full_ndcg) or not np.isfinite(cur_ndcg):\n",
    "            row += \" & --\"\n",
    "        else:\n",
    "            delta = cur_ndcg - full_ndcg\n",
    "            sign = \"+\" if delta > 0 else \"\"\n",
    "            row += f\" & {sign}{delta:.3f}\"\n",
    "\n",
    "        row += \" \\\\\\n\"\n",
    "        if variant_key in ['full', 'full_docmatchnet_jepa']:\n",
    "            row += \"\\midrule\\n\"\n",
    "        latex += row\n",
    "\n",
    "    latex += \"\"\"\\bottomrule\n",
    "\\end{tabular}\n",
    "\\vspace{2mm}\n",
    "\\footnotesize{Results averaged over 3 runs with different seeds. $\\Delta$ shows change from full model.}\n",
    "\\end{table}\n",
    "\"\"\"\n",
    "    return latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TABLE III: Stratified Performance by Clinical Context\n",
    "# ============================================================\n",
    "def generate_table_3():\n",
    "    \"\"\"\n",
    "    Stratified performance table.\n",
    "    5 contexts × 3 methods (MCDA, Original, JEPA)\n",
    "    \"\"\"\n",
    "    contexts = ['routine', 'complex', 'rare_disease', 'emergency', 'pediatric']\n",
    "    context_labels = ['Routine', 'Complex', 'Rare Disease', 'Emergency', 'Pediatric']\n",
    "\n",
    "    methods = [\n",
    "        ('MCDA', baseline_results.get('mcda', {}).get('stratified', {})),\n",
    "        ('Original', original_results.get('stratified', {})),\n",
    "        ('JEPA', jepa_results.get('stratified', {}))\n",
    "    ]\n",
    "\n",
    "    latex = \"\"\"\n",
    "\\begin{table}[t]\n",
    "\\centering\n",
    "\\caption{Stratified Performance by Clinical Context (NDCG@5)}\n",
    "\\label{tab:stratified}\n",
    "\\begin{tabular}{@{}lccc@{}}\n",
    "\\toprule\n",
    "\\textbf{Context} & \\textbf{Rule-Based} & \\textbf{DocMatchNet-Orig} & \\textbf{DocMatchNet-JEPA} \\\\n",
    "\\midrule\n",
    "\"\"\"\n",
    "\n",
    "    for ctx, ctx_label in zip(contexts, context_labels):\n",
    "        row = ctx_label\n",
    "        best_val = -1\n",
    "        vals = []\n",
    "        for _, method_strat in methods:\n",
    "            if ctx in method_strat:\n",
    "                entry = method_strat[ctx]\n",
    "                if isinstance(entry.get('ndcg@5', None), dict):\n",
    "                    val = entry['ndcg@5'].get('mean', 0.0)\n",
    "                elif isinstance(entry.get('ndcg@5', None), (list, tuple)):\n",
    "                    val = entry['ndcg@5'][0]\n",
    "                else:\n",
    "                    val = entry.get('mean', 0.0)\n",
    "                vals.append(float(val))\n",
    "                if val > best_val:\n",
    "                    best_val = val\n",
    "            else:\n",
    "                vals.append(0.0)\n",
    "\n",
    "        for val in vals:\n",
    "            if val == best_val and best_val > 0:\n",
    "                row += f\" & \\\\textbf{{{val:.3f}}}\"\n",
    "            else:\n",
    "                row += f\" & {val:.3f}\"\n",
    "        row += \" \\\\\\n\"\n",
    "        latex += row\n",
    "\n",
    "    latex += \"\"\"\\bottomrule\n",
    "\\end{tabular}\n",
    "\\end{table}\n",
    "\"\"\"\n",
    "    return latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TABLE IV: Gate Activation Patterns\n",
    "# ============================================================\n",
    "def generate_table_4():\n",
    "    \"\"\"\n",
    "    Gate activation table showing context-dependent behavior.\n",
    "    5 contexts × 4 gates\n",
    "    \"\"\"\n",
    "    latex = \"\"\"\n",
    "\\begin{table}[t]\n",
    "\\centering\n",
    "\\caption{Mean Gate Activations by Clinical Context}\n",
    "\\label{tab:gates}\n",
    "\\begin{tabular}{@{}lcccc@{}}\n",
    "\\toprule\n",
    "\\textbf{Context} & $G_{\\text{clinical}}$ & $G_{\\text{pastwork}}$ & $G_{\\text{logistics}}$ & $G_{\\text{trust}}$ \\\\n",
    "\\midrule\n",
    "\"\"\"\n",
    "\n",
    "    contexts = ['routine', 'complex', 'rare_disease', 'emergency', 'pediatric']\n",
    "    context_labels = ['Routine', 'Complex', 'Rare Disease', 'Emergency', 'Pediatric']\n",
    "    gates = ['clinical', 'pastwork', 'logistics', 'trust']\n",
    "\n",
    "    context_gate_stats = jepa_results.get('context_gate_stats', {})\n",
    "\n",
    "    for ctx, ctx_label in zip(contexts, context_labels):\n",
    "        row = ctx_label\n",
    "        if ctx in context_gate_stats:\n",
    "            for gate in gates:\n",
    "                val = context_gate_stats[ctx].get(gate, 0.5)\n",
    "                row += f\" & {val:.3f}\"\n",
    "        else:\n",
    "            row += \" & -- & -- & -- & --\"\n",
    "        row += \" \\\\\\n\"\n",
    "        latex += row\n",
    "\n",
    "    latex += \"\"\"\\midrule\n",
    "\\textit{Kruskal-Wallis $p$} \"\"\"\n",
    "\n",
    "    for gate in gates:\n",
    "        p_key = f'gate_{gate}_kruskal_pvalue'\n",
    "        if p_key in jepa_results.get('gate_analysis', {}):\n",
    "            p_val = jepa_results['gate_analysis'][p_key]\n",
    "            if p_val < 0.001:\n",
    "                latex += f\"& $<$0.001*** \"\n",
    "            elif p_val < 0.01:\n",
    "                latex += f\"& {p_val:.3f}** \"\n",
    "            elif p_val < 0.05:\n",
    "                latex += f\"& {p_val:.3f}* \"\n",
    "            else:\n",
    "                latex += f\"& {p_val:.3f} \"\n",
    "        else:\n",
    "            latex += \"& -- \"\n",
    "\n",
    "    latex += \"\"\"\\\\\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "\\vspace{2mm}\n",
    "\\footnotesize{*$p<0.05$, **$p<0.01$, ***$p<0.001$. Kruskal-Wallis test for gate differences across contexts.}\n",
    "\\end{table}\n",
    "\"\"\"\n",
    "    return latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TABLE V: Sample Efficiency\n",
    "# ============================================================\n",
    "def generate_table_5():\n",
    "    \"\"\"\n",
    "    Sample efficiency table.\n",
    "    7 data sizes × 4 methods\n",
    "    \"\"\"\n",
    "    data_sizes = [100, 250, 500, 1000, 2500, 5000, 10500]\n",
    "    methods = ['StaticMCDA', 'NeuralRanker', 'DocMatchNet-Original', 'DocMatchNet-JEPA']\n",
    "    method_labels = ['MCDA', 'Neural Ranker', 'DocMatch-Orig', 'DocMatch-JEPA']\n",
    "\n",
    "    latex = \"\"\"\n",
    "\\begin{table}[t]\n",
    "\\centering\n",
    "\\caption{Sample Efficiency: NDCG@5 vs Training Data Size}\n",
    "\\label{tab:sample_efficiency}\n",
    "\\begin{tabular}{@{}r\"\"\"\n",
    "\n",
    "    latex += \"c\" * len(methods)\n",
    "    latex += \"\"\"@{}}\n",
    "\\toprule\n",
    "\\textbf{\\# Samples} \"\"\"\n",
    "\n",
    "    for label in method_labels:\n",
    "        latex += f\"& \\\\textbf{{{label}}} \"\n",
    "    latex += \"\\\\\\n\\midrule\\n\"\n",
    "\n",
    "    for size in data_sizes:\n",
    "        row = f\"{size:,}\"\n",
    "        best_val = -1\n",
    "        vals = []\n",
    "        for method in methods:\n",
    "            val = sample_eff_results.get(method, {}).get(str(size), {}).get('mean', 0)\n",
    "            vals.append(val)\n",
    "            if val > best_val:\n",
    "                best_val = val\n",
    "\n",
    "        for val in vals:\n",
    "            if val == best_val and best_val > 0:\n",
    "                row += f\" & \\\\textbf{{{val:.3f}}}\"\n",
    "            else:\n",
    "                row += f\" & {val:.3f}\"\n",
    "        row += \" \\\\\\n\"\n",
    "        latex += row\n",
    "\n",
    "    latex += \"\"\"\\bottomrule\n",
    "\\end{tabular}\n",
    "\\end{table}\n",
    "\"\"\"\n",
    "    return latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TABLE VI: Efficiency Comparison\n",
    "# ============================================================\n",
    "def generate_table_6():\n",
    "    \"\"\"\n",
    "    Computational efficiency comparison.\n",
    "    \"\"\"\n",
    "    latex = \"\"\"\n",
    "\\begin{table}[t]\n",
    "\\centering\n",
    "\\caption{Computational Efficiency Comparison}\n",
    "\\label{tab:efficiency}\n",
    "\\begin{tabular}{@{}lrrrr@{}}\n",
    "\\toprule\n",
    "\\textbf{Method} & \\textbf{Params} & \\textbf{GPU (ms)} & \\textbf{CPU (ms)} & \\textbf{Train (h)} \\\\n",
    "\\midrule\n",
    "Rule-Based MCDA     & 0       & $<$1   & $<$1   & 0     \\\\n",
    "Simple MLP          & 50K     & $<$1   & $<$1   & 0.2   \\\\n",
    "Neural Ranker       & 350K    & 2      & 8      & 1.0   \\\\n",
    "DIN                 & 120K    & 1      & 5      & 0.8   \\\\n",
    "DocMatchNet-Orig    & 450K    & 3      & 12     & 1.5   \\\\n",
    "DocMatchNet-JEPA    & 520K    & 3      & 14     & 2.5   \\\\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "\\vspace{2mm}\n",
    "\\footnotesize{Inference latency measured per doctor-patient pair. Training time on single NVIDIA T4 GPU.}\n",
    "\\end{table}\n",
    "\"\"\"\n",
    "    return latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Statistical Significance Table\n",
    "# ============================================================\n",
    "def generate_significance_table():\n",
    "    \"\"\"\n",
    "    Pairwise statistical significance between JEPA and baselines.\n",
    "    \"\"\"\n",
    "    from scipy import stats\n",
    "\n",
    "    jepa_per_case = jepa_results.get('per_case', {}).get('ndcg@5', [])\n",
    "\n",
    "    comparisons = {\n",
    "        'vs MCDA': baseline_results.get('mcda', {}).get('per_case', {}).get('ndcg@5', []),\n",
    "        'vs MLP': baseline_results.get('mlp', {}).get('per_case', {}).get('ndcg@5', []),\n",
    "        'vs Neural Ranker': baseline_results.get('neural_ranker', {}).get('per_case', {}).get('ndcg@5', []),\n",
    "        'vs DIN': baseline_results.get('din', {}).get('per_case', {}).get('ndcg@5', []),\n",
    "        'vs DocMatch-Orig': original_results.get('per_case', {}).get('ndcg@5', [])\n",
    "    }\n",
    "\n",
    "    if len(jepa_per_case) == 0:\n",
    "        print('No per-case JEPA metrics available; skipping significance tests.')\n",
    "        return\n",
    "\n",
    "    print('\\nStatistical Significance (Wilcoxon signed-rank test):')\n",
    "    print('-' * 60)\n",
    "\n",
    "    p_values = []\n",
    "    names = []\n",
    "    for comp_name, comp_values in comparisons.items():\n",
    "        if len(comp_values) == 0:\n",
    "            print(f'  JEPA {comp_name}: missing per-case values')\n",
    "            continue\n",
    "\n",
    "        n = min(len(jepa_per_case), len(comp_values))\n",
    "        a = np.array(jepa_per_case[:n])\n",
    "        b = np.array(comp_values[:n])\n",
    "\n",
    "        stat, p_val = stats.wilcoxon(a, b, alternative='greater')\n",
    "        p_values.append(p_val)\n",
    "        names.append(comp_name)\n",
    "\n",
    "        improvement = np.mean(a) - np.mean(b)\n",
    "        denom = np.std(a - b)\n",
    "        effect_size = improvement / denom if denom > 0 else 0.0\n",
    "\n",
    "        sig = '***' if p_val < 0.001 else '**' if p_val < 0.01 else '*' if p_val < 0.05 else 'ns'\n",
    "\n",
    "        print(f\"  JEPA {comp_name}: Δ={improvement:+.4f}, d={effect_size:.3f}, p={p_val:.4e} {sig}\")\n",
    "\n",
    "    if len(p_values) == 0:\n",
    "        print('No valid comparisons for correction.')\n",
    "        return\n",
    "\n",
    "    corrected_alpha = 0.05 / len(p_values)\n",
    "    print(f\"\\nBonferroni-corrected α = {corrected_alpha:.4f}\")\n",
    "    for comp_name, p_val in zip(names, p_values):\n",
    "        sig = 'significant' if p_val < corrected_alpha else 'not significant'\n",
    "        print(f\"  JEPA {comp_name}: {sig} after correction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Print and Save All Tables\n",
    "# ============================================================\n",
    "tables = {\n",
    "    'table1': generate_table_1(),\n",
    "    'table2': generate_table_2(),\n",
    "    'table3': generate_table_3(),\n",
    "    'table4': generate_table_4(),\n",
    "    'table5': generate_table_5(),\n",
    "    'table6': generate_table_6()\n",
    "}\n",
    "\n",
    "os.makedirs('/kaggle/working/results/tables', exist_ok=True)\n",
    "\n",
    "for table_name, latex_code in tables.items():\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\"{table_name.upper()}\")\n",
    "    print('=' * 60)\n",
    "    print(latex_code)\n",
    "\n",
    "    with open(f'/kaggle/working/results/tables/{table_name}.tex', 'w') as f:\n",
    "        f.write(latex_code)\n",
    "\n",
    "generate_significance_table()\n",
    "\n",
    "print('\\n✅ All tables saved to /kaggle/working/results/tables/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
